[["index.html", "言語統計処理（春学期） Chapter 1 About 1.1 講義概要 1.2 講義スケジュール 1.3 成績評価について 1.4 留意事項", " 言語統計処理（春学期） 寺井雅人（Masato Terai） Published:2025-02-03, Last update(JST): 2025-04-04 15:53:52 Chapter 1 About  この資料は、名古屋大学大学院人文学研究科の学生を対象に開講されている言語統計処理（春学期）で使用する資料です。配布する際は、事前に作成者の寺井雅人まで連絡してください（researchmap）。  この資料は、適宜修正、アップデート行う予定です。ファイルの最終更新日を確認するようにしてください。 1.1 講義概要  この授業では，受講者が15回の授業終了時に，以下の知識・能力を身につけていることを目標とする。 統計処理の手続きに関する知識 分析結果を適切に解釈し、説明する能力 プログラム言語(R)を用いた統計処理能力 統計理論の数学・概念的知識 注 毎回の講義で必ずRStudioがインストールされているパソコンを持参してください。 講義内容、講義スケジュールは講義の進度等によって変更する可能性があります。 1.2 講義スケジュール Week 1：オリエンテーション、R(Studio)のインストールと操作、R Markdown Week 2：要約統計量 Week 3：推測統計学 Week 4：統計的検定の論理と t検定 Week 5：相関分析 Week 6：単回帰分析 Week 7：重回帰分析(1) Week 8：重回帰分析(2): コーディングの変更 Week 9：重回帰分析(3): 交互作用の解釈 Week 10：一般化線形モデル：ロジスティック回帰分析 Week 11：階層モデル Week 12：効果量と検定力分析 Week 13：ノンパラメトリック検定 Week 14：tidyverseパッケージによるデータの加工と可視化 Week 15：言語研究とオープンサイエンス 1.3 成績評価について 小テスト（20%）、演習課題（40%）、レポート試験（40%） 上記の各評価100点満点に換算し、それらを合計した得点が60点以上を合格とする。A+（100-95）、A（94-80）、B（79-70）、C（69-65）、C-（64-60）、F（59-0） 1.4 留意事項 質問は講義内容に関する質問への回答を優先します。取り組んでいる学位論文やその他プロジェクトへの質問への回答は原則お答えしません。 "],["week-1-オリエンテーションrstudioのインストールと操作r-markdown.html", "Chapter 2 Week 1: オリエンテーション、R(Studio)のインストールと操作、R Markdown 2.1 「統計処理」とは 2.2 Rとは 2.3 Rのインストール 2.4 RStudioとは 2.5 RStudioのインストール 2.6 RStudioの機能 2.7 プロジェクト機能 2.8 RStudioのカスタマイズ 2.9 R Markdown入門 2.10 ドキュメントチャンク：Markdown記法 2.11 Let’s 実践 2.12 名古屋飯といえば 2.13 ひつまぶし：Hitsumabushi 2.14 答え合わせ 2.15 コードチャンクの挿入 2.16 Let’s 実践 2.17 食費の合計 2.18 答え合わせ 2.19 次週までの課題 2.20 参考文献", " Chapter 2 Week 1: オリエンテーション、R(Studio)のインストールと操作、R Markdown .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} 2.1 「統計処理」とは 2.1.1 量的研究、質的研究 本講義のタイトルにある「統計処理」は、研究の目的などに応じて得られたデータをまとめたり、可視化したり解析する行為を指します。言語に関する研究の手法は大きく分けて以下の2つがある。 量的研究（ quantitative research ） 数量を用いて分析。一般化が目的。「仮説検証型」。 質的研究（ qualitative research ） 数量化せずに分析。一般化は目的ではない。「仮説生成型」。  寺井は量的な研究しか行ってきていないため、本講義では量的な研究を行うことを念頭に統計処理の方法について講義を行う。しかし、それらが質的研究と全く関連がないわけではない（もし質的な研究に関心がある受講生の方がいたら、関連すると思う点を教えてください）。 量的研究では数量を扱うため、統計手法を用いて分析を行うことが多い。よって、量的研究を行う場合、統計に関する知識が必要不可欠。 データ収集の前に分析手法をある程度決めておく必要がある（Garbage in, garbage out. ）。使用する統計手法だけでなく、以下のことも十分に考えておくことが必要。 どんなデータが必要？(What) どのようにデータを取ればいい？ (How) どれくらいのデータが必要？ (How many) 誰に対してデータを取る？(Who) 2.2 Rとは Rはプログラム言語の一種で、統計解析向けの言語。統計解析以外にもWebアプリを作ったり資料を作成したりすることも可能（この資料もRを使って作成しています）。Rは無料でインストール・使用することができる。 Rに備わっている機能だけで分析を行うことができるが、世界中のRユーザーが開発した機能（パッケージ）を無料でインストールすることができる。これにより、様々な分析を行うことができるが、それらのアップデートが行われるため注意が必要である（アップデートにより以前と同じように動かないということも起こりうるため）。 RをiPhone本体、パッケージをXやInstagramなどのアプリとイメージするとよい Excelなどコードを書かなくても統計解析を行うことができるソフトウェアは多い。しかし、ソフトウェアは無料のものばかりではなく、また実行したい分析を機能として持っていない可能性がある。近年では生成AIなどによって、プログラミングのハードルが以前よりも低くなったと考えられる。ソフトウェアで実行するよりも、プログラミング言語を駆使して分析を行う方が、統計以外の知識にもつながる。最初は「二階から目薬」のような気持ちになるかもしれないが、根気強く、授業者、友人、先輩、そしてAIさん達に頼りながら取り組んでほしい。 2.3 Rのインストール  Windowsを使用している人で、DocumentsのパスにOne Driveが関係している人は教えてください。将来悪さをする可能性がある。 Rの公式サイトにアクセス（ https://www.r-project.org/ ） CRANをクリック Japanのリンクをクリック（Yamagata University） 自分のパソコンのOSを選択 “install R for the first time”をクリック。全部NextでOK! インストールが完了したら、Rを立ち上げて以下のコードを入力する。Enterを押すと命令が実行される。 20 + 1 ## [1] 21 20 - 1 ## [1] 19 3 * 4 ## [1] 12 4 / 2 ## [1] 2 2 ^ 2 ## [1] 4 2.4 RStudioとは Rだけでも分析は可能だが、Rだけの解析は難しい。そこで、よりRでの解析を行いやすくする統合開発環境（RStudio）の中でRを使用する。 注意点として、Rのインストールも必ず行う必要がある。 RStudioはWeb版とローカル版があり、前者はオンライン上で使用するが、後者は各個人のパソコンで使用する。Web版の使用には、サーバーが必要であるため、基本的にローカル版（RStudio Desktop）での使用に慣れる方がよい。 2.5 RStudioのインストール RStudioのサイトへ行く（ https://posit.co/download/rstudio-desktop/ ） All Installers and Tarballsで自分自身のパソコンのOSを選び、ダウンロード 2.6 RStudioの機能 4つのペイン： ソース 実行するコードのメモ帳 環境・履歴 読み込んだデータを表示したりや過去に実行したコマンドを記録できる コンソール R。ソースペインを実行する場所 ファイル・作図・パッケージ・ヘルプ ワーキングディレクトリにあるファイルを表示したり、作成した図を確認したり、インストールされているパッケージを確認したり、パッケージの使い方を確認する 2.7 プロジェクト機能 プロジェクト = ディレクトリ ファイルや操作履歴を保存できる ディレクトリ（）とは、場所のこと。Rは一か所にしか滞在できない、移動する際も、命令してあげないと自分で勝手に移動してくれない。ごとが異なる場所であるため、ファイルを読み込んだりする場合も、Rがいる場所と、ファイルがある場所が異なる場合、Rを移動させるか、ファイルをRがいる箇所まで移動させないと読み込むことはできない。 プロジェクトを作成する利点 研究ごとに分析に必要なファイルをまとめることができる 2.7.1 プロジェクトの作成 ドキュメントディレクトリに新しいフォルダーを作成 名前は、絶対英数字のみ！（Rが関係しそうな場合、ファイル名、フォルダ名に日本語を使わない方が安心です） 作り方を解説しているサイト（私たちのR） RStudioを開き、右上の[Project:]ボタンをクリック。 [New Project]をクリックし、[Existing Directory]から、先ほど作成した名前のディレクトリを選択 今後、この講義で配布されたファイルや、作成したファイルは全てそのディレクトリ内に入れるようにしてください 今後、この講義でRStudioを使用する場合は必ずこのプロジェクトを開いてください 2.8 RStudioのカスタマイズ RStudioの設定変更【見た目】 文字のサイズを大きくしたり、背景の色を変更することが可能 その他にも、()の色分けをしてくれたりなど分析の補助になる機能もある 2.9 R Markdown入門 Rの出力結果を文字や写真、リンクなどと一緒に出力できるもの。 左上の紙のマークを押して、R Markdownを開く 【パーツ１】YAML（YAML Ain’t Markup Language）ヘッダー：文章全体の体裁や情報を操作する タイトル、サブタイトル 作成者 作成した日時、更新日時も設定可能 どのような形式で作成するか 注意 ・ YAMLヘッダーは、RでもMarkdownでもないプログラム言語で記述 【パーツ２】コードチャンク：Rのコードを記述するところ 【パーツ３】ドキュメントチャンク：Markdownと呼ばれるプログラム言語で記述するところ 見出し、表、箇条書き、強調、斜体など、Wordのリボン部分にある機能をMarkdownで書く 2.9.1 Knitを押して出力！ 初期設定はHTMLファイル出力 2.10 ドキュメントチャンク：Markdown記法 2.10.1 覚えるのはマストではない。その都度調べてよく使うものを覚えていく Markdownなら生成AIはほぼ完ぺきに正解を教えてくれる 必要最低限で覚えておくとよい記法 見出し → これはマスト！ #の数で指定。文字との間を半角あけるのを忘れない。 箇条書き *, +, -のいずれかを入れる。文字との間を半角あけるのを忘れない。 半角スペースを2つ前（もしくはtab）に入れると、レベル２を作れる。さらに2ついれると、、、 強調 *で挟むと斜体 **で挟むとBold体 ***で挟むとどうなるでしょう 2.11 Let’s 実践 以下の文章をR Markdownを使って再現してください。 2.12 名古屋飯といえば 2.13 ひつまぶし：Hitsumabushi おすすめは以下のお店です。 ひつまぶし花岡 場所：栄 2.14 答え合わせ # 名古屋飯といえば ## ひつまぶし：*Hitsumabushi* おすすめは以下のお店です。 - **ひつまぶし花岡** - 場所：栄 2.15 コードチャンクの挿入 2.15.1 ショートカットキーが便利：[Ctrl] + [Alt] + [I]（Windows）、[Command] + [Option] + [I]（Mac） このコードの中はR。Rで使う関数などを自由に指定できる 以下のチャンク内でないと、動かない = Rの命令として実行してもらえない ```{r} ``` dat &lt;- c(1, 4, 6) mean(dat) ## [1] 3.666667 plot(dat) 2.16 Let’s 実践 以下をドキュメントチャンクとコードチャンクを使って再現してください。 2.17 食費の合計 以下は、名古屋旅行で使った食費の合計である。 注! hitsuはひつまぶし、misoは味噌カツを表す。 hitsu &lt;- 1300 * 2 miso &lt;- 1000 * 2 total &lt;- sum(hitsu, miso) 2.18 答え合わせ ## 食費の合計 - 以下は、名古屋旅行で使った食費の合計である。 - **注!** *hitsu*はひつまぶし、*miso*は味噌カツを表す \\```{r} hitsu &lt;- 1300 * 2 miso &lt;- 1000 * 2 total &lt;- sum(hitsu, miso) \\``` 2.19 次週までの課題 2.19.1 課題内容 小テストの準備。本講義の内容に関する簡単なクイズを行います。配布した資料を見返しておいてください。 自己紹介の文をR Markdownで作成し、出力したHTMLファイルを提出してください。以下の2項目を必ず入れてください。クラス内や外部へ公開してもいい情報だけを入れてください！ 名前、出身、研究科、自分の研究したいことを二文くらいでまとめる。 レベル分け、箇条書き、強調（e.g., 下線、太字、イタリック） 2.19.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 2.20 参考文献 外国語教育ハンドブック [RStudioの設定変更【見た目】] RユーザーのためのRSTudio［実践］入門 私たちのR "],["references.html", "References", " References "],["week-2要約統計量.html", "Chapter 3 Week 2：要約統計量 3.1 事前の確認 3.2 今日の目標 3.3 今日の格言 3.4 記述統計学と推測統計学 3.5 データの尺度 3.6 「～とみなす」 3.7 要約統計量 3.8 データの可視化 3.9 ハンズオンセッション 3.10 まとめ 3.11 次週までの課題 3.12 参考文献", " Chapter 3 Week 2：要約統計量 3.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 3.2 今日の目標 記述統計、推測統計の違いおよびデータの尺度について理解できる。 データの要約統計量やグラフの意味が理解でき、またそれらをRで算出・作成ができる。 3.3 今日の格言 プログラムは思った通りには動かない。書いた通りに動くのだ（unknown） 前半は主に説明、後半はRを使用して手を動かしながらやってもらいます。 3.4 記述統計学と推測統計学 3.4.1 記述統計学（descriptive statistics） 得たデータを要約する統計手法 統計量（statistic）の算出、データの可視化 統計量：データから計算された数値のこと（e.g., 平均値や合計値） 3.4.2 推測統計学（inferential statistics） 得られたデータから、母集団の性質を推測する。 測定、将来の予測、因果関係の推測、現象の説明という主に4つの目的 母集団：想定する集団のこと（日本人の英語力を調べたい = 日本人全員） 母集団の一部から集めたデータから、母集団全体に当てはまることを理解する 記述統計ではできない 3.5 データの尺度 4種類あり、比例、間隔、順序、名義の順に情報量が少なくなる 上の順序のデータを下の順位のデータに変換することはできるが、逆の変換はできない 3.5.1 比率尺度（ratio scale） 様々な統計処理に使える 例：長さ、重さ、時間 ゼロが「何もない」ことを表す メモリがすべて等間隔 データ同士で四則演算ができる 3.5.2 間隔尺度（interval scale） 例：温度、テストの得点、偏差値、テストの平均点 メモリの間隔は同じ ゼロは「何もない」ことを表さない 「足す」「引く」は可能。「かける」「わる」はできない。 3.5.3 順序尺度（ordinal scale） 例：順位、投票のランキング、リカート・スケール（Likert scale） 順位のデータ メモリの間隔が一定になる保証はない（= 大小のみを指す）。 0位もない 四則演算ができない 3.5.4 名義尺度（nominal scale） データに任意の数を与えたデータ 例：男性は1、女性は2 メモリは等間隔でない ゼロは「何もない」を表さない 四則演算ができない 3.6 「～とみなす」 テスト得点は厳密にいうと、間隔尺度とは言えない？ 配点が1点と5点は5倍の違いがあるか？ 0点は能力が全くないと言えるか？ しかしテスト得点を統計分析したい場面が多く、統計分析は間隔尺度以上のデータを必要とする。 テスト得点の間隔を等間隔にする努力を怠らないのであれば間隔尺度として「みなそう」ということに現状はなっている（完全に合意されているわけではない）。 本講義ではテスト得点を間隔尺度として「みなす」 3.7 要約統計量 データを取ったらとりあえず要約をする。 そのままのデータ（e.g., 100人分の素点）を人間はなかなか理解できない。 集まったデータを目的合わせて要約をし、分かりやすく提示する。 大別して代表値と散布度があり、前者は大体の値、後者はばらつきを表すデータ 3.7.1 各統計量 3.7.1.1 代表値 平均値（mean） 平均値は沢山ある：算術平均、幾何平均、移動平均 本講義では平均は算術平均を指す 算出方法：すべての数を足し合わせて、データの数で割る 中央値（median） 小さい方から並べてちょうど真ん中にある値 奇数の時：1, 2, 3 =&gt; 中央値は2 偶数の時：1, 2, 3, 4 =&gt; 中央値は = 2.5 平均値は外れ値の影響を受けやすいが、逆に外れ値を考慮しやすい。この二つはことなる基準であるため、平均値と中央値の二つを算出して比較するとよい。 四分位（quantile） 小さい方から並べたデータを4分割する 第1四分位：データの25% 第2四分位：データの50%の個所 = 中央値 第3四分位：データの75% 最頻値（mode） 得られた数値をまとめ、同じ数字が何回出てくるか（度数: Frequency）を数える。その中で一番数が多い数字のこと。 名義尺度や順序尺度水準のデータはこの指標を使うとよい 例：以下は3人のアンケート結果です。それぞれ3つのポケモンを選んでいます。 回答者 1位 2位 3位 Aさん ピカチュウ イーブイ ゲンガー Bさん ピカチュウ リザードン ミュウ Cさん ピカチュウ カビゴン フシギバナ ポケモン名 得票数 ピカチュウ 3 イーブイ 1 ゲンガー 1 リザードン 1 ミュウ 1 カビゴン 1 フシギバナ 1 最頻値は3でピカチュウの得票数が多かった。 3.7.1.2 散布度 分散（variance）：σ2 データが平均値の付近に密集している程度 値が大きいほどばらつきが大きい \\[\\sigma^2=\\frac{1}{N}\\sum_{i=1}^N(x_i-\\mu)^2\\] N : データの数 xi : データ一つ一つ u : 平均値 各データを平均値から引き、「平均値との差」という指標に変換（ = 平均からの偏差） 全部足したいが、プラスとマイナスが混じっており、全部足すと0になる。 2乗し全部プラスにする。 全部の偏差を足して、データの数で割る。 標準偏差（standard deviation）：σ 分散のルートを取った値。分散は元のデータを2乗している。そのため単位が大きく解釈が困難なため。 値が大きいほどばらつきが大きい \\[\\sqrt{σ^{2}}\\] 平均、標準偏差などの要約だけではデータの全体像は見えにくい。下記の図のように、同じ平均、標準偏差（M = 50, SD = 10）でもデータの分布が異なることが分かる。このように、得られたデータの把握には、数値の要約だけでなく、可視化も重要となる。 3.8 データの可視化 3.8.1 量的データの可視化 3.8.1.1 1つのデータ 3.8.1.1.1 ヒストグラム（histogram） データを階級幅で区切り、その中に入るデータがいくつあるか（度数）を描画する score_data %&gt;% ggplot(aes(x = score_data$English)) + geom_histogram(binwidth = 5, fill = &quot;skyblue&quot;, color = &quot;black&quot;) + labs(title = &quot;英語の得点分布&quot;, x = &quot;得点&quot;, y = &quot;人数&quot;) ## Warning: Use of `score_data$English` is discouraged. ## ℹ Use `English` instead. 3.8.1.2 2つのデータ 3.8.1.2.1 散布図（scatter plot） 量的データ同士の関係を描画する 以下の図では100人がそれぞれ国語と英語のテストを受け、その得点を描画している。 ggplot(score_data, aes(x = English, y = Japanese)) + geom_point(color = &quot;blue&quot;, alpha = 0.6) + labs(title = &quot;英語と国語の得点の関係&quot;, x = &quot;英語の得点&quot;, y = &quot;国語の得点&quot;) + theme_minimal() 3.8.2 量的 + 質的データの可視化 科目（名義尺度）ごとの得点（間隔尺度）のような場合。 3.8.2.1 棒グラフ（bar plot） それぞれの科目の得点の平均値を描画 3.8.2.2 箱ひげ図（boxplot） 棒グラフよりもより多くの情報を確認できる。 外れ値が含まれる場合、描画されている最大値もしくは最小値はデータの中のもっとも大きい数をではない場合がある。 一般的に外れ値として判定される数 第1四分位数 - 1.5 × IQR（Inter-Quartile Range：第3四分位数から第1四分位数の範囲） 第3四分位数 + 1.5 × IQR 3.8.2.3 ヴァイオリン・プロット（Violin plot） ヒストグラムを滑らかな曲線（カーネル密度推定）に変え、背中合わせに張り付けたグラフ データが集まっている個所が膨らんで描画されるため、全体的な分布を把握しやすい ggplot(score_data, aes(x = &quot;英語&quot;, y = English, fill = &quot;英語&quot;)) + geom_violin(trim = FALSE, alpha = 0.6) + geom_violin(aes(x = &quot;国語&quot;, y = Japanese, fill = &quot;国語&quot;), trim = FALSE, alpha = 0.6) + scale_fill_manual(values = c(&quot;英語&quot; = &quot;skyblue&quot;, &quot;国語&quot; = &quot;salmon&quot;)) + labs(title = &quot;英語と国語の得点分布（ヴァイオリン・プロット）&quot;, x = &quot;科目&quot;, y = &quot;得点&quot;) + theme_minimal() 3.8.3 質的データの可視化 四則演算ができないため、平均値などを算出できない。 度数分布表（frequency distribution table） 1次元 Table 3.1: Do you like Pikachu and Eevee? Yes No 67 33 クロス集計表（cross table） 2次元 survey_data %&gt;% group_by(Pokemon, Like) %&gt;% count() %&gt;% arrange(desc(Like)) %&gt;% tidyr::pivot_wider(names_from = Like, values_from = n) %&gt;% kableExtra::kbl(align = &quot;c&quot;, caption = &quot;Do you like Pikachu and Eevee?&quot;) %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;), full_width = T) Table 3.2: Do you like Pikachu and Eevee? Pokemon Yes No イーブイ 35 15 ピカチュウ 32 18 3.9 ハンズオンセッション 3.9.1 Rの基本用語 3.9.1.1 変数 どんなデータも格納できる箱。箱には必ず名前を付ける。名前は英数字のみを入れること。また、命名には規則がある。 名前の先頭に数字（e.g., 1hako）や記号（e.g., %hako）は使用できない 大文字と小文字は区別される（Hakoとhakoは別の変数として認識される） プログラミングの世界では、以下の二つの命名の流儀がある。 スネークケース：変数の区切りを”_“で示す（e.g., snake_case） キャメルケース：変数の区切りを大文字で示す（e.g., camelCase） 自由に箱（変数）に名前を付けてよいが、できるだけ自分の中で一貫したルールを持ち、第三者が見ても何が格納されているか分かりやすい名前を付けることを意識する。 変数に入れたデータは、［Environment］タブに表示される。 変数の中身が数値の場合、数値を足したりかけたりなど計算ができる。 numという名前の変数に1から10の数字を入れ、それらを2倍した num &lt;- 1:10 num ## [1] 1 2 3 4 5 6 7 8 9 10 num * 2 ## [1] 2 4 6 8 10 12 14 16 18 20 変数の中身は上書きすることもできる num &lt;- num * 2 3.9.1.2 データの型 「いちたすに」と「1 + 2」はコンピュータにとっては別もの 実数型（numeric）：数値全般（e.g., 10.4） 整数型（integer）：整数のみ（e.g., 10） 文字列型（character）：文字（e.g., “十”）。入力する際は\"\"や''で囲む 論理型（logical）：TRUEとFALSEからなる 因子型（factor）：データに順番（数字を割り振る） dat &lt;- 1:4 str(dat) ## int [1:4] 1 2 3 4 dat &lt;- factor(dat, levels = c(4:1)) str(dat) ## Factor w/ 4 levels &quot;4&quot;,&quot;3&quot;,&quot;2&quot;,&quot;1&quot;: 4 3 2 1 3.9.1.3 関数 パッケージに含まれている、命令を実行するのに必要なもの。data.frame()のような文字列とかっこの組み合わせ。かっこの中にデータを格納する。 数学の関数とイメージしてもよい。例えば、Y = 2x という関数は、xを2倍する関数。入れたデータが2倍されて返ってくる。 使う際は呼び出す必要があり、Rのセッションが切れるまでは何回も呼び出す必要はない。Rに標準で備わっているものは呼び出す必要はない（base関数という）。 下の例では、plot()関数で変数の中身を描画している dat.2 &lt;- 1:10 plot(dat.2) help(関数名)やウェブサイトで調べると、使い方を確認することができる。 3.9.1.4 ベクトル データのまとまり c()関数で作成可能。連続する数値であれば、:でもOK numVector1 &lt;- c(1, 35, 90, 0.9) numVector2 &lt;- c(1, 35, 90, 9) chVector &lt;- c(&quot;いちご&quot;, &quot;strawberry&quot;, &quot;イチゴ&quot;) numchVector &lt;- c(&quot;イチゴ&quot;, 1000, &quot;みかん&quot;, &quot;500&quot;) 変数に何かを入れたら、必ず中身を確認する！ numVector1 ## [1] 1.0 35.0 90.0 0.9 numVector2 ## [1] 1 35 90 9 chVector ## [1] &quot;いちご&quot; &quot;strawberry&quot; &quot;イチゴ&quot; numchVector ## [1] &quot;イチゴ&quot; &quot;1000&quot; &quot;みかん&quot; &quot;500&quot; データの型がどうなっているかを確認。確認する関数は様々なものがある。[Environment]タブでも表示されている。 class(numVector1) ## [1] &quot;numeric&quot; str(numVector2) ## num [1:4] 1 35 90 9 typeof(chVector) ## [1] &quot;character&quot; mode(numchVector) ## [1] &quot;character&quot; 3.9.2 データを読み込む 研究では、ファイルに格納されたデータに対して分析を行う。データ基本的にxlsx、csv、txtという拡張子のファイルに格納されていることが多い（最近ではオンラインでのデータ収集によってJSON形式もよく見るようになりました）。 xlsx エクセルファイル。 csv (Comma-Separated Values) カンマ（,）で項目を区切ったファイル txt 文字データだけが含まれるファイル（区切りは様々） 拡張子を表示させる設定に変更する。 データを読み込む場合、ファイルの種類によって読み込む際の関数が異なる。リンク先から（データ格納庫）データをダウンロードし、本講義用のR project内に移動させる。 移動させたら、以下のコードを走らせ、データをR(Studio)に読み込む 文字化けする場合、以下のコードを引数の中に加える（Windows: 挿入, MAC: 挿入）。 以下の処理で、csvファイル内のデータをdatという変数の中に格納したことになる。 dat &lt;- read.csv() 3.9.3 データフレーム 行（横）と列（縦）からなる、ベクトルのかたまり 数値、文字、因子など様々なベクトルを格納するデータ。データ分析のデータは基本的にこの型を指す。 読み込んだデータは基本的にデータフレームであるが、ベクトルからdata.frame()関数で作成することもできる。 fruit_df &lt;- data.frame( name = c(&quot;イチゴ&quot;, &quot;みかん&quot;), price = c(100, 150) ) 数値は行の番号を指し、データには含まれない。 fruit_df ## name price ## 1 イチゴ 100 ## 2 みかん 150 3.9.4 要約統計量の算出 3.9.4.1 各統計量ごと # 合計 (sum) sum(mtcars$mpg) ## [1] 642.9 # 平均 (mean) mean(mtcars$mpg) ## [1] 20.09062 # 中央値 (median) median(mtcars$mpg) ## [1] 19.2 # 最大値 (max) max(mtcars$mpg) ## [1] 33.9 # 最小値 (min) min(mtcars$mpg) ## [1] 10.4 # 標本分散 (var) var(mtcars$mpg) ## [1] 36.3241 # 標本標準偏差 (sd) sd(mtcars$mpg) ## [1] 6.026948 # （最大 - 最小） range_mpg &lt;- range(mtcars$mpg) wide_mpg &lt;- diff(range_mpg) wide_mpg # 範囲を表示 ## [1] 23.5 # 尖度 (kurtosis) ※&quot;moments&quot; パッケージを使用 #install.packages(&quot;moments&quot;) # 初回のみ library(moments) kurtosis(mtcars$mpg) ## [1] 2.799467 # 四分位範囲 (IQR) IQR(mtcars$mpg) ## [1] 7.375 3.9.4.2 一度に出力 base関数 base::summary(mtcars$mpg) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 10.40 15.43 19.20 20.09 22.80 33.90 psychパッケージのdescribe関数 # install.packages(&quot;psych&quot;) 1つのパソコンにつき一回でよい library(psych) # 使用する際、セッションにつき一回 ## ## Attaching package: &#39;psych&#39; ## The following objects are masked from &#39;package:ggplot2&#39;: ## ## %+%, alpha describe(mtcars$mpg) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 32 20.09 6.03 19.2 19.7 5.41 10.4 33.9 23.5 0.61 -0.37 1.07 3.9.4.3 最頻値 Rでは最頻値の求め方に少し一工夫必要。いろいろなやり方があるが、その一例として下記がある。 # 最頻値 (mode) ※最頻値は複数ある場合があるため table() を使用 table_mpg &lt;- table(mtcars$mpg) mode_mpg &lt;- as.numeric(names(table_mpg)[table_mpg == max(table_mpg)]) mode_mpg # 最も頻度の高い値を表示 ## [1] 10.4 15.2 19.2 21.0 21.4 22.8 30.4 3.9.5 作図 Rに最初から登録されているデータセットを使用 参考 描画のパラメータ。詳しくはウェブサイトを参考に（例 ） main: 図のタイトル xlab: x軸のタイトル ylab: y軸のタイトル border: ヒストグラムの棒の枠線 type: 線や点のスタイル col: 色を指定（e.g., “blue”, “red”, “green”） pch: 点の形指定（e.g., pch = 16 は●、pch = 17 は▲） lwd: 線の太さを指定 3.9.5.1 ヒストグラム hist(mtcars$mpg, main = &quot;Histogram of Miles Per Gallon (mpg)&quot;, xlab = &quot;Miles Per Gallon&quot;, col = &quot;lightblue&quot;, border = &quot;black&quot;) 3.9.5.2 折れ線グラフ plot(airquality$Temp, type = &quot;l&quot;, main = &quot;Daily Temperature in New York&quot;, xlab = &quot;Day&quot;, ylab = &quot;Temperature (°F)&quot;, col = &quot;blue&quot;, lwd = 2) 3.9.5.3 散布図 plot(mtcars$wt, mtcars$mpg, main = &quot;Scatter Plot of Car Weight vs. MPG&quot;, xlab = &quot;Weight (1000 lbs)&quot;, ylab = &quot;Miles Per Gallon&quot;, col = &quot;darkgreen&quot;, pch = 16) 3.9.5.4 箱ひげ図 boxplot(mtcars$mpg[mtcars$vs == 1], mtcars$mpg[mtcars$vs == 0], names = c(&quot;Engine: straight&quot;, &quot;Engine: V-shaped&quot;), main = &quot;Boxplots of Miles Per Gallon&quot;, ylab = &quot;Values&quot;, col = c(&quot;lightcoral&quot;, &quot;lightblue&quot;)) 3.9.5.5 バイオリンプロット #install.packages(&quot;vioplot&quot;) library(vioplot) ## Warning: package &#39;vioplot&#39; was built under R version 4.3.3 ## Loading required package: sm ## Warning: package &#39;sm&#39; was built under R version 4.3.3 ## Package &#39;sm&#39;, version 2.2-6.0: type help(sm) for summary information ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric vioplot(mtcars$mpg[mtcars$vs == 1], mtcars$mpg[mtcars$vs == 0], drawRect = F, # Tにすると、箱ひげ図が中に描かれる names = c(&quot;Engine: V-shaped&quot;, &quot;Engine: straight&quot;), col = c(&quot;lightcoral&quot;, &quot;lightblue&quot;), main = &quot;Violin Plot of Miles Per Gallon&quot;, ylab = &quot;Miles Per Gallon&quot;) 3.10 まとめ （引用：平井 et al. (2021). 『教育・心理系研究のためのRによるデータ分析』 p. 3） 種類 指標 特徴 名義尺度以上 最頻値 (mode) 最も多い度数を示すデータの値。主に名義尺度で用いられる代表値。 順序尺度以上 中央値 (median) データを順番に並べたときの真ん中（50%タイル）の値。順序情報に基づくため外れ値の影響を受けにくい。（例）テストの得点が {1, 3, 5, 7, 9} の場合は、中央値は 5 になる。 間隔尺度以上 平均 (mean) 個々の測定値の和を測定値の個数で割った値。中央値に比べ、外れ値に引っ張られる傾向がある。なお、標本平均 \\(\\bar{x}\\) と区別して母集団の平均を表す場合は平均（\\(\\mu\\)）と呼ぶ。 名義尺度以上 平均情報量 総度数と各カテゴリ度数との比率。（例）本の貸し出し総数が 10 件とすると、総度数は 10 件。そのうち、フィクションは 3 件、実務書 3 件、ノンフィクション 2 件、それ以外のジャンルは 2 件とカテゴリ度数を示す。 順序尺度以上 範囲 (range) 最大値と最小値との差。 順序尺度以上 四分位偏差 (quartile deviation) 順に並んだデータを 4 等分し、その境界となる第1四分位数（\\(Q_1\\)：25%タイル）と第3四分位数（\\(Q_3\\)：75%タイル）の差を四分位範囲（inter quartile range）と言う。それを 2 で割った値が四分位偏差。\\(Q = \\frac{Q_3 - Q_1}{2}\\) 間隔尺度以上 分散 (variance) 平均からの偏差平方和の大きさを示す。データ \\(x_i\\) と平均（\\(\\bar{x}\\)）の差を2乗して、全データ（\\(n\\)）またはデータ数 \\(n-1\\)（標本分散）で割った値。統計では、不偏不分散（unbiased variance）として、\\(n-1\\) で割ることが多い。\\(s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n-1}\\) 間隔尺度以上 標準偏差 (standard deviation) 上記の分散の平方根を取った値で、非負値になる。単位が元の値と同じ尺度なので直感的に解釈しやすい。小さい値はデータが平均の近くにあり、個別データのばらつきが小さいことを示す。\\(s = \\sqrt{\\frac{\\sum (x_i - \\bar{x})^2}{n-1}}\\) 3.11 次週までの課題 3.11.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 下記のデータをもとに、どの指標でもよいので、以下の内容を含めること。R Markdownファイルで作成し、HTMLファイルに変換しそれを提出 要約統計量を算出 最低2つの図 気づいたことを2行以上でまとめる ポケモンのデータセット（入手元） 一部列を削除している。 データの内訳 id: 各ポケモンに振られた数値 名前：ポケモンの名前 タイプ1：ポケモンに設定されている属性のようなもの。複数のタイプを持つポケモンがいるので、タイプ1となっている 高さ：身長 重さ：体重 世代：ポケモンには1~8まで世代が存在し、新しいゲームが出るたびに新種のポケモンが発表される ステータス：ポケモンが持つ6つ能力（HP、こうげき、ぼうぎょ、とくこう、とくぼう、すばやさ）の合算値 HP: Hit Pointで体力のこと こうげき：物理技の攻撃力 ぼうぎょ：物理技の防御力 とくこう：特殊技の攻撃力 とくぼう：特殊技の防御力 すばやさ：どれくらい速くワザを出せるか 捕まえやすさ：数値が上がるほど捕まえやすくなり最大で255で、最小は3 進化：0 = 進化しないポケモン、1 = たねポケモン、2 = 1進化したポケモン、3 = 2進化したポケモン 画像URL：コピー&amp;ペーストすればどんなポケモンか見れる 3.11.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 3.12 参考文献 外国語教育ハンドブック Rでらくらくデータ分析 心理学統計法 放送大学 https://www.geeksforgeeks.org/a-complete-guide-to-the-built-in-datasets-in-r/ https://eau.uijin.com/advgraphs/parameters.html https://smart-hint.com/poke-data/introduction/#%E3%83%9D%E3%82%B1%E3%83%A2%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%82%92%E5%AD%A6%E3%81%B6 .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["推測統計学.html", "Chapter 4 推測統計学 4.1 事前の確認 4.2 今日の目標 4.3 母集団と標本 4.4 確率と確率変数 4.5 推測統計学の考え方 4.6 区間推定の考え方 4.7 Rの関数で95%信頼区間を求める 4.8 ハンズオンセッション 4.9 まとめ", " Chapter 4 推測統計学 4.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 4.2 今日の目標 母集団と標本の違いや確率分布が理解できる 区間推定の考え方が理解できる 4.3 母集団と標本 推測統計学は、母集団から標本を得て、母集団の特徴を推測する手法 4.3.1 母集団（population） 調べたい対象の集団のこと 例 研究課題：英語を第二言語として学ぶ人は母語の影響を必ず受ける。 母集団：世界中の英語を第二言語として学ぶ人 4.3.2 標本（Sample） 実験や調査のために母集団の中から選ばれたもの 選ぶことを標本抽出（sampling）と呼ぶ 4.4 確率と確率変数 推測統計学では確率が非常に重要な概念。 4.4.1 確率 4.4.2 確率変数と確率分布 4.4.2.1 確率変数（random variable） 確率的に生じる事象に数値を割り当てたもの 実際に得られた値のことを確率変数の実現値という 確率変数はスロットマシーンが回っている状態。実現値はスロットマシーンが止まって値が定まった状態をイメージするとよい 4.4.2.2 確率分布（probability distribution） 確率変数の実現値それぞれの生じやすさを確率で表したもの。統計学では、確率変数の実現値を与えると確率を返す関数のことを確率分布という 事象を確率変数として扱うことで、母集団を人の集団ではなく、確率変数の実現値の集合として考えることができる。 1万人の学生の集団という母集団が、数値が1万個ある集団と仮定でき、数学的な枠組みとして考えやすくなる（数学の世界に現実世界を映す）。 この場合、母集団の性質を標本に正確に反映させるために、単純無作為抽出（simple random sampling）を行う必要がある。 母集団のすべての対象が偏りなく選ばれること（= 無作為に選ぶ） 4.4.2.3 確率分布の種類 離散型確率分布：確率質量関数 とびとびの値をとる（e.g., 裏、表） ベルヌーイ分布、二項分布、ポアソン分布 連続確率分布：確率密度関数 連続した値をとる（e.g., 身長） 正規分布、t 分布、カイ二乗分布 4.5 推測統計学の考え方 4.5.1 標本統計量 標本から計算される記述統計量のこと 標本平均：母集団から得た標本のデータの平均値 母平均：母集団の平均値 4.5.2 標本分布 標本統計量が確率的に変動することを表した確率分布のこと 標本を沢山抽出した場合であって、1つのデータの分布ではない 標本サイズ（ k ）が大きくなるにつれ、標本分布の散らばりはどんどん小さくなる 以下の図では100ほどのデータがあれば母平均（0.7）の ± 0.1にほとんどのデータが集まることが分かる しかし、これは母平均を事前に把握している場合を例であり、事前に母平均を知っていることは基本的にない。 4.6 区間推定の考え方 4.6.1 母集団分布に確率分布を仮定する 母集団分布が未知の場合、母集団からある値が標本として選ばれる事象の確率が。よく知られた確率分布に従うと仮定する。 統計モデル（statistical model）や確率モデル（probabilistic model）と呼ぶ よく知られたモデルとして、正規分布（normal distribution）が挙げられる 適切な確率モデルを設定しなければ、そこから算出したデータは正確ではない。 ある程度大きいデータを取り、そのヒストグラムを描画して形状を確認する データの発生メカニズムから選ぶ 例. 反応速度は対数正規分布で近似する、発生確率の低い出来事はポワソン分布に近似する 4.6.2 正規分布の性質 確率分布は形状を決めるパラメータがある。 正規分布のパラメータ：平均（確率分布の位置） + 分散（確率分布の広がり） 期待値（Expected value）：確率分布の平均値のこと ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. 確率変数が離散的な値をとる場合、確率変数の実現値ろと確率は一対一対応している（例 1か0のデータ）。 ## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(density)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. 確率変数が連続的な値をとる場合、実現値の値ではなく、その範囲と確率が対応する。つまり、確率分布の面積が確率と対応する（数値積分をして求めないといけない）。 integrate(f = dnorm, lower = 0, upper = 1) ## 0.3413447 with absolute error &lt; 3.8e-15 平均値 ± 1.96 × 標準偏差で、標本分布の95%の範囲になる。 白い部分は二か所合わせてデータの5% ## [1] 2.055362 - mean(density_data$x) ± 1.96となっているのは、標準偏差が1であるため。 integrate(f = dnorm, lower = mean(density_data$x) - 1.96, upper = mean(density_data$x) + 1.96) ## 0.9489619 with absolute error &lt; 9.2e-12 4.6.3 確率モデルを用いた推定 適切な確率モデルが設定されているとき、母数を推定することは、確率モデルのパラメータがどのような値であるかを推測することと同じ。 4.6.4 正規分布モデルにおける標本平均の標本分布 標準誤差（Standard Error: SE） 標本分布の標準偏差 SE= n = 標本サイズ 標本サイズが大きいほど標準誤差は小さくなり、標本平均は母平均に近づく（分母に標本サイズ） 4.6.5 区間推定 点推定（point estimation）：平均値のように1つの値によって母数（母平均など）を推定すること 標本サイズがどれだけ大きくても、標本平均は確率的に変動するため、ずばり母数を当てることは難しい 4.6.5.1 信頼区間 区間推定（interval estimation）：区間による推定を行うこと 必ずこの区間に当てはまることは主張できない。そのため、区間推定では、信頼度（degree of confidence）を設定する。これを信頼区間（confidence interval）という。 言語研究の分野では95%が一般的 4.6.5.1.1 母分散を事前に知っている場合 標本サイズは25、標本平均99.46、母分散は4を例とする。よって標準誤差は0.4。 「得られた標本統計量が95%の信頼度で否定されない母数の範囲」を考える =&gt; 標本平均99.46が95%上限ぎりぎりになるような母数と、95%下限ぎりぎりになるような母数の範囲。上記で扱ったように、面積の95%を塗りつぶすには、平均値から ± 1.96 × 標準偏差すればよい。 下限：99.46 - 1.96 × 0.4 = 98.68 上限：99.46 + 1.96 × 0.4 = 100.24 下記の図の赤い点線の内側の範囲が95%信頼区間 4.6.5.1.2 母分散を知らない場合 母分散が分からない場合の母平均の推定方法を扱う。現実的に、母分散が分かっていることはほとんどない。 母分散が分からない場合、上記の算出法では母平均の区間推定はできない。従って、母分散に依存しない統計量の計算が必要となる 4.6.5.1.2.1 t 値を用いた信頼区間の計算 t 値：下記の式から算出できる値。t分布に従う。 \\[ t = \\frac{\\bar{x} - \\mu}{\\frac{u^2}{\\sqrt{n}}} \\] t分布には、自由度（degree of freedom）と呼ばれるパラメータがある。t分布の自由度は、標本サイズによって変わる。自由度は、 n - 1で計算できる。 自由度が100くらいになると、標準正規分布（平均0, 標準偏差1の正規分布）と同じような形になる。 母平均が分からない場合、上記のt値を計算することはできない。しかし、母平均の信頼区間を求める場合、t分布の95%の面積にああるような範囲を考えればいい。自由度25の時、上側と下側それぞれ2.5%（5% ÷ 2）となるようなt値を求める（表から値を探したりして値を見つける）。 Rの標準的な関数で求めることも可能 qt(.975, df = 24) ## [1] 2.063899 qt(.025, df = 24) ## [1] -2.063899 以下の式をもとに算出する \\[ \\left( \\bar{x} - t_{\\alpha/2, \\, n-1} \\cdot \\frac{u^2}{\\sqrt{n}}, \\quad \\bar{x} + t_{\\alpha/2, \\, n-1} \\cdot \\frac{u^2}{\\sqrt{n}} \\right) \\] u^2は不偏分散であり、以下の式で求められる。自由度25、標準偏差が2.24の場合、nに25、Sに2.24を代入する。しかし、標本サイズが大きいときはほとんど同じ値になるため、実用上標本分散を用いることもある。 \\[ s^2 = \\frac{1}{n-1}S^2 \\] 上限：99.46 + 2.06 * sqrt{} 下限：99.46 - 2.06 * sqrt{} 98.52 - 100.40の間に母平均があると推定された 4.7 Rの関数で95%信頼区間を求める gmodels::ci(mtcars$mpg) ## Warning in ci.numeric(mtcars$mpg): No class or unkown class. Using default ## calcuation. ## Estimate CI lower CI upper Std. Error ## 20.090625 17.917679 22.263571 1.065424 上記の関数と一致した mean(mtcars$mpg) + qt(df = (nrow(mtcars)-1), .025) * sd(mtcars$mpg)/sqrt(nrow(mtcars)) ## [1] 17.91768 mean(mtcars$mpg) + qt(df = (nrow(mtcars)-1), .975) * sd(mtcars$mpg)/sqrt(nrow(mtcars)) ## [1] 22.26357 不偏分散の不偏とは  推測統計学では一致性（consistency）、不偏性（unbiasedness）、有効性（efficiency）という概念が重要となります。詳しい説明は別の機会に行いますが、不偏分散は不偏性をもつ推定量のことを表します。不偏性とは推定量の期待値が母数と一致する性質になります。標本平均は不偏推定量ですが、標本分散、標本標準偏差は不偏推定量ではありません。つまり、母分散と標本分散にはズレが存在します。このズレを調節するため、n - 1で偏差二乗和を割っています（割る数が-1だけ減るので、標本分散より少し大きくなる）。 4.8 ハンズオンセッション 4.8.1 データの読み込み dat &lt;- read.csv(&quot;../stat_class_2025/sample_data/pokemon_data.csv&quot;) 4.8.1.1 データの中身を確認 summary(dat) ## id 名前 タイプ1 高さ ## Min. : 1 Length:897 Length:897 Min. : 0.100 ## 1st Qu.:225 Class :character Class :character 1st Qu.: 0.500 ## Median :449 Mode :character Mode :character Median : 1.000 ## Mean :449 Mean : 1.186 ## 3rd Qu.:673 3rd Qu.: 1.500 ## Max. :897 Max. :20.000 ## 重さ 世代 ステータス HP ## Min. : 0.10 Min. :1.000 Min. :175.0 Min. : 1 ## 1st Qu.: 8.50 1st Qu.:2.000 1st Qu.:320.0 1st Qu.: 50 ## Median : 27.00 Median :4.000 Median :440.0 Median : 65 ## Mean : 64.03 Mean :4.143 Mean :422.9 Mean : 69 ## 3rd Qu.: 65.00 3rd Qu.:6.000 3rd Qu.:500.0 3rd Qu.: 80 ## Max. :999.90 Max. :8.000 Max. :720.0 Max. :255 ## こうげき ぼうぎょ とくこう とくぼう ## Min. : 5.00 Min. : 5.00 Min. : 10.00 Min. : 20.00 ## 1st Qu.: 55.00 1st Qu.: 50.00 1st Qu.: 46.00 1st Qu.: 50.00 ## Median : 75.00 Median : 67.00 Median : 65.00 Median : 65.00 ## Mean : 76.54 Mean : 71.88 Mean : 69.67 Mean : 69.87 ## 3rd Qu.: 95.00 3rd Qu.: 90.00 3rd Qu.: 90.00 3rd Qu.: 85.00 ## Max. :181.00 Max. :230.00 Max. :173.00 Max. :230.00 ## すばやさ 捕まえやすさ 進化 画像URL ## Min. : 5.00 Min. : 3.00 Min. :0.000 Length:897 ## 1st Qu.: 45.00 1st Qu.: 45.00 1st Qu.:1.000 Class :character ## Median : 65.00 Median : 60.00 Median :1.000 Mode :character ## Mean : 65.93 Mean : 97.85 Mean :1.418 ## 3rd Qu.: 85.00 3rd Qu.:150.00 3rd Qu.:2.000 ## Max. :200.00 Max. :255.00 Max. :3.000 head(dat) ## id 名前 タイプ1 高さ 重さ 世代 ステータス HP こうげき ぼうぎょ ## 1 1 フシギダネ くさ 0.7 6.9 1 318 45 49 49 ## 2 2 フシギソウ くさ 1.0 13.0 1 405 60 62 63 ## 3 3 フシギバナ くさ 2.0 100.0 1 525 80 82 83 ## 4 4 ヒトカゲ ほのお 0.6 8.5 1 309 39 52 43 ## 5 5 リザード ほのお 1.1 19.0 1 405 58 64 58 ## 6 6 リザードン ほのお 1.7 90.5 1 534 78 84 78 ## とくこう とくぼう すばやさ 捕まえやすさ 進化 ## 1 65 65 45 45 1 ## 2 80 80 60 45 2 ## 3 100 100 80 45 3 ## 4 60 50 65 45 1 ## 5 80 65 80 45 2 ## 6 109 85 100 45 3 ## 画像URL ## 1 https://raw.githubusercontent.com/PokeAPI/sprites/master/sprites/pokemon/other/official-artwork/1.png ## 2 https://raw.githubusercontent.com/PokeAPI/sprites/master/sprites/pokemon/other/official-artwork/2.png ## 3 https://raw.githubusercontent.com/PokeAPI/sprites/master/sprites/pokemon/other/official-artwork/3.png ## 4 https://raw.githubusercontent.com/PokeAPI/sprites/master/sprites/pokemon/other/official-artwork/4.png ## 5 https://raw.githubusercontent.com/PokeAPI/sprites/master/sprites/pokemon/other/official-artwork/5.png ## 6 https://raw.githubusercontent.com/PokeAPI/sprites/master/sprites/pokemon/other/official-artwork/6.png 4.8.2 確率分布を選ぶ 4.8.2.1 データの可視化 hist(dat$こうげき) 4.8.2.2 正規分布をあてはめてみる # x軸の範囲を決定 x &lt;- seq(min(dat$こうげき), max(dat$こうげき), length.out = nrow(dat)) #min(dat$こうげき) から max(dat$こうげき) まで、データの数 (nrow(dat)) だけ 等間隔 に区切った値を x に入れる。これを使って、なめらかな曲線を描画するための基準点を作る # ヒストグラムを確率密度で描画 hist(dat$こうげき, probability = TRUE) #probability = TRUE を指定すると、ヒストグラムの y軸が「確率密度」になる。分布をあてはめるときは、この設定をしないと当てはまらない。デフォルト（probability = FALSE）では「度数」（データの数）になる # 正規分布の確率密度関数を描画 lines(x, dnorm(x, mean = mean(dat$こうげき), sd = sd(dat$こうげき)), lwd = 2) #「データの分布が もし正規分布に従っていたら どんな形になるか？」を、ヒストグラムの上に描く。dnorm() は 正規分布 の確率密度関数を計算する。平均 (mean(dat$こうげき)) と 標準偏差 (sd(dat$こうげき)) を使って 「理想的な正規分布」 の形を作る。lwd = 2で線の太さを少し太くする 4.8.3 母分散未知の母平均の95%信頼区間を求める 母平均を得られたデータから推定しよう ポケモンのデータを読み込み、ci関数とqt関数で95%信頼区間求めてみよう。 qt関数では、t値を使い、式を作って計算する必要があります 4.8.4 ci関数 今回の警告メッセージは無視してOK（参考） #install.packages(&quot;gmodels&quot;) library(gmodels) ## Warning: package &#39;gmodels&#39; was built under R version 4.3.3 ci(dat$こうげき) ## Warning in ci.numeric(dat$こうげき): No class or unkown class. Using default ## calcuation. ## Estimate CI lower CI upper Std. Error ## 76.5406912 74.5956429 78.4857395 0.9910493 4.8.5 qt関数 必要なパーツ：平均値、t値、標本標準偏差（本当は\\[{\\sqrt{不偏分散}}\\] = 不偏標準偏差）、サンプル数 sd関数は、標準偏差を算出する関数だが、分母をn-1した値を返している（= 不偏標準偏差） n &lt;- nrow(dat) #サンプル数 m &lt;- mean(dat$こうげき) #平均値 t_value &lt;- qt(df = n - 1, .975) #t値 sd &lt;- sd(dat$こうげき)#標本標準偏差 lower &lt;- m - t_value * sd/sqrt(n) #下限 upper &lt;- m + t_value * sd/sqrt(n) #上限 lower ## [1] 74.59564 upper ## [1] 78.48574 下限はこっちでも同じ値になる t_value_low &lt;- qt(df = n -1, .025) lower2 &lt;- m + t_value_low * sd/sqrt(n) lower2 ## [1] 74.59564 4.9 まとめ "],["統計的検定.html", "Chapter 5 統計的検定 5.1 事前の確認 5.2 今日の目標 5.3 統計的検定（statistical test） 5.4 統計的検定の手順 5.5 統計的検定で必要な知識 5.6 ハンズオンセッション 5.7 次週までの課題 5.8 参考文献", " Chapter 5 統計的検定 5.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 5.2 今日の目標 統計的検定の論理や手順を理解できる t 検定をRで実装し、分析結果を報告することができる 5.3 統計的検定（statistical test） 母数についての推定（例「日本人の男子の平均身長は170 cmだ」）が合っているかを、統計学的に検定する 使用する標本は、母集団から無作為抽出していることを前提にしている = 標本は母集団を代表している 大別して2種類ある パラメトリック検定： 母数（パラメータ）に特定の確率分布の仮定を設ける検定（例 t 検定、分散分析） 注：確率分布の形状を決める値（正規分布の平均と標準偏差など）もパラメータと呼ぶ。本講義ではパラメータは母数ではなく、確率分布を規定する値を指す。 ノンパラメトリック検定：母集団に特定の確率分布を仮定しない検定（例 カイ二乗検定） 5.3.1 統計的検定の論理 母集団からサンプリングした標本から、母数についての推定が合っているかを議論できない。しかし、確率的な範囲であれば、推定が間違っているかを確かめることができる。 標本から計算した95%信頼区間が160 cmから167cmだった場合、母数は170cmよりも小さい（推定は誤り） 標本から計算した95%信頼区間が167 cmから175cmだった場合、推定が合っているか誤りなのか分からない（信頼区間が170 cmを含んでいるから） 推測統計学における統計的検定の論理では、「母数についての等号（ = ）の仮説」が偽であることは言えるが、正しいとは言えない。 「母数の等号についての仮説」を帰無仮説（null hypothesis）と呼ぶ 帰無仮説は以下のように表す（Hはhypothesisの頭文字）\\[H_0: u = 170\\] 統計的検定では、帰無仮説が偽であるかを検定する。 背理法に似た方法であり、証明したい主張の否定の仮説を立て、得られた結果から主張できる結論が「矛盾」であることを示すことで、主張が正しいことを証明する。 例：「世界には白いカラスがいる」と主張したい 「全てのカラスは黒い」という仮説を立てる（帰無仮説） 1羽でも白いカラスが見つかれば、帰無仮説は偽であり、「世界には白いカラスがいる」と主張できる。 仮説が偽と主張する（否定する）方が簡単 対立仮説：帰無仮説の否定 \\[H_1: u ≠ 170\\] 帰無仮説が否定されれば、対立仮説が真となる 帰無仮説が偽であると判断できない場合、帰無仮説は保留になる（= 分からない）。 帰無仮説は真であるということはできない。 5.3.2 統計検定の具体的な考え方 帰無仮説が正しいと仮定する。標本から計算された統計量の実現値が、標本分布から考えて十分低い確率でしか生じないような値であれば、帰無仮説が偽であると判断する 注意点として、選んだ確率モデル（確率分布）が妥当でない場合、検定の結果も妥当ではなくなる。以下の例では、母集団からの標本抽出が正規分布で近似できるという仮定のもと行う。 例： 2025年度にT先生のクラス（40人）で実施された英語テストの平均点は60点であった。昨年度の平均点は55点であり、2025年度の平均点は、昨年度の平均点に比べ十分に高い得点であるかを検定する。 帰無仮説 u = 55の下で、得点が平均パラメータ u = 50の正規分布に従うと仮定。 クラス平均は60点、標準偏差は3であると分かった。 母分散が分からない場合、t 統計量を用いる。 \\[t = \\frac{\\overline{x} - \\mu_0}{\\frac{u}{\\sqrt{n}}}\\] 上記の値を代入し、 \\[t = \\frac{\\overline{60} - 55}{\\frac{3}{\\sqrt{40}}}\\] 計算すると、 t = 10.54となる。このような検定のための統計量を検定統計量という。 (60-55)/(3/sqrt(40)) ## [1] 10.54093 自由度が39（40-1）で95%の範囲は0±2.02であるため、得られたt値がこの絶対値より大きいと棄却域に（青く塗られた箇所）に入ることになる。帰無仮説が真であると仮定したときの検定統計量の標本分布のことを帰無分布（null distribution）という。 棄却域が占める割合を有意水準（significance level）と言い、αと表記する。慣例的に、両側合わせて0.05が用いられる。 qt(0.975, df = (40-1)) ## [1] 2.022691 得られたt値は2.02よりも大きく、棄却域に入る。従って、帰無仮説が真であると考えると、非常に小さい確率でしか起きない結果が得られたという帰無仮説が真であるという仮定と矛盾した結果となっている。この場合、統計的に有意であると表現する。 つまり、「2025年度の平均点60点は、昨年度よりも統計的に高い得点である。」と主張できる。 2025年度の得点が昨年度よりも統計的有意に高いことは、全員の得点が昨年度よりも高いことを必ずしも意味しないということに注意。比較しているのはあくまでも平均点。以下のどちらのデータでも統計的有意差が得られる。 summary(data1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 55.00 58.33 60.27 60.16 62.08 65.36 summary(data2) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 52.88 54.14 57.34 58.11 61.45 66.51 黒い点線は平均値55点 5.4 統計的検定の手順 確率モデルの設定 母数について仮説を立てる。この母数は確率モデル（確率分布）のパラメータと対応しているという仮定が必要。 先行研究の結果、得られたデータの分布などから適切な確率モデルを選ぶ必要がある 帰無仮説の設定 例えば、映画を見ると英単語の学習に効果的だということを調べる場合、映画を見る群と、映画を見ない群を用意する。二つの群の平均値の差が0でなければ、映画を見ることに何らかな効果があると主張できる。この場合、以下のような帰無仮説を立てる。 帰無仮説：二つの群の平均値差は0 検定統計量の設定 有意水準（ α ）の設定 慣例的に言語研究の分野では5%が用いられる。 帰無仮説を偽とする場合でも、最大5%程度はそれが間違えている可能性を表す。 分析の前に決定し、結果を見て有意水準を大きくするのは、研究倫理に反するとみられる可能性が大いにある。 分析の前に0.05よりも大きくすることはよい。 検定統計量の実現値の計算 5.5 統計的検定で必要な知識 5.5.1 p 値 検定統計量を変換し、有意水準と比較しやすくしたもの 検定統計量の実現値が大きいほどp値は小さくなる 上記の手順では、検定統計量の実現値と棄却域の範囲を確認して、帰無仮説が棄却されるかを判断していた。しかし、コンピュータソフトウェアでは、p値が表示され、この値が事前に設定した有意水準よりも大きいかもしくは小さいかを確認して棄却の有無を判断する。 t.test(df$Data1, mu = 55) ## ## One Sample t-test ## ## data: df$Data1 ## t = 12.351, df = 39, p-value = 4.691e-15 ## alternative hypothesis: true mean is not equal to 55 ## 95 percent confidence interval: ## 59.31461 61.00448 ## sample estimates: ## mean of x ## 60.15955 t.test(df$Data2, mu = 55) ## ## One Sample t-test ## ## data: df$Data2 ## t = 4.4932, df = 39, p-value = 6.106e-05 ## alternative hypothesis: true mean is not equal to 55 ## 95 percent confidence interval: ## 56.70752 59.50353 ## sample estimates: ## mean of x ## 58.10553 e-やe+は指数的記法です。6.106e-05であれば、6.106 × 10^(-5)なので、0.を合わせて0が5つ6の前につきます。逆に6.106e+05であれば6.106 × 10^5です。Rではoptions関数で通常の値に戻して表示できます。 options(scipen = 999) t.test(df$Data2, mu = 55) ## ## One Sample t-test ## ## data: df$Data2 ## t = 4.4932, df = 39, p-value = 0.00006106 ## alternative hypothesis: true mean is not equal to 55 ## 95 percent confidence interval: ## 56.70752 59.50353 ## sample estimates: ## mean of x ## 58.10553 5.5.2 統計的検定の誤りと検出力 第一種の誤り（type Ⅰ error） 帰無仮説が真なのに、誤って偽だと主張すること（本当は差がないのに差があると判断する） 有意水準 α の値と一致 統計的検定では、限界点として、100%正しいことは保証されない。有意水準が5%であれば、5%の誤った主張を許すことになる。 第二種の誤り（type Ⅱ error） 帰無仮説が偽なのに、それを偽であると言えない（保留）すること（本当は差があるのに差がないと判断する） β で表す Figure 5.1: image source: https://www.statisticssolutions.com/to-err-is-human-what-are-type-i-and-ii-errors/ 検出力（power） 帰無仮説が偽であるとき、正しく帰無仮説を棄却できる確率 1 - β で表す 統計的検定では、α を維持しながら検出力を高くするのが望ましい 大きい効果ほど、大きい標本サイズほど、統計的有意を検出しやすくなる 有意水準を小さくすると、第二種の誤りが大きくなる = α を小さくすると、β は大きくなる 帰無分布と真の母数の標本分布が離れるため、検出力は、帰無仮説と母平均の差が大きいほど、標本サイズが大きいほど大きくなる。 サンプルサイズ・検定力・有意水準に加え、効果量（effect size）も連動している。効果量は後の講義で詳しく扱うが、簡単に説明すると、関心を持つ事柄の大きさである。4つのうち、3つが分かれば、自動的に残りの1つの値を特定できる。これを利用したのが検定力分析（power analysis）である。これを実験前に使うことで、どれくらいの標本を収集すべきかを検討できる。近年の研究では、参加者の数を検定力分析で決めているかを重視する（査読で！）動きがある。 5.5.3 有意性検定（≒ 統計的検定）の問題点 有意確率（ p &lt; 0.05）だけに結果を頼るのはよくない 無作為抽出を前提としていても、必ず得られた結果に誤差が含まれている 標本サイズに大きく左右される 統計的検定における誤差と問題点の対処法 できるだけ母集団を代表するサンプルを得る 信頼区間を報告する 検定力分析で標本サイズを事前に決める 効果量を報告する 言語研究における効果量は、Neyman-Pearson流の理論に基づくことがほとんど。 5.5.4 頻度論的統計学とベイズ統計学 ここまで説明してきた話 + この講義のほとんどの説明における統計学は、頻度論的統計学（frequentist statistics）と呼ばれる枠組み。 検定において用いる数学的手法が異なる。頻度 vs. ベイズのような「主義の違いによる対立構造」は避けた方がよい 参考: Bayesians are frequentists. 母集団からサンプリングする（標本を抽出する）のは繰り返すことができる試行において起こる事象の相対頻度（frequency）をもとに行われる。例えば、サイコロを14回降って、1の目が3回出た場合、1が出る確率は になる。これを頻度論的確率と呼び、人間の主観や信念に依存しない客観的な確率である。 確率とは無限回試行を行ったときの割合 仮説の評価を p 値を用いて行う 「帰無仮説のもとでデータが得られる確率」を計算する データを追加して再度分析する際、、適切な方法を用いないと、計算されたp 値と有意水準が当初の値から変わってしまう（検定力分析が重要な理由） ベイズ統計学では、主観確率（「明日は30%で晴れるだろう」）と客観確率（「10日3日晴れたから明日は晴れるだろう」）の両方を検定に使用する。 ベイズ統計学では p 値は使わない ベイズ統計では、データを追加して再度分析することはOK（データの二度漬けをしない限り） 頻度論的統計学、ベイズ統計学どちらにおいても、「無作為抽出により標本が母集団を代表している」「母集団からのサンプリングを近似していること」という前提が重要 ベイズ統計学の方が道具的に使いやすいと考えることもできる フローチャート的な統計分析は推奨されません。分析の前に、分析するデータの母集団がどのような形状なのか、この分析方が正しいのかなど十分検討することが重要です。 5.6 ハンズオンセッション 5.6.1 t 検定 t 分布に照らし合わせて、2群の平均値の差を検証する場合に用いる。 平均値だけでなく、分散（データのばらつき）も考慮される 5.6.2 基本用語 5.6.2.1 対応のあり・なし 対応あり（repeated measures）：同じ参加者からの2種類のデータ（例 同じ参加者の国語と英語の点数） 対応なし（independent measures）：異なる参加者からなる2種類のデータ（例 1年生と2年生の英語の点数） 実験群（experimental group）と統制群（control group） 5.6.3 t検定を使用する前提 データの種類：間隔尺度または比例尺度 サンプリング：母集団から無作為抽出され、母集団を十分代表していること 正規性：標本平均の分布が正規分布に従うこと。少々外れている場合は正規性に対して頑健であるためOK。大きく外れている場合はノンパラメトリック版のt検定を検討することも考えれるが、ウェルチのt検定を用いることをできるだけ優先する方がいい場合が多い。ノンパラメトリック検定にも使用する前提がある。 （対応なしの場合のみ）等分散性：比較する2群のデータの分散が等しいこと（= 母分散が等しい集団からデータがサンプリングされていること）。t検定は母分散の等質性に関しても頑健であるため、グループのサンプルサイズが等しい場合、分析結果が歪むことはほとんどない。 ウェルチのt検定を使うのがよい = t 検定の場合基本ウェルチのt 検定を使う （対応なしの場合のみ）観測値の独立性：データがお互いに影響し合い相関が高い場合、第一種の過誤が起こりやすくなる 重要正規性の検定や等分散性の検定を行うことを推奨されることがあるが、このような事前テストは第一種&amp;第二種の過誤の確率を高めることが報告されている（e.g., Rasch et al. [2011]）。そのため、そのような検定を行わず、ウェルチのt 検定を行う方がよい。 5.6.4 t 値の算出 標本平均の標本誤差：差がどれだけ偶然の誤差によって起きるかを推定 偶然起こる誤差おりどの程度大きいかを調べる検定 \\[t\\ =\\ \\frac{観測された標本平均の差}{標本平均の差の標準誤差}\\] 5.6.4.1 対応なし t 検定（サンプルサイズが等しい） \\[ t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}} \\hspace{3pc} (df = n_1 + n_2 - 2) \\] 5.6.4.2 対応なし t 検定（サンプルサイズが異なる） \\[ s_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2} \\] \\[ t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_p^2}{n_1} + \\frac{s_p^2}{n_2}}} \\] 5.6.4.3 対応あり t 検定 \\[ t = \\frac{\\bar{x}_1 - \\bar{x}_2}{S_D / \\sqrt{n}} \\hspace{3pc} (df = n - 1) \\] 5.6.5 Rでの実装 5.6.5.1 対応なし t 検定 データの読み込み dat_t_ind &lt;- read.csv(&quot;../stat_class_2025/sample_data/ttest_inde.csv&quot;) head(dat_t_ind) ## ID Class English ## 1 1 A 85 ## 2 2 A 78 ## 3 3 A 90 ## 4 4 A 82 ## 5 5 A 88 ## 6 6 A 84 length(table(dat_t_ind$ID)) ## [1] 80 boxplot(English ~ Class, data = dat_t_ind) library(psych) describeBy(dat_t_ind$English, group = dat_t_ind$Class) ## ## Descriptive statistics by group ## group: A ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 40 83.03 4.3 83 83 5.93 76 90 14 0.01 -1.25 0.68 ## ------------------------------------------------------------ ## group: B ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 40 60.48 5.73 60 60.44 7.41 50 70 20 0.05 -1.25 0.91 t.test(English ~ Class, data = dat_t_ind) ## ## Welch Two Sample t-test ## ## data: English by Class ## t = 19.911, df = 72.353, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true difference in means between group A and group B is not equal to 0 ## 95 percent confidence interval: ## 20.2925 24.8075 ## sample estimates: ## mean in group A mean in group B ## 83.025 60.475 論文記載例 * 本来であれば、効果量も報告する必要があるが、今回は省略している。 異なる指導法を実施したクラス A とクラス B の英語テストの平均点は、83.03 (SD = 4.3)と 60.48 (SD = 5.73 でクラス A の平均の方が高かった。 t 検定を使って比較した結果、t(72.353) = 19.911, p &lt; .001、 d = xxx [95%CI = xxx, xxx] で、クラスAのほうが統計的に有意に英語テストの成績が高いことがわかった。 p 値は原則実数値報告である（ p = .046）。しかし、値が0.01よりも小さい場合は、p &lt; .001のように報告する。 5.6.5.2 対応あり データの読み込み dat_t_rep &lt;- read.csv(&quot;../stat_class_2025/sample_data/ttest_rep.csv&quot;) head(dat_t_rep) ## ID English Math ## 1 1 85 78 ## 2 2 88 82 ## 3 3 90 85 ## 4 4 92 89 ## 5 5 87 83 ## 6 6 91 86 length(table(dat_t_rep$ID)) ## [1] 40 boxplot(dat_t_rep$English, dat_t_rep$Math, names = c(&quot;English&quot;, &quot;Math&quot;)) describe(dat_t_rep$English) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 40 82.22 8.65 82 82.16 11.86 70 96 26 0.04 -1.67 1.37 describe(dat_t_rep$Math) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 40 75.85 10.02 75.5 75.56 13.34 61 94 33 0.15 -1.47 1.59 paired = Tを設定する t.test(dat_t_rep$English, dat_t_rep$Math, paired = T ) ## ## Paired t-test ## ## data: dat_t_rep$English and dat_t_rep$Math ## t = 21.641, df = 39, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 5.779151 6.970849 ## sample estimates: ## mean difference ## 6.375 論文記載例 * 本来であれば、効果量も報告する必要があるが、今回は省略している。 Aクラスの40名の学生を対象に、英語と数学のテストの得点を比較した。英語の平均点は、82.22 (SD = 8.65)と 75.85 (SD = 10.02)で英語の平均の方が高かった。対応ありの t 検定を使って比較した結果、t(39) = 21.641, p &lt; .001、 d = xxx [95%CI = xxx, xxx] で、英語のほうが統計的に有意に得点が高いことがわかった。 5.7 次週までの課題 5.7.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 （宿題を考える） Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 5.7.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 5.8 参考文献 心理学統計法 放送大学 https://www.isc.meiji.ac.jp/~hirukawa/randomevent/test1.htm 中村 心理学・教育学研究のための効果量入門 平井 et al.  心理学統計の基礎 https://www.note.kanekoshobo.co.jp/n/nf836d37b7f10#61a8e679-85a4-411c-96dd-5a1a37335572 https://x.com/genkuroki/status/1227224899875295234 https://norimune.net/3339 https://statmodeling.stat.columbia.edu/2024/01/08/bayesians-are-frequentists-2/ Rasch, D., Kubinger, K. D., &amp; Moder, K. (2011). The two-sample t test: pre-testing its assumptions does not pay off. Statistical papers, 52, 219-231. .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["week5-相関分析.html", "Chapter 6 Week5: 相関分析 6.1 事前の確認 6.2 今日の目標 6.3 相関分析（Correlation analysis）とは 6.4 ハンズオンセッション 6.5 次週までの課題 6.6 参考文献", " Chapter 6 Week5: 相関分析 6.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 6.2 今日の目標 相関分析に関する統計理論を数学的・概念的に理解できる。 相関分析をRで行い、その結果を解釈し報告することができる。 6.3 相関分析（Correlation analysis）とは 相関：2つのデータの間にある線形の関係の強さを示す。これを分析することを相関分析という 相関関係を確認する際、散布図で視覚的に確認、数値的に相関係数（Correlation coefficienct）が用いられる。 通常、ピアソンの（積率）相関係数（Pearson’s correlation coefficient, r）を指す。値は \\(-1\\leq r \\leq1\\) をとる。 相関係数は2変数の関係が線形になっている場合のみ使用できる。 相関係数の重要なパーツ 共分散（covariance）：各変数の平均からの偏差の積を平均したもの \\[ s_{xy} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) \\] 不偏共分散は以下の通り。相関係数を算出するRパッケージのcorは計算する際に、不偏分散を使用している。 \\[ s_{xy} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) \\] The denominator *n* − 1 is used which gives an unbiased estimator of the (co)variance for i.i.d. observations. 相関係数を求める式 \\[ r_{xy} = \\frac{S_{xy}}{S_xS_y} \\] 共分散（\\(S_{xy}\\)）を2変数それぞれの標準偏差の積で割ったもの（共分散を基準化している） 基準化の理由として、定数倍などすると、値の大きさが変わってしまうため 6.3.1 相関関係の種類 正の相関（positive correlation）：右上がり。1つの変数が増加すると、もう片方も増加する 相関係数が正の値をとる 負の相関（negative correlation）：右下がり。1つの変数が増加すると、yが減少する。 相関係数が負の値をとる ピアソンの相関係数は外れ値に影響されやすい。あらかじめ散布図で外れ値がないかを確認する 以下の図では、左側の図のデータの一部（n = 2）を外れ値に変更した 右側の図の相関係数がわずか2つの外れ値によって大きくなっていることが分かる cor(data2$x, data2$y, method = &quot;pearson&quot;) ## [1] 0.7351905 cor(data4$x, data4$y, method = &quot;pearson&quot;) ## [1] 0.9108736 6.3.2 相関係数の検定 ほとんどの場合、母相関係数 ρ が0という帰無仮説を立てて行われる。 \\[ H_0 : ρ = 0 \\] 検定統計量は t 分布に従うことを利用して検定が行われる。 \\[ t = \\frac{r}{\\sqrt{1-r^2}}\\sqrt{n-2} \\] 統計的に有意である場合、「母相関係数は0である」という帰無仮説を棄却し、「母相関係数は0ではない」という対立仮説を採択する。無相関検定とも呼ぶ。 母相関が0以外である帰無仮説を立てることもできるが、この場合検定統計量 t は 非心 t 分布に従い、 t 分布には従わない。 重要 無相関検定で有意差が得られても、母相関係数が0ではないということを示すだけであり、相関の強弱を示していないことに注意が必要。 6.4 ハンズオンセッション 6.4.1 データの読み込み dat &lt;- read.csv(&quot;../stat_class_2025/sample_data/cor.csv&quot;) head(dat) ## ID English Math Japanese ## 1 1 56 63 53 ## 2 2 55 54 50 ## 3 3 24 43 24 ## 4 4 57 29 59 ## 5 5 49 38 57 ## 6 6 27 38 20 library(psych) describe(dat$English) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 40 49.45 13.19 49 49.31 11.86 24 87 63 0.31 0.27 2.09 describe(dat$Math) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 40 49.5 14.09 51.5 50.34 14.83 15 72 57 -0.49 -0.31 2.23 describe(dat$Japanese) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 40 49.35 13.41 49.5 49.62 14.08 20 74 54 -0.19 -0.61 2.12 6.4.2 散布図の作成 plot(dat$English, dat$Math) plot(dat$English, dat$Japanese) psych::pairs.panels(dat[,2:4]) 6.4.3 相関係数の算出 corr.test関数は、上述のcor関数を使用している。 psych::corr.test(dat[,2:4], method = &quot;pearson&quot;) ## Call:psych::corr.test(x = dat[, 2:4], method = &quot;pearson&quot;) ## Correlation matrix ## English Math Japanese ## English 1.00 0.64 0.69 ## Math 0.64 1.00 0.43 ## Japanese 0.69 0.43 1.00 ## Sample Size ## [1] 40 ## Probability values (Entries above the diagonal are adjusted for multiple tests.) ## English Math Japanese ## English 0 0.00 0.00 ## Math 0 0.00 0.01 ## Japanese 0 0.01 0.00 ## ## To see confidence intervals of the correlations, print with the short=FALSE option cor.testを使用するとより詳細な結果が返ってくる library(stats) cor.test(dat$English, dat$Math, method = &quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: dat$English and dat$Math ## t = 5.1734, df = 38, p-value = 0.000007715 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4143074 0.7951314 ## sample estimates: ## cor ## 0.6428501 6.4.4 相関係数の解釈 6.4.4.1 相関係数の大きさ Cohenの基準と呼ばれるベンチマークがある。しかし、これはもともとすべての分野に適応することを意図したものではなく、行動科学分野の研究に基づき作成されたものであった。 小（small）： .10、中（Medium）：.30、大（Large）：.50 相関係数の値の大きさは文脈（e.g., 研究分野や研究対象）において解釈する必要がある。 例）リーディングのテスト得点とリスニングのテスト得点が r = .50の場合と、聞いた音を書きだすテストの得点と聴解のテスト得点が r = .50 第二言語習得研究における相関係数の目安として提示された例 “For correlation coefficients, we suggest that rs close to .25 be considered small, .40 medium, and .60 large. These values correspond roughly to the 25th, 50th, and 75th percentiles in our primary and meta-analytic samples.” (Plonsky &amp; Oswald, 2014) 相関係数が小さい研究は査読の段階で削除されていたり、そもそも出版されずお蔵入りになっている場合もあるので注意。 6.4.4.2 因果関係の主張 相関分析では関係の強さの程度しか分からない。相関があることは必ずしも因果関係があることを示しているわけではない。 e.g., チョコレートの消費量とノーベル賞受賞者の数に相関がみられた チョコレートを沢山食べると優秀な人材が育つんだね（✖ チョコレート→ ノーベル賞） 第三の変数（共変量）による疑似相関の可能性もある チョコの例も、「豊かさ」による疑似相関かもしれない 疑似相関の例：アイスクリームとビールの売り上げにおける「気温」、年収の高さと血圧における「年齢」 第三の変数を考慮した相関係数の計算は回帰分析の回で扱います 因果関係を調べるための条件 ジョン・スチュアート・ミルは、以下の3つの条件を提示した 原因 X が結果 Y よりも時間的に先行している 原因 X と結果 Y に共変関係がある 他の因果的説明が排除されている 6.4.5 論文への記載 検証する変数が多い場合、表として提示すると分かりやすい。 特に焦点を当てたい個所を本文で言及する。 表 1 英語、数学、日本語のテスト得点の記述統計と相関係数、95%信頼区間 Variable M SD 1 2 1. English 49.45 13.19 2. Math 49.50 14.09 .64** [.41, .80] 3. Japanese 49.35 13.41 .69** [.48, .82] .43** [.14, .65] 注. * p &lt; .05. ** p &lt; .01. 3つのテスト得点の間には、統計的有意な相関関係がみられた（表1）。英語と日本語の相関係数が最も高く（r = .69 95% CI [.48-.82], t(38) = 5.90, p &lt; .001）、数学と日本語の相関係数が最も低かった（r = .43, 95% CI [.14-.65], t(38) = 2.93, p = .006）。 6.5 次週までの課題 6.5.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 （宿題を考える） Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 6.5.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 6.6 参考文献 心理学統計法 放送大学 心理学・教育学研究のための効果量入門 平井 et al.  外国語教育ハンドブック 心理統計 Plonsky, L., &amp; Oswald, F. L. (2014). How big is “big”? Interpreting effect sizes in L2 research. Language learning, 64(4), 878-912. Messerli, F. H. (2012). Chocolate consumption, cognitive function, and Nobel laureates. N Engl J Med, 367(16), 1562-1564. https://www.pref.yamaguchi.lg.jp/soshiki/22/101008.html .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["単回帰分析連続型の説明変数.html", "Chapter 7 単回帰分析（連続型の説明変数） 7.1 今後の修正案 7.2 事前の確認 7.3 今日の目標 7.4 回帰分析（regression analysis）とは 7.5 ハンズオンセッション 7.6 次週までの課題 7.7 参考文献", " Chapter 7 単回帰分析（連続型の説明変数） 7.1 今後の修正案 最小二乗法の話だけをするのであれば、lmを一貫して使った方がいい？でも正規分布なら一致するからglmを使ってもいい？？ 興味深い資料： https://qiita.com/s-nakagawa2/items/c01650b49fbda218a73d#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE https://note.com/kiyo_ai_note/n/n8112cc3a665b 7.2 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 7.3 今日の目標 回帰分析の統計理論を数学的・概念的に理解できる 回帰分析（独立変数が連続値）をRで実装し、その結果を可視化などを通して説明できる 7.4 回帰分析（regression analysis）とは データに回帰直線をあてはめ、そこから得られた予測値や残差をもとにデータを解釈する方法 青い線が回帰直線 7.4.1 回帰分析の種類 線形モデル（Linear Model） 正規分布を仮定 最小二乗法で推定 一般化線形モデル（generalized linear model） 正規分布以外を仮定できる 最尤推定法で推定 一般化線形混合（効果）モデル（generalized linear mixed model） 正規分布以外を仮定でき、個体差や場所差などを考慮に入れる 最尤推定法で推定 7.4.2 変数の名前 独立変数（independent variable）：説明変数や予測変数とも呼ばれる。予測に用いられる変数 x 従属変数（dependent variable）：目的変数や基準変数とも呼ばれる。予測される方の変数 y 7.4.3 最小二乗法 以下の一次式で表される \\[ \\hat{y} = a + bx \\] 傾き（ b ）：変数 x の1単位の差異に対応する y の予測値の差異の大きさ。回帰係数（regression coefficient） とも呼ばれる。 変数 x の単位を把握しておくことが重要。標準化すると、1標準偏差あたりに変換できる 切片（ a ） 回帰直線が実際のデータに最もよく適合するように計算される。計算方法として最小2乗法（least squares method）が1例としてあげられる。 \\[ b = r\\frac{S_y}{S_x} \\] \\[ a = \\hat{y} - b\\bar{x} \\] 回帰直線の式に上記の式を代入。x が平均 \\(\\bar{x}\\) に等しいとき、 y の予測値 \\(\\hat{y}\\) は y の平均 \\(\\bar{y}\\) に等しくなる。= 回帰直線は、点（\\(\\bar{x}\\), \\(\\bar{y}\\)）を通る傾き b の直線 \\[ \\hat{y} = (\\bar{y} - b\\bar{x}) + bx\\\\ \\hspace{0em} = \\bar{y} + b(x - \\bar{x}) \\] 最小2乗法以外にも最尤推定法があり、前者は手元のデータに当てはめることを考え、後者はこのデータが出てくる確率が一番高くなるように、確率分布のパラメータを考える。どちらの基準を用いても推定値はほぼ同じ値になる。誤差が独立していて、正規分布していれば、最小二乗法と最尤推定は等価になる。最尤推定法は正規分布以外の確率分布にも適用できるため、最尤推定法の方がより用いられる（最小2乗法は2つの変数の直接的な関係を仮定するため、線形ではない回帰モデルでは最小2乗法が使えない場合がある）。 最小二乗法：lm関数 stats::lm(mtcars$mpg ~ mtcars$cyl, weights = NULL) ## ## Call: ## stats::lm(formula = mtcars$mpg ~ mtcars$cyl, weights = NULL) ## ## Coefficients: ## (Intercept) mtcars$cyl ## 37.885 -2.876 最尤推定法：glm関数 iteratively reweighted least squaresを用いて最尤推定している stats::glm(mtcars$mpg ~ mtcars$cyl) ## ## Call: stats::glm(formula = mtcars$mpg ~ mtcars$cyl) ## ## Coefficients: ## (Intercept) mtcars$cyl ## 37.885 -2.876 ## ## Degrees of Freedom: 31 Total (i.e. Null); 30 Residual ## Null Deviance: 1126 ## Residual Deviance: 308.3 AIC: 169.3 7.4.4 ベイズ推定 最尤法の代わりに使う方法。 最小2乗法、最尤推定法：「点」を推定 =&gt; 1つの値を返す ベイズ推定：「幅」（分布）を推定。事後分布を返す。この分布の一番高い個所を「点」として報告することもできる マルコフ連鎖モンテカルロ法（MCMC）によって得られた乱数のサンプルを使って推定する。 ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: mpg ~ cyl ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 32 ## predictors: 2 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 37.9 2.2 35.0 37.9 40.6 ## cyl -2.9 0.3 -3.3 -2.9 -2.4 ## sigma 3.3 0.4 2.8 3.3 3.9 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 20.1 0.8 19.0 20.1 21.1 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 3670 ## cyl 0.0 1.0 3563 ## sigma 0.0 1.0 2742 ## mean_PPD 0.0 1.0 3683 ## log-posterior 0.0 1.0 1537 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). ベイズ推定では、事前分布を指定する。つまり、最小2乗法や最尤推定法を使う場合と異なり、得られたデータだけでなく、事前の知識を反映して分析できる。 変数 xにより狭い事前分布を設定平均が0、標準偏差が0.2 ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: mpg ~ cyl ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 32 ## predictors: 2 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 22.1 1.6 20.0 22.2 24.2 ## cyl -0.3 0.2 -0.6 -0.3 -0.1 ## sigma 5.7 0.8 4.7 5.6 6.7 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 20.1 1.4 18.3 20.1 21.9 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 2937 ## cyl 0.0 1.0 2991 ## sigma 0.0 1.0 2402 ## mean_PPD 0.0 1.0 3316 ## log-posterior 0.0 1.0 1638 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). 異なる事前分布を持つ回帰モデルから得られた事後分布の描画 より狭い事前分布をおくと、事前分布が推定に与える影響が、広い事前分布の場合より大きくなる。 広い、狭い = 標準偏差の大きさ 注 事前分布を狭く指定しない場合、頻度統計の結果もベイズ統計の結果も近似する。 ベイズ推定では、事前分布の設定を行ったり、サンプリングが適切に行われたかを確認する手順が必要である。今回は推定の紹介だけで、今後詳しい設定法などに言及する。 7.4.5 回帰分析における予測値と残差 残差（residual）：予測の誤差ともいう。それぞれの観測値と直線の差のこと。つまり、\\(e = y - \\hat{y}\\) 。 残差の平均は0 残差と変数 x の相関は0 予測値 \\(\\hat{y}\\) と残差の相関は0 予測値は変数 x を線形下もので、相関係数の絶対値は変わらないから 前のセクションで述べた 最小2乗法は残差を2乗して足し合わせた残差平方和が最小になるように計算を行う 7.4.5.1 デモ HPを従属変数、こうげきを独立変数として単回帰分析を実行し、resという変数に格納する res &lt;- lm(dat$HP ~ dat$こうげき) ## ## Call: ## lm(formula = dat$HP ~ dat$こうげき) ## ## Residuals: ## Min 1Q Median 3Q Max ## -73.432 -13.565 -3.125 8.740 212.873 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 38.08851 2.15454 17.68 &lt;0.0000000000000002 *** ## dat$こうげき 0.40381 0.02625 15.38 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.32 on 895 degrees of freedom ## Multiple R-squared: 0.2092, Adjusted R-squared: 0.2083 ## F-statistic: 236.7 on 1 and 895 DF, p-value: &lt; 0.00000000000000022 残差の平均を計算 mean(res$residuals) ## [1] -0.0000000000000008983663 残差と変数 x の相関を計算 cor(res$residuals, dat$こうげき) ## [1] -0.000000000000000009412816 残差と予測値の相関を計算 cor(res$residuals, res$fitted.values) ## [1] 0.000000000000000144472 R で計算すると、理論的には 0 になるはずの値が浮動小数点演算の誤差により完全に 0 にならないことがあります(参考)。 7.4.5.2 変数の直行分解と残差の意義 残差の式は以下のように書き換えられる。 \\[ y = \\hat{y} + e \\] 前のセクションで示したように、右辺の二つは無相関である。従って、従属変数を無相関の成分に分解する式であると言える。相関がない2変数は「互いに直交する」ともいえる。つまり、上記の式は、直行分解の式である。 独立変数と残差が無相関であるという性質により、「従属変数 yの成分のうち、独立変数 x とは相関の無い残差成分」を取り出すことが可能になる。 つまり、残差は単なるズレではなく、従属変数のうち独立変数とは関係しない部分を表している 残差と誤差は異なる。「誤差」は求めようとする真の回帰式（母集団などのように神様しか知らない）から算出される値と実際のデータとの差を表す。真の回帰式は理論的なものであるため誤差を計算では求められない。「残差」は実際のデータを用いて推定された回帰式から算出される値と実際のデータとの差を指し、計算で求められる。 7.4.5.2.1 ポケモンのHPとこうげきの例 ポケモンのHPをこうげき変数で予測する（「こうげき」の値が大きいポケモンはHPも高そう） こうげき：150 HP：105 残差は「HPのうち、こうげきでは説明できない成分」 残差が正の大きな値：「こうげきから予測されるレベルよりもHPがかなり高いポケモン」 HPの平均と当該ポケモンのHP ## [1] 68.99666 ## [1] 255 こうげきの平均と当該ポケモンのこうげき ## [1] 76.54069 ## [1] 10 残差が負の大きな値：「こうげきから予測されるレベルよりもHPがかなり低いポケモン」 HPの平均と当該ポケモンのHP ## [1] 68.99666 ## [1] 1 こうげきの平均と当該ポケモンのこうげき ## [1] 76.54069 ## [1] 90 残差（変数）はHPそのものとは意味内容が異なる（「こうげきから予測されるHPよりも高いか低いか」を示している）。HPそのものが高いポケモンでも、こうげきが高ければ残差の値は大きくならない。また、HPそのものが低くても、こうげきのわりにはHPが高ければ残差は大きくなる。 残差に注目することで、もともとの変数間の関係を調べるだけでは知ることのできなかったより本質的な関係が明らかになる可能性がある 7.4.6 回帰直線の当てはまりの良さ 相関係数の2乗のことを分散説明率とよぶことがある。また、独立変数がどれだけ従属変数の値を決定するかを表していることから、決定係数（coefficient of determination: \\(R^{2}\\)）とも呼ばれる。高いほどよい（高すぎても予測の点から問題はある）。 \\[ R^{2} = 1 - \\frac{SS_e}{SS_y} \\] \\(SS_e\\)：残差の2乗和 \\(SS_y\\)：目的変数の偏差2乗和 0-1（0-100%）の間の値をとる 調整済決定係数（Adjusted R-squared）：独立変数の数が多い場合、その影響の大きさに関わらず、決定係数が大きくなる。その欠点を補ったもの summary(res) ## ## Call: ## lm(formula = dat$HP ~ dat$こうげき) ## ## Residuals: ## Min 1Q Median 3Q Max ## -73.432 -13.565 -3.125 8.740 212.873 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 38.08851 2.15454 17.68 &lt;0.0000000000000002 *** ## dat$こうげき 0.40381 0.02625 15.38 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.32 on 895 degrees of freedom ## Multiple R-squared: 0.2092, Adjusted R-squared: 0.2083 ## F-statistic: 236.7 on 1 and 895 DF, p-value: &lt; 0.00000000000000022 7.4.7 回帰係数の有意性 帰無仮説（独立変数の係数が0）を t 分布をもとに検定 7.4.8 回帰分析を使う際の注意点 係数の数値は”Effects”ではなく、“Comparison” 「係数がXXという数値が得られた。従って、ZZ増えると、変数 y は上がる/下がる」という主張は、不正確な場合がほとんど。回帰分析は「説明」と「予測」のどちらにも用いられるが、変数 x から変数 y への→を（「説明」）主張するにはその他の手続きが必要となる。 予測（実用的）：応用的な状況で有用な意思決定を行うために結果や行動の予測する 説明（理論的）：理論の検証や発展のために現象の性質を理解したり説明したりする 決定係数の値が高く、よく適合していることと、そのモデル内の回帰係数が「因果効果の良い推定値」かどうかは、本質的には別の問題 予測変数と目的変数に線形の関係がある 十分なサンプルサイズが必要 検定力分析で事前に決定する 外れ値がないか 残差の独立性があるか 残差に相関がある場合、残差の独立性が満たされていない 時系列など時間に関わるデータはこれが満たされない場合が多い（株価のデータなど） 残差の等分散性があるか 残差に何らかの傾向があるとモデルが誤っていると判断する 残差が正規分布しているか 回帰モデルは独立変数が正規分布していることを前提としていない。また、従属変数が正規分布していることを仮定しているわけではなく、regression errorが正規分布していることを仮定している。 7.5 ハンズオンセッション 7.5.1 データの読み込み 英語テストの得点が従属変数、独立変数が英語学習歴の長さ dat &lt;- read.csv(&quot;../stat_class_2025/sample_data/simp_reg.csv&quot;) 7.5.2 読み込んだデータの確認 head(dat, 5) ## student mid end quiz ## 1 S001 77 NA 36 ## 2 S002 54 47 28 ## 3 S003 73 65 31 ## 4 S004 63 60 26 ## 5 S005 44 62 24 記録されていないデータ（セルにNA）がないかを確認する complete.cases(dat) ## [1] FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [13] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [37] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [49] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [73] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [85] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [97] TRUE TRUE TRUE TRUE subset(dat, complete.cases(dat) == FALSE) ## student mid end quiz ## 1 S001 77 NA 36 NAが入っている行を削除 dat.2 &lt;- na.omit(dat) 削除されているか再度確認 subset(dat.2, complete.cases(dat.2) == FALSE) ## [1] student mid end quiz ## &lt;0 rows&gt; (or 0-length row.names) summary(dat) ## student mid end quiz ## Length:100 Min. :16.00 Min. : 5.00 Min. : 3.00 ## Class :character 1st Qu.:46.75 1st Qu.:46.50 1st Qu.:20.00 ## Mode :character Median :57.00 Median :57.00 Median :26.00 ## Mean :56.91 Mean :54.21 Mean :26.61 ## 3rd Qu.:68.25 3rd Qu.:64.50 3rd Qu.:33.25 ## Max. :92.00 Max. :92.00 Max. :49.00 ## NA&#39;s :1 散布図で外れ値がないかを確認。par(pty=\"s\")を実行することで、正方形の図として描画される。 par(pty=&quot;s&quot;) plot(dat.2$mid, dat.2$end, xlim = c(0, 100), ylim = c(0, 100), xlab = &quot;Mid-term&quot;, ylab = &quot;Final&quot;, ) 外れ値 データの大部分の傾向と異なるもので、必ずしも誤りとは限らないが、データ集計や分析の際にその存在が結果の精度を悪化させる可能性があるもの。 何を外れ値とするかは研究の目的やデータ収集の状況による。今回はマハラノビスの距離を用いて、行う例を紹介する。 d &lt;- mahalanobis(dat.2[,2:3], apply(dat.2[,2:3], 2, mean), cov(dat.2[, 2:3])) n &lt;- nrow(dat.2) v &lt;- ncol(dat.2[, 2:3]) outliers &lt;- n * (n - v) / ((n ^ 2 - 1) * v) * d &gt; qf(0.9, n, v) par(pty=&quot;s&quot;) plot(dat.2[, 2:3], pch = ifelse(outliers, 16, 21), xlim = c(0, 100), ylim = c(0, 100), xlab = &quot;Mid-term&quot;, ylab = &quot;Final&quot; ) 外れ値の除去 dat.3 &lt;- dat.2[-which(outliers == TRUE),] par(pty=&quot;s&quot;) plot(dat.3[, 2:3], xlim = c(0, 100), ylim = c(0, 100), xlab = &quot;Mid-term&quot;, ylab = &quot;Final&quot; ) 7.5.3 変数間の相関の確認 cor(x = dat.3$mid, y = dat.3$end) ## [1] 0.7532885 7.5.4 回帰分析の実施 最小二乗法 model.ls &lt;- lm(end ~ mid, data = dat.3) summary(model.ls) ## ## Call: ## lm(formula = end ~ mid, data = dat.3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -24.2474 -5.4599 -0.7961 5.0888 26.6908 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 14.5133 3.7623 3.858 0.000208 *** ## mid 0.7257 0.0650 11.164 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.314 on 95 degrees of freedom ## Multiple R-squared: 0.5674, Adjusted R-squared: 0.5629 ## F-statistic: 124.6 on 1 and 95 DF, p-value: &lt; 0.00000000000000022 最尤推定法 model.mlm &lt;- glm(end ~ mid, data = dat.3) summary(model.mlm) ## ## Call: ## glm(formula = end ~ mid, data = dat.3) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 14.5133 3.7623 3.858 0.000208 *** ## mid 0.7257 0.0650 11.164 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 86.74516) ## ## Null deviance: 19051.4 on 96 degrees of freedom ## Residual deviance: 8240.8 on 95 degrees of freedom ## AIC: 712.16 ## ## Number of Fisher Scoring iterations: 2 決定係数 r_2 &lt;- 1 - model.mlm$deviance/model.mlm$null.deviance r_2 ## [1] 0.5674435 performance::r2(model.mlm) ## R2: 0.567 自由度調整済決定係数 \\[ 1 - \\frac{n-1}{n-p}(1-R^2) \\] n &lt;- nrow(dat.3) p &lt;- length(coef(model.mlm)) -1 # 切片を抜いた変数の数 1 - ((1 - r_2) * (n - 1)) / (n - p - 1) ## [1] 0.5628903 ベイズ推定 model.b &lt;- stan_glm(end ~ mid, data = dat.3, refresh = 0, seed = 123) summary(model.b) ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: end ~ mid ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 97 ## predictors: 2 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 14.4 3.8 9.6 14.5 19.2 ## mid 0.7 0.1 0.6 0.7 0.8 ## sigma 9.4 0.7 8.6 9.4 10.3 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 55.1 1.4 53.4 55.1 56.9 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.1 1.0 4001 ## mid 0.0 1.0 4069 ## sigma 0.0 1.0 3172 ## mean_PPD 0.0 1.0 3946 ## log-posterior 0.0 1.0 1876 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). 7.5.5 結果の解釈 par(pty=&quot;s&quot;) plot(dat.3[, 2:3], xlim = c(0, 100), ylim = c(0, 100), xlab = &quot;Mid-term&quot;, ylab = &quot;Final&quot; ) abline(model.mlm) 信頼区間も可視化 最尤推定法 stats::confint(model.ls, level = 0.95) ## 2.5 % 97.5 % ## (Intercept) 7.0442767 21.982321 ## mid 0.5966093 0.854701 ベイズ推定 rstanarm::posterior_interval(model.b, prob = 0.95)[&quot;mid&quot;, ] ## 2.5% 97.5% ## 0.5979704 0.8552482 new &lt;- data.frame(mid = seq(1, 100, 1)) pred &lt;- stats::predict(model.mlm, newdata = new, se.fit = T, level = 0.95, type = &quot;response&quot;) confidence &lt;- data.frame( fit = pred$fit, lower = pred$fit - 1.96 * pred$se.fit, upper = pred$fit + 1.96 * pred$se.fit ) 点線が95%信頼区間 par(pty=&quot;s&quot;) plot(dat.3[, 2:3], xlim = c(0, 100), ylim = c(0, 100), xlab = &quot;Mid-term&quot;, ylab = &quot;Final&quot; ) abline(model.ls) lines(new$mid, confidence[, 2], lty = 3) lines(new$mid, confidence[, 3], lty = 3) 7.5.6 モデルの診断 予測値と残差の散布図（x軸 = 予測値、y軸 = 残差） 点は、点線に対して、ランダムに散らばっていればよい。赤い線は残差を説明する回帰曲線で、点線（残差0の線）と重なっているほど良いモデル。 残差の絶対値が大きいデータフレームの行番号を表示している par(pty=&quot;s&quot;) plot(model.mlm, which = 1) Q-Q（quantile-quantile）プロット（x軸 = 標準正規分布の分位点、y軸 = 残差の分位点） 正規分布であれば、点線に重なる 残差の絶対値が大きいデータフレームの行番号を表示している わかりやすいアニメーション（参考） par(pty=&quot;s&quot;) plot(model.mlm, which = 2) acf関数で残差の独立性を確認 自己相関係数：一つ前のデータとの相関を示す。Lagはデータの数の半分になる 引数にplot = Tでコレログラムを描画 ラグ0は係数1になる。 青い点線は帰無仮説「自己相関係数が0」の95%信頼区間。この中に線が収まっていれば、自己相関がないと判断する stats::acf(model.mlm$residuals, plot = F) ## ## Autocorrelations of series &#39;model.mlm$residuals&#39;, by lag ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 1.000 0.142 0.054 -0.046 -0.292 -0.214 -0.338 -0.053 0.014 0.009 0.208 ## 11 12 13 14 15 16 17 18 19 ## 0.181 0.047 0.125 -0.118 -0.020 -0.185 -0.086 -0.018 -0.095 stats::acf(model.mlm$residuals, plot = T) 論文への記載 中間試験の得点から学期末試験の得点を予測するため、回帰分析を行った。その結果、係数は統計的に有意であった（b = 0.73 [0.60, 0.85], SE = 0.07, p &lt; .001）。係数は分散の57 %を説明していた（\\(R^2\\) = 56.7 %, 調整 \\(R^2\\) = 56.2 %）。 （結果に対し謙虚）平均して、中間試験の得点が1点差の学生を比較した際、中間試験の得点が1点高い学生は、低い学生に比べ、期末試験の得点が0.73点高い。 （因果関係を匂わせており不正確）中間試験の得点が1点高くなるほど、期末試験の得点は0.73点高くなる 7.6 次週までの課題 7.6.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 （宿題を考える） Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 7.6.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 7.7 参考文献 心理学統計法 放送大学 平井 et al.  心理学統計の基礎 https://stackoverflow.com/questions/23992032/sum-of-residuals-using-lm-is-non-zero https://takehiko-i-hayashi.hatenablog.com/entry/2017/09/27/105559 https://bellcurve.jp/statistics/course/9704.html 言葉と数式で理解する多変量解析入門 https://oroshi.me/2021/01/lsm http://www.ner.takushoku-u.ac.jp/masano/class_material/waseda/keiryo/R34_MLE.html#1_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%97%E6%B3%95%E3%81%A8%E6%9C%80%E5%B0%A4%E6%B3%95%E3%81%AE%E9%81%95%E3%81%84 Gelman et al., Regression and other stories https://zenn.dev/tatamiya/articles/0d9a79260ebb42#lm-%E9%96%A2%E6%95%B0%E3%81%AE%E5%AE%9F%E8%A3%85%E3%82%92%E3%81%A9%E3%81%86%E3%82%84%E3%81%A3%E3%81%A6%E8%BE%BF%E3%82%8B%E3%81%8B%EF%BC%9F Rによる教育データ分析入門 https://www.stat.go.jp/training/2kenkyu/ihou/72/pdf/2-2-723.pdf https://hira-labo.com/archives/1806 https://qiita.com/kenmatsu4/items/59605dc745707e8701e0 心理学的研究における重回帰分析の適用に関わる諸問題 .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["week7-重回帰分析.html", "Chapter 8 Week7: 重回帰分析 8.1 メモ 8.2 事前の確認 8.3 今日の目標 8.4 重回帰分析とは 8.5 重回帰分析を行う上での注意点 8.6 投入方 8.7 ハンズオンセッション 8.8 次週までの課題 8.9 参考文献", " Chapter 8 Week7: 重回帰分析 8.1 メモ 重回帰分析の係数の解釈にきを付ける。ある変数の影響を0にした際の影響であることを示す 8.2 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 8.3 今日の目標 8.4 重回帰分析とは 単回帰分析：変数が1つ \\[ \\hat{y} = a + bx \\] 重回帰分析：変数が2つ以上 \\[ \\hat{y} = a + {b_1}{x_1} + {b_2}{x_2} + {b_3}{x_3} \\] 8.4.1 偏回帰係数 重回帰式における回帰係数：偏回帰係数（partial regression coefficient） 他の独立変数の影響を取り除いた（一定にした）、ある独立変数の従属変数への影響力 平均化された 1 単位の比較 e.g., “When comparing two children whose mother have the same level of education, the child whose mother is x IQ points higher is predicted to have a test score is 6x higher, on average. (Gelman et al., 2020, pp. 134) 変数間で単位が異なる場合、従属変数、独立変数をすべて標準化することで、標準化偏回帰係数（standardized partial regression coefficient）を算出し、変数間の影響力を比較する （標準化）偏回帰係数は、従属変数と独立変数の因果関係を示すわけではないことに注意 8.4.2 重相関係数と決定係数 重相関係数（multiple correlation coefficient） 全ての独立変数から得られた、従属変数との相関を表す指標 単回帰の場合は、相関係数の2乗が決定係数 調整済み決定係数（Adjusted R-squared） 独立変数の数が多いほど、重相関係数の値が大きくなる（インフレする）ため、修正を加えた値 8.4.3 独立変数の有意性 個々の独立変数が従属変数の予測に有意に寄与するかは t 分布を用いて検定する 帰無仮説：ある独立変数の係数は0 8.4.4 回帰式の有意性（ F 検定） すべての偏回帰係数は0であるという帰無仮説を立て、 F 値をもとに検定を行う F 値（分散比）：モデルの分散を自由度で割った値（平均平方和）÷ モデルの誤差分散を自由度で割った値（平均誤差分散） F 検定が有意でない場合、モデルからの予測値は実際の値と大きく異なることを示す 8.5 重回帰分析を行う上での注意点 8.5.1 サンプルサイズ 明確な基準はなく、目標とする効果量や実験項目の数などによって異なる 検定力分析を行い、実験や調査を行う前に事前に決定することが望まれる 8.5.2 多重共線性（multicolinearity） 独立変数間の相関関係が高いと、偏回帰係数を正しく推定することができない 注意点 (Multicollinearity should not be confused with a raw strong correlation between predictors. What matters is the association between one or more predictor variables, conditional on the other variables in the model.) From (https://rdrr.io/cran/performance/man/check_collinearity.html) 多重共線性の問題がないかを確認するための3指標。分析前に閾値を設定し、論文内でも多重共線性の判断をどのようにするか明記しておくとよい 許容度（tolerance）：値が 0.1以下で多重共線性があると判断される VIF（variance inflation factor）： 論文でよく見る指標。許容度の逆数で、5-10以上だと多重共線性だと判断。 条件指数（condition index）：15以上で強い多重共線性があると判断 8.5.3 外れ値 回帰直線は外れ値に大きく影響する 外れ値を調べる代表的な4指標 残差：各データの残差を標準値に変換し、± 2標準偏差もしくは ± 3以上の割合を調べる クックの距離：データが回帰式全体に与える影響を示す指標。1以上で問題ありと判断される てこ比：各ケースにおける複数の変数データが全体の平均からどの程度ずれているかの指標。平均てこ比の3倍以上の値を取る場合問題ありと判断される。 平均てこ比：独立変数の数 + 1 ÷ サンプルサイズ マハラノビス距離：複数の独立変数における各データの平均と各ケースのデータの距離を示す指標。マハラノビスの表を参考に判断する（マハラノビスとてこ比を両方使う必要はない）。 8.5.4 残差の独立性、正規性、等分散、線形性 残差の独立性：どの独立変数の残差間にも相関がないという前提。 残差の正規性：残差の散布図やヒストグラムなどで確認できる 残差の等分散性：独立変数がどの値の場合でも残差分散が同じである必要がある 残差の線形性：残差と予測値には線形関係がある必要がある。散布図などで確認 https://www.note.kanekoshobo.co.jp/n/n9624e14dda8e#733dd8a6-e3c2-4767-8e8b-7a50ae6eeaf4 https://www.jstage.jst.go.jp/article/jjpsy/92/3/92_92.19226/_pdf 8.6 投入方 重回帰分析の場合、独立変数を入れる順序で書く独立変数の有意性や偏回帰係数が変化する。 どの方法を用いるのかは研究の目的によっても異なる。基本的に、分析の前に決めておく方がよい。 8.6.1 強制投入法 理論や仮説に基づいて慎重に選んだすべての独立変数を1度に含めてモデルを作成する。 独立変数を増やすほど決定係数は大きくなることに注意 8.6.2 階層的投入法 階層的回帰分析とも言われる。理論や仮説に基づいて、独立変数を1つずつ投入していく。段階的にモデルに含めるため、各独立変数がどの程度決定係数の向上に影響を与えているか把握できる（強制投入法のあとに階層的投入法を行うなど）。 8.6.3 ステップワイズ法 統計的回帰分析とも呼ばれる。統計的に最も予測率が高いと考えられる変数から順に自動的に投入される。従属変数と相関の高い独立変数が投入され、その後偏回帰係数の有意性が次に最も高くなる独立変数が選ばれ順に投入される。 階層的投入法では、分析者が投入する順番を決めるが、ステップワイズ法では予測率に応じて自動で投入される。従ってその結果が理論や仮説に基づいて選ばれたモデルになるとは限らない 8.6.4 変数減少法 すべての独立変数を投入し、予測への寄与が小さい独立変数から順に変数を抜いていく 8.7 ハンズオンセッション 強制投入法、ステップワイズ法のやり方を確認 8.7.1 データの読み込み library(readr) dat &lt;- read_csv(&quot;../stat_class_2025/sample_data/regression_data.csv&quot;) ## Rows: 120 Columns: 8 ## ── Column specification ─────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (8): ID, Placement, FirstT, MidT, LastT, EndT, Class, Course ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. 必ず中身を確認。 head(dat) ## # A tibble: 6 × 8 ## ID Placement FirstT MidT LastT EndT Class Course ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 15 35 84 85 90 1 2 ## 2 2 29 17 72 76 85 1 2 ## 3 3 17 45 64 54 70 1 1 ## 4 4 77 59 42 48 34 0 0 ## 5 5 54 31 20 10 13 0 0 ## 6 6 51 18 52 34 15 1 1 8.7.2 基本統計量の算出 library(psych) describe(dat) ## vars n mean sd median trimmed mad min max range skew ## ID 1 120 60.50 34.79 60.5 60.50 44.48 1 120 119 0.00 ## Placement 2 120 54.20 28.50 50.5 54.61 37.81 4 99 95 -0.02 ## FirstT 3 120 54.19 24.00 54.0 54.22 31.13 10 99 89 0.02 ## MidT 4 120 50.79 25.30 52.0 51.08 31.13 4 100 96 -0.09 ## LastT 5 120 50.50 24.53 47.5 49.68 27.43 6 100 94 0.28 ## EndT 6 120 52.50 25.18 53.0 52.74 31.13 6 98 92 -0.05 ## Class 7 120 0.66 0.48 1.0 0.70 0.00 0 1 1 -0.66 ## Course 8 120 0.97 0.81 1.0 0.96 1.48 0 2 2 0.06 ## kurtosis se ## ID -1.23 3.18 ## Placement -1.32 2.60 ## FirstT -1.15 2.19 ## MidT -1.12 2.31 ## LastT -0.99 2.24 ## EndT -1.13 2.30 ## Class -1.58 0.04 ## Course -1.48 0.07 8.7.3 データの図示 箱ひげ図 boxplot(dat[, 2:6], xlab = &quot;Test&quot;, ylab = &quot;Score&quot;, ylim = c(0, 100) # y軸を0から100の範囲で表示する ) 蜂群図 #install.packages(&quot;beeswarm&quot;, dependencies = T) #一度やればOK library(beeswarm) beeswarm(dat[, 2:6]) 箱ひげ図 + 蜂群図 boxplot(dat[, 2:6], xlab = &quot;Test&quot;, ylab = &quot;Score&quot;, ylim = c(0, 100)) beeswarm(dat[, 2:6], add = T #箱ひげ図の上に描画すると明示的に記す ) 8.7.4 相関関係の確認 高い相関関係を示す独立変数はない psych::corr.test(dat[, 2:6]) ## Call:psych::corr.test(x = dat[, 2:6]) ## Correlation matrix ## Placement FirstT MidT LastT EndT ## Placement 1.00 0.02 -0.36 -0.09 -0.30 ## FirstT 0.02 1.00 0.26 0.08 0.37 ## MidT -0.36 0.26 1.00 0.43 0.85 ## LastT -0.09 0.08 0.43 1.00 0.53 ## EndT -0.30 0.37 0.85 0.53 1.00 ## Sample Size ## [1] 120 ## Probability values (Entries above the diagonal are adjusted for multiple tests.) ## Placement FirstT MidT LastT EndT ## Placement 0.00 0.99 0.00 0.99 0 ## FirstT 0.80 0.00 0.02 0.99 0 ## MidT 0.00 0.00 0.00 0.00 0 ## LastT 0.33 0.40 0.00 0.00 0 ## EndT 0.00 0.00 0.00 0.00 0 ## ## To see confidence intervals of the correlations, print with the short=FALSE option psych::pairs.panels(dat[, 2:6]) 8.7.5 重回帰分析の実施（強制投入法） lm()関数を使用する。 重回帰分析の結果をoutput_forcedという変数に格納する output_forced &lt;- lm( EndT ~ # 従属変数 Placement + FirstT + MidT + LastT, # 独立変数 data = dat # データセット ) summary()で結果を確認 プレイスメントテストの係数が有意ではなく、年度末模試の予測に適さない可能性が示唆された。 Adjusted R-squaredの結果を確認すると、4つの独立変数で従属変数の77.6%を説明 summary(output_forced) ## ## Call: ## lm(formula = EndT ~ Placement + FirstT + MidT + LastT, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.999 -6.532 0.373 7.884 39.006 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -2.11492 4.42429 -0.478 0.63354 ## Placement -0.03101 0.04154 -0.747 0.45684 ## FirstT 0.18318 0.04749 3.857 0.00019 *** ## MidT 0.69883 0.05334 13.101 &lt; 0.0000000000000002 *** ## LastT 0.21533 0.04960 4.341 0.0000306 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.91 on 115 degrees of freedom ## Multiple R-squared: 0.7839, Adjusted R-squared: 0.7764 ## F-statistic: 104.3 on 4 and 115 DF, p-value: &lt; 0.00000000000000022 8.7.6 外れ値の診断 分析結果からresid()関数で残差を算出し、その値をscale()関数で標準化 res &lt;- resid(output_forced) z.res &lt;- scale(res) boxplot(z.res) - 最大値、最小値の2つが外れ値の可能性あり describe(z.res) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 120 0 1 0.03 0.01 0.95 -2.56 3.33 5.9 -0.03 0.45 0.09 olsrr関数を使うと、様々な図を一度に表示可能 #install.packages(&quot;olsrr&quot;) library(olsrr) ## Warning: package &#39;olsrr&#39; was built under R version 4.3.3 ## ## Attaching package: &#39;olsrr&#39; ## The following object is masked from &#39;package:datasets&#39;: ## ## rivers ols_plot_diagnostics(output_forced) 8.7.7 多重共線性の確認 多重共線性の問題はなさそう VIF: 5以上のものはない 許容度：0.1以下のものもない 条件指数（Condirion Index）：全て15以下 ols_coll_diag(output_forced) ## Tolerance and Variance Inflation Factor ## --------------------------------------- ## Variables Tolerance VIF ## 1 Placement 0.8502943 1.176063 ## 2 FirstT 0.9170130 1.090497 ## 3 MidT 0.6539385 1.529196 ## 4 LastT 0.8049192 1.242361 ## ## ## Eigenvalue and Condition Index ## ------------------------------ ## Eigenvalue Condition Index intercept Placement FirstT ## 1 4.40535969 1.000000 0.00298802134 0.007522632 0.0068745860846 ## 2 0.30501018 3.800437 0.00164204177 0.365472991 0.0000002735316 ## 3 0.15650328 5.305532 0.00006369806 0.046463119 0.5262904224956 ## 4 0.08687444 7.121061 0.01599506848 0.103299519 0.3709362786036 ## 5 0.04625240 9.759409 0.97931117036 0.477241738 0.0958984392846 ## MidT LastT ## 1 0.005788082 0.006945791 ## 2 0.123931389 0.044863293 ## 3 0.003523541 0.394117664 ## 4 0.620787643 0.517410058 ## 5 0.245969345 0.036663194 8.7.8 重回帰分析の実施（ステップワイズ法） step()関数を用いる。この関数では、AIC（Akaike’s Information Criterion）の値が最も低い（= 最も良いモデル）が選択される。 AICが最も小さくなる変数をモデルから削除していった結果が出力される -変数名：その変数を抜いたモデルの結果 none：すべての変数を含めたモデル output_step &lt;- stats::step(output_forced) ## Start: AIC=599.41 ## EndT ~ Placement + FirstT + MidT + LastT ## ## Df Sum of Sq RSS AIC ## - Placement 1 79.0 16384 597.99 ## &lt;none&gt; 16305 599.41 ## - FirstT 1 2109.1 18414 612.00 ## - LastT 1 2672.0 18977 615.62 ## - MidT 1 24332.6 40637 706.99 ## ## Step: AIC=597.99 ## EndT ~ FirstT + MidT + LastT ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 16384 597.99 ## - FirstT 1 2038.4 18422 610.06 ## - LastT 1 2613.6 18997 613.75 ## - MidT 1 29590.9 45974 719.80 Placementを抜いたモデルの結果 中間試験のみで約71%のデータを説明している（0.71 × 100） summary(output_step) ## ## Call: ## lm(formula = EndT ~ FirstT + MidT + LastT, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -30.995 -6.820 0.491 7.669 38.131 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4.14790 3.48037 -1.192 0.235773 ## FirstT 0.17853 0.04699 3.799 0.000233 *** ## MidT 0.71384 0.04932 14.474 &lt; 0.0000000000000002 *** ## LastT 0.21220 0.04933 4.302 0.0000355 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.88 on 116 degrees of freedom ## Multiple R-squared: 0.7828, Adjusted R-squared: 0.7772 ## F-statistic: 139.4 on 3 and 116 DF, p-value: &lt; 0.00000000000000022 8.7.9 結果の報告の仕方 プレイスメントテスト、前期試験、中間模試、および後期試験の得点から年度末試験の得点を予測するために、ステップワイズ法による重回帰分析を行った。その結果、中間模試、後期試験、および前期試験の得点が予測に有意で、この3つの変数のモデルは従属変数の分散の78% ( \\(R^2\\) = .783.調整 \\(R^2\\) = .777)を説明しており、かなり予測率が高いといえる。なかでも、中問試験のみによって分散の71%を説明していた。 8.8 次週までの課題 8.8.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 （宿題を考える） Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 8.8.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 8.9 参考文献 平井 et al.  外国語教育ハンドブック 南風原 https://bellcurve.jp/statistics/course/24461.html?srsltid=AfmBOoq5YejCPBlcGOIawwi-sCV98ib6WvQKuCNEhshmn1IzwdR7JhyV Gelman et al., 2021. regression and Other Stories .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["week8-重回帰分析-2.html", "Chapter 9 Week8: 重回帰分析 (2) 9.1 事前の確認 9.2 今日の目標 9.3 分散分析 9.4 分散分析と回帰分析の関係 9.5 分散分析は今回扱いません 9.6 重回帰分析での質的変数の扱い方 9.7 ハンズオン・セッション 9.8 検定の繰り返し問題アゲイン 9.9 解決策 9.10 次週までの課題 9.11 参考文献", " Chapter 9 Week8: 重回帰分析 (2) 9.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 9.2 今日の目標 9.3 分散分析 9.3.1 t 検定覚えてますか？ 2つのデータの平均値の差を t 分布を用いて検定する。 e.g., Aグループの英語テストの平均点 vs. Bグループの英語テストの平均点（対応なし） e.g., Aグループの英語テストの平均点 vs. Aグループの国語テストの平均点（対応あり） 9.3.2 検定の繰り返し 3つのデータを比較する場合 e.g., Aグループの英語テストの平均点 vs. Bグループの英語テストの平均点 vs. Cグループの英語テストの平均点 グループ間の平均点の差を検定したい A vs. B A vs. C B vs. C 検定における有意水準 検定結果は、5 %（有意水準 5%と設定する場合）の間違いの可能性を含む（第一種の誤り） 帰無仮説が真なのに、誤って偽だと主張すること（本当は差がないのに差があると判断する） Figure 9.1: image source: https://www.statisticssolutions.com/to-err-is-human-what-are-type-i-and-ii-errors/ 検定を繰り返すことの問題 第一種の誤りの確率が当初設定した数値よりも大きくなってしまう 同時に帰無仮説が2つ以上成立する場合に問題となる 上記の例では帰無仮説（「AとBに差はない」 + 「AとCに差はない」 + 「BとCに差はない」）のいずれか一つが棄却されればよい。 1回の検定で帰無仮説が保留される確率 = 95 %（1 - 0.05 (有意水準)） 3回の検定で全て保留される確率 = 0.95 × 0.95 × 0.95 = 0.857 = 86 % 3回の中でいずれか一つが棄却される確率 1 - 0.857 = 0.142 = 約 14% 当初の値の3倍近くまでエラーが膨張！ 同じデータに対して複数回検定を行うこともエラー率を高める 留学から帰ってきた学生に質問紙（100項目）を配布し、留学前と留学後でどの項目に差がみられるか確認する \\[ 1 - (1 - 0.05)^{100} = 99.4 % \\] - 同じ参加者のリーディング、リスニング、スピーキングテストそれぞれに2群の t 検定 「AとBの比較を行う。正規性の確認のために正規分布かを検定し、その後、等分散性を検定でさらに確認し、 t 検定を行った。」も検定の多重性の問題に該当する。この場合、AもBのデータもそれぞれ正規分布に従うという二つの帰無仮説を成立させる必要がある。またいくつかの検定を通過させ、条件（都合）に合う検定を選ぶことにもなる。 9.3.3 検定の多重性を考慮する 多重比較補正を行う 有意水準を調整する ボンフェロー二補正、ホルム補正など ボンフェロー二補正 有意水準の値を厳しくする 3回繰り返す場合、毎回の有意差を 0.05 / 3 = 0.017 新しいサンプルを集める e.g., リーディングテストとは別のサンプルを集めて、リスニングテストの検定を行う 3群以上の比較が可能な分析を使う 分散分析など 9.4 分散分析と回帰分析の関係 前の週では、量的変数による重回帰を扱った。しかし、重回帰分析では、質的変数（e.g., 性別、クラス）同士、量的変数と質的変数などのデータを扱う場合もある。 独立変数が一つ：単回帰分析 独立変数が二つ以上：重回帰分析 独立変数が質的（独立変数の数は関係ない）：分散分析 分散分析に、量的変数（共変量）を加える：共分散分析 9.5 分散分析は今回扱いません 9.5.1 理由 1 当該分野で分散分析を行っている論文をほとんど見なくなったから 2010年代前半までの研究では分散分析が多いです。 僕は授業以外で分散分析をやったことがありません 9.5.2 理由 2 分散分析よりも自由に分析が行える（理由1に関連している） 分散分析は独立変数として質的変数を仮定するが、実際には量的変数との交互作用を検討したい場面が多い 過去の研究を見ると、量的変数を質的変数に変換する手立てが取られたりした（語彙サイズを得点をもとに、閾値を求めて低・中・高にしたり） 後半で扱う一般化線形混合効果モデルでは、様々な確率分布、ランダムな誤差を考慮できる 分散分析と同じような平均値の比較を行うことが可能 質的変数のコーディング 分散分析は統計学の教科書であれば必ず登場します。それほど学習する必要性のある内容で、今後説明する回帰モデルでの質的変数の扱いでも、分散分析の考え方を理解しておくと理解しやすいです。しかし、本講義は統計学以外にプログラミング言語の習得まで扱うため、時間的制約があります。そのため、やむを得ずシラバスから削除しました(´;ω;｀)。自分が使わなくても以前の研究を読む際に必要になることもあり得ますよね。 9.6 重回帰分析での質的変数の扱い方 9.6.1 変数のコーディング 指導法A、Bなどの変数はそのまま分析することができない。その為、数値のデータをあてはめて分析を行う（データを変換する）。この手立てを変数を△△コーディングするという。 今回扱うコーディングにより、分析結果の係数の数値の意味が異なるため、重回帰分析の肝となる内容である。 言語研究で使われる頻度が高いコーディング法 set.seed(123) # 再現性のための乱数設定 # サンプルサイズ n &lt;- 20 # 疑似データの作成 df &lt;- data.frame( ID = 1:n, Method = factor(rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), length.out = n)), # 3つの指導法を割り当て Score = round(runif(n, min = 50, max = 100), 1) # 50-100の範囲でランダムに得点を生成 ) # データの表示 print(df) ## ID Method Score ## 1 1 A 64.4 ## 2 2 B 89.4 ## 3 3 C 70.4 ## 4 4 A 94.2 ## 5 5 B 97.0 ## 6 6 C 52.3 ## 7 7 A 76.4 ## 8 8 B 94.6 ## 9 9 C 77.6 ## 10 10 A 72.8 ## 11 11 B 97.8 ## 12 12 C 72.7 ## 13 13 A 83.9 ## 14 14 B 78.6 ## 15 15 C 55.1 ## 16 16 A 95.0 ## 17 17 B 62.3 ## 18 18 C 52.1 ## 19 19 A 66.4 ## 20 20 B 97.7 トリートメント・コントラスト（treatment contrasts） 別名ダミーコーディング 基準のグループと、それ以外の各グループを比較 contr.treatment(水準数)関数（statsパッケージ） library(stats) contrasts(df$Method) &lt;- contr.treatment(3) 指導法Aが基準となる（0） 指導法AとB、指導法AとCの比較 df$Method ## [1] A B C A B C A B C A B C A B C A B C A B ## attr(,&quot;contrasts&quot;) ## 2 3 ## A 0 0 ## B 1 0 ## C 0 1 ## Levels: A B C 係数の方向（正/負）も重要 切片：基準の指導法Aの平均値 Method 2: 指導法B - 指導法A Method 3: 指導法C - 指導法A results &lt;- lm(Score ~ Method, data = df) results$coefficients ## (Intercept) Method2 Method3 ## 79.014286 9.185714 -15.647619 # 各指導法の平均を確認 aggregate(Score ~ Method, data = df, FUN = mean) ## Method Score ## 1 A 79.01429 ## 2 B 88.20000 ## 3 C 63.36667 サム・コントラスト（sum contrasts） 全グループの平均の平均値（GM: grand mean）と1が割り当てられたデータを比較 contr.sum(水準数)関数（statsパッケージ） library(stats) contrasts(df$Method) &lt;- contr.sum(3) 指導法Cが比較から除外（0） 指導法Aと全体平均、指導法Bと全体平均の比較 df$Method ## [1] A B C A B C A B C A B C A B C A B C A B ## attr(,&quot;contrasts&quot;) ## [,1] [,2] ## A 1 0 ## B 0 1 ## C -1 -1 ## Levels: A B C 係数の方向（正/負）も重要 切片： GM Method 1: 指導法A - GM Method 2: 指導法B - GM results_sum &lt;- lm(Score ~ Method, data = df) results_sum$coefficients ## (Intercept) Method1 Method2 ## 76.860317 2.153968 11.339683 tmp &lt;- aggregate(Score ~ Method, data = df, FUN = mean) GM &lt;- mean(tmp$Score) GM ## [1] 76.86032 反復コントラスト（repeated contrasts） 隣接する2つのグループを比較する 上・中・下の場合、上 vs. 中、中 vs. 下 contr.sdif(水準数)関数（MASSパッケージ） library(MASS) ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:olsrr&#39;: ## ## cement ## The following object is masked from &#39;package:sm&#39;: ## ## muscle ## The following object is masked from &#39;package:patchwork&#39;: ## ## area ## The following object is masked from &#39;package:dplyr&#39;: ## ## select contrasts(df$Method) &lt;- contr.sdif(3) 指導法Aと指導法B、指導法Bと指導法Cの比較 df$Method ## [1] A B C A B C A B C A B C A B C A B C A B ## attr(,&quot;contrasts&quot;) ## 2-1 3-2 ## A -0.6666667 -0.3333333 ## B 0.3333333 -0.3333333 ## C 0.3333333 0.6666667 ## Levels: A B C 分数表示 contrasts(df$Method) &lt;- fractions(contr.sdif(3)) df$Method ## [1] A B C A B C A B C A B C A B C A B C A B ## attr(,&quot;contrasts&quot;) ## 2-1 3-2 ## A -2/3 -1/3 ## B 1/3 -1/3 ## C 1/3 2/3 ## Levels: A B C 係数の方向（正/負）も重要 切片： GM Method 2-1: 指導法B - 指導法A Method 3-2: 指導法C - 指導法B results_rep &lt;- lm(Score ~ Method, data = df) results_rep$coefficients ## (Intercept) Method2-1 Method3-2 ## 76.860317 9.185714 -24.833333 全体のコーディングの比較   Treatment Sum Repeat Predictors Estimates p Estimates p Estimates p (Intercept) 79.01 &lt;0.001 76.86 &lt;0.001 76.86 &lt;0.001 Method [2] 9.19 0.187 11.34 0.010 Method [3] -15.65 0.038 Method [1] 2.15 0.589 Method2-1 9.19 0.187 Method3-2 -24.83 0.002 Observations 20 20 20 R2 / R2 adjusted 0.432 / 0.365 0.432 / 0.365 0.432 / 0.365 他にも多項コントラスト、ヘルムートコントラストなど 変数の順番を並び替える方法 factor()関数を使う df$Method &lt;- factor(df$Method, levels = c(&quot;C&quot;, &quot;A&quot;, &quot;B&quot;)) 研究課題に合わせてコーディング法を選ぶ必要があり、またどのコーディングを使用したか、どの数値をどのデータにあてはめたのかを報告する必要がある。 参加者内/参加者間のデータかは関係ない。 以上のどのコーディング法でも、水準数 - 1が計算される 9.7 ハンズオン・セッション ポケモンのデータセットの中身を減らしたもの library(readr) dat &lt;- read_csv(&quot;../stat_class_2025/sample_data/week8_data.csv&quot;) ## New names: ## Rows: 46 Columns: 17 ## ── Column specification ## ─────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; chr (3): 名前, タイプ1, 画像URL dbl (14): ...1, id, 高さ, 重さ, 世代, ステータス, HP, ## こうげき, ぼうぎょ, とくこう, とくぼう, すばやさ, 捕まえ... ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or ## set `show_col_types = FALSE` to quiet this message. ## • `` -&gt; `...1` 9.7.1 データの概要 今回は、重さ、タイプ1、世代の三つに関心があると仮定する データ構造の分かりやすさを優先しており、モデル自体の妥当性は考慮していないことに注意 head(dat, 5) ## # A tibble: 5 × 17 ## ...1 id 名前 タイプ1 高さ 重さ 世代 ステータス HP こうげき ぼうぎょ ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 7 ゼニガメ… みず 0.5 9 1 314 44 48 65 ## 2 2 55 ゴルダッ… みず 1.7 76.6 1 500 80 82 78 ## 3 3 61 ニョロゾ… みず 1 20 1 385 65 65 65 ## 4 4 73 ドククラ… みず 1.6 55 1 515 80 70 65 ## 5 5 79 ヤドン…… みず 1.2 36 1 315 90 65 65 ## # ℹ 6 more variables: とくこう &lt;dbl&gt;, とくぼう &lt;dbl&gt;, すばやさ &lt;dbl&gt;, ## # 捕まえやすさ &lt;dbl&gt;, 進化 &lt;dbl&gt;, 画像URL &lt;chr&gt; library(psych) describe(dat$重さ) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 46 47.32 72.65 25.7 31.56 28.84 0.8 398 397.2 3 10.25 10.71 boxplot(dat$重さ) table(dat$タイプ1) ## ## ノーマル みず ## 22 24 boxplot(dat$重さ~ dat$タイプ1) aggregate(重さ ~ タイプ1, data = dat, FUN = mean) ## タイプ1 重さ ## 1 ノーマル 25.11818 ## 2 みず 67.67500 table(dat$世代) ## ## 1 2 3 ## 17 12 17 boxplot(dat$重さ~ dat$世代) aggregate(重さ ~ 世代, data = dat, FUN = mean) ## 世代 重さ ## 1 1 52.37059 ## 2 2 48.25833 ## 3 3 41.61176 9.7.2 2水準のコーディング 世代間の重さの比較をトリートメントコントラストコーディングで検討 トリートメントコントラスト ノーマルタイプを基準にする 水準の順番を確認 factor(dat$タイプ1) ## [1] みず みず みず みず みず みず みず みず ## [9] みず みず みず みず みず みず みず みず ## [17] みず みず みず みず みず みず みず みず ## [25] ノーマル ノーマル ノーマル ノーマル ノーマル ノーマル ノーマル ノーマル ## [33] ノーマル ノーマル ノーマル ノーマル ノーマル ノーマル ノーマル ノーマル ## [41] ノーマル ノーマル ノーマル ノーマル ノーマル ノーマル ## Levels: ノーマル みず コーディングする際は、Factor型になっている必要がある class(dat$タイプ1) ## [1] &quot;character&quot; Factor型に変更する dat$タイプ1 &lt;- factor(dat$タイプ1) class(dat$タイプ1) ## [1] &quot;factor&quot; トリートメントコントラストコーディングを実施 contrasts(dat$タイプ1) &lt;- contr.treatment(2) ノーマルが基準となっている contrasts(dat$タイプ1) ## 2 ## ノーマル 0 ## みず 1 (単)回帰分析の実施 results_tr &lt;- lm(重さ ~ タイプ1, data = dat) みずタイプポケモンの方が、平均して42.56kg ノーマルポケモンよりも重いこと。 summary(results_tr) ## ## Call: ## lm(formula = 重さ ~ タイプ1, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -65.77 -39.55 -18.87 14.76 330.33 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.12 14.96 1.679 0.1003 ## タイプ12 42.56 20.72 2.054 0.0459 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 70.18 on 44 degrees of freedom ## Multiple R-squared: 0.08752, Adjusted R-squared: 0.06678 ## F-statistic: 4.22 on 1 and 44 DF, p-value: 0.04592 報告の例 ポケモンの重さを、ポケモンのタイプでどの程度予測できるかを調査するため、回帰分析を行った。その結果、ポケモンのタイプは重さを統計的有意に予測していた。しかし、決定係数の値は8.8%、調整済決定係数は6.7%と予測力は大きくなかった。トリートメントコントラストコーディングでノーマルタイプを基準に（ノーマル = 0、みず = 1）比較すると、みずタイプのポケモンはノーマルタイプのポケモンよりも42.56 kg平均して重いことが予想される。 9.7.3 3水準のコーディング 反復コントラストコーディングで世代間の重さを比較 dat$世代 &lt;- factor(dat$世代) contrasts(dat$世代) &lt;- fractions(contr.sdif(3)) contrasts(dat$世代) ## 2-1 3-2 ## 1 -2/3 -1/3 ## 2 1/3 -1/3 ## 3 1/3 2/3 （単）回帰分析 results_repe &lt;- lm(重さ ~ 世代, data = dat) summary(results_repe) ## ## Call: ## lm(formula = 重さ ~ 世代, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -50.57 -39.24 -18.99 1.69 356.39 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.414 11.083 4.278 0.000103 *** ## 世代2-1 -4.112 27.963 -0.147 0.883773 ## 世代3-2 -6.647 27.963 -0.238 0.813252 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 74.17 on 43 degrees of freedom ## Multiple R-squared: 0.004202, Adjusted R-squared: -0.04211 ## F-statistic: 0.09073 on 2 and 43 DF, p-value: 0.9134 世代1と3を比較するためコーディングを変更 dat$世代 &lt;- factor(dat$世代, levels = c(&quot;1&quot;, &quot;3&quot;, &quot;2&quot;)) contrasts(dat$世代) ## 3 2 ## 1 0 0 ## 3 1 0 ## 2 0 1 contrasts(dat$世代) &lt;- fractions(contr.sdif(3)) 世代2-1：世代3 - 世代1 世代3-2：世代2 - 世代3 results_repe2 &lt;- lm(重さ ~ 世代, data = dat) summary(results_repe2) ## ## Call: ## lm(formula = 重さ ~ 世代, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -50.57 -39.24 -18.99 1.69 356.39 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.414 11.083 4.278 0.000103 *** ## 世代2-1 -10.759 25.439 -0.423 0.674455 ## 世代3-2 6.647 27.963 0.238 0.813252 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 74.17 on 43 degrees of freedom ## Multiple R-squared: 0.004202, Adjusted R-squared: -0.04211 ## F-statistic: 0.09073 on 2 and 43 DF, p-value: 0.9134 報告の例 ポケモンの重さを、ポケモンの世代でどの程度予測できるかを調査するため、回帰分析を行った。その結果、ポケモンの世代は重さを統計的有意に予測していなかった。しかし、決定係数の値は0.42%、調整済決定係数はマイナスの値を示していた。さらに、F 検定に有意差は見られなかった。世代間の比較においても、有意差がみられるペアはなかった。 9.8 検定の繰り返し問題アゲイン t 検定から分散分析の接続で取り上げたりしますが、 t 検定に限った話ではなく、これから先の分析でも、帰無仮説と付き合うのであれば、向き合っていく必要のあるテーマです。常に意識しましょう。 9.8.1 重回帰分析における検定 検定の多重性は、第一種の過誤を高めてしまうことが問題 重回帰分析で使用される検定として二つある（モデル比較の際にはさらに検定を行う） モデル全体: F 検定 回帰モデル自体の有意性を検定。帰無仮説「すべての偏回帰係数がゼロ」 各係数 各係数は t 値をもとに検定が行われている 2水準と3水準では、係数の数がそれぞれ1と2となり、水準が増えるほど検定を繰り返すことになる 同じ参加者に対し、英語と日本語で実験を行い、言語別のデータセットを作成。それらに重回帰分析を行うと、検定を繰り返していることになります。この場合、モデルに言語変数を入れ、下位検定で多重比較を行って言語ごとの影響を確認します。 各係数での検定の繰り返しの問題は、この分野ではあまり問題にされることが少ないと思います。しかし、シミュレーションを行うと、係数の p 値がインフレするのを確認できるのも事実です。 9.9 解決策 9.9.1 p 値の補正 p_adjust()関数 lm()関数で作成したモデルを使用する。 補正法： Romano-Wolf stepdown（初期値）, Bonferroni, Bonferroni-Holm, and Benjamini-Hochberg corrections, etc… #install.packages(&quot;hdm&quot;) library(hdm) ## Warning: package &#39;hdm&#39; was built under R version 4.3.3 results_sum_RM &lt;- p_adjust(results_sum, method = &quot;bonferroni&quot;) 補正後 results_sum_RM[,2] ## (Intercept) Method1 Method2 ## 0.000000000000004800219 1.000000000000000000000 0.029708515524948679587 補正前 summary(results_sum)[[&quot;coefficients&quot;]][,4] ## (Intercept) Method1 Method2 ## 0.000000000000001600073 0.588539274664316103269 0.009902838508316226529 補正では第2種の誤りが大きくなるのを防げないというシミュレーション結果もある 9.9.2 ベイズ統計 検定の繰り返しは、帰無仮説検定を行う頻度統計における問題。 以前使用したbrm()関数を使用。 contrasts(dat$タイプ1) &lt;- contr.sum(2) library(brms) ## Loading &#39;brms&#39; package (version 2.20.4). Useful instructions ## can be found by typing help(&#39;brms&#39;). A more detailed introduction ## to the package is available through vignette(&#39;brms_overview&#39;). ## ## Attaching package: &#39;brms&#39; ## The following objects are masked from &#39;package:rstanarm&#39;: ## ## dirichlet, exponential, get_y, lasso, ngrps ## The following object is masked from &#39;package:psych&#39;: ## ## cs ## The following object is masked from &#39;package:stats&#39;: ## ## ar results_sum_bayes &lt;- brm( 重さ ~ タイプ1, # 応答変数「重さ」と説明変数「タイプ1」の回帰モデル data = dat, # データフレーム dat を使用 family = gaussian(), # 正規分布（ガウス分布）を仮定 prior = prior(normal(0, 10)), # 事前分布として平均0、標準偏差10の正規分布を設定 chains = 4, # MCMCの独立した4つのチェーンを使用 iter = 5000, # 総サンプリング回数（各チェーンあたり5000回） warmup = 500, # ウォームアップ（バーンイン）期間として最初の500回を破棄 thin = 2, # 2回ごとに1つのサンプルを取得（間引き） seed = 123, # 乱数シードを設定し、再現性を確保 refresh = 0 ) ## Compiling Stan program... ## Start sampling summary(results_sum_bayes) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: 重さ ~ タイプ1 ## Data: dat (Number of observations: 46) ## Draws: 4 chains, each with iter = 5000; warmup = 500; thin = 2; ## total post-warmup draws = 9000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 44.17 9.96 24.97 63.71 1.00 8205 8555 ## タイプ11 -10.21 7.28 -24.50 4.07 1.00 8493 8029 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 70.50 7.49 57.58 86.81 1.00 8154 7938 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 9.10 次週までの課題 9.10.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 Week 7の内容も踏まえ、以下のデータを基に重回帰分析を行いましょう 外れ値のデータが入っていることに注意です Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 9.10.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 9.11 参考文献 平井 et al.  外国語教育ハンドブック 南風原 https://bellcurve.jp/statistics/course/24461.html?srsltid=AfmBOoq5YejCPBlcGOIawwi-sCV98ib6WvQKuCNEhshmn1IzwdR7JhyV https://home.hirosaki-u.ac.jp/pteiki/r/3pecification/multiplecomp/ Plonsky, L., &amp; Oswald, F. L. (2017). Multiple regression as a flexible alternative to ANOVA in L2 research. Studies in Second Language Acquisition, 39(3), 579-592. 水本篤. (2009). 複数の項目やテストにおける検定の多重性: モンテカルロ・シミュレーションによる検証. 外国語教育メディア学会機関誌, 46, 1-19. https://yukiyanai.github.io/jp/classes/econometrics1/contents/R/multiple-comparison.html#%E5%A4%9A%E9%87%8D%E6%AF%94%E8%BC%83%E8%A3%9C%E6%AD%A3%E3%81%AE%E8%A8%88%E7%AE%97%E6%B3%95 小島ますみ（2022）. 外国語教育研究における（一般化）線形混合モデル：仮説に適したコーディング・モデリングを中心に The 2021 Annual Conference on Vocabulary Acquisition .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["week9-重回帰分析-3交互作用の解釈.html", "Chapter 10 Week9: 重回帰分析 (3)：交互作用の解釈 10.1 事前の確認 10.2 今日の目標 10.3 交互作用 10.4 ハンズオンセッション 10.5 最後に 10.6 次週までの課題 10.7 参考文献", " Chapter 10 Week9: 重回帰分析 (3)：交互作用の解釈 10.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 10.2 今日の目標 10.3 交互作用 2つ以上の独立変数の組み合わせが従属変数にもたらす影響 質的変数はトリートメント・コーディングを行ったと仮定 一般化線形モデルでは、「説明変数同士の積」を説明変数として加えることで、交互作用を表現する 10.3.1 量的変数 × 量的変数 model1 &lt;- brm(sales ~ product * clerk, gaussian(link = &quot;identity&quot;), data = dat, seed = 123, refresh = 0, iter = 5000, chains = 2) ## Compiling Stan program... ## Start sampling 緑色（平均値）の線、赤色の線は右肩上がりになっている plot(eff, plot = F)[[1]]   sales Predictors Estimates CI (95%) Intercept 88.19 63.23 – 112.05 product -2.26 -3.01 – -1.51 clerk 6.49 2.01 – 11.02 product:clerk 1.05 0.91 – 1.19 Observations 100 R2 Bayes 0.967 量的 × 量的変数の交互作用の予測値 切片 + Product × (-2.26) + Clerk × (6.49) + （Product × Clerk） × 1.05 店員数（Clerk）によって、製品数（Product）の係数の値が変化する #gfrwsufewz table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #gfrwsufewz thead, #gfrwsufewz tbody, #gfrwsufewz tfoot, #gfrwsufewz tr, #gfrwsufewz td, #gfrwsufewz th { border-style: none; } #gfrwsufewz p { margin: 0; padding: 0; } #gfrwsufewz .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: 100%; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #gfrwsufewz .gt_caption { padding-top: 4px; padding-bottom: 4px; } #gfrwsufewz .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #gfrwsufewz .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #gfrwsufewz .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gfrwsufewz .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gfrwsufewz .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gfrwsufewz .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #gfrwsufewz .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #gfrwsufewz .gt_column_spanner_outer:first-child { padding-left: 0; } #gfrwsufewz .gt_column_spanner_outer:last-child { padding-right: 0; } #gfrwsufewz .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #gfrwsufewz .gt_spanner_row { border-bottom-style: hidden; } #gfrwsufewz .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #gfrwsufewz .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #gfrwsufewz .gt_from_md > :first-child { margin-top: 0; } #gfrwsufewz .gt_from_md > :last-child { margin-bottom: 0; } #gfrwsufewz .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #gfrwsufewz .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #gfrwsufewz .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #gfrwsufewz .gt_row_group_first td { border-top-width: 2px; } #gfrwsufewz .gt_row_group_first th { border-top-width: 2px; } #gfrwsufewz .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gfrwsufewz .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #gfrwsufewz .gt_first_summary_row.thick { border-top-width: 2px; } #gfrwsufewz .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gfrwsufewz .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gfrwsufewz .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #gfrwsufewz .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #gfrwsufewz .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #gfrwsufewz .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gfrwsufewz .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gfrwsufewz .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gfrwsufewz .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gfrwsufewz .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gfrwsufewz .gt_left { text-align: left; } #gfrwsufewz .gt_center { text-align: center; } #gfrwsufewz .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #gfrwsufewz .gt_font_normal { font-weight: normal; } #gfrwsufewz .gt_font_bold { font-weight: bold; } #gfrwsufewz .gt_font_italic { font-style: italic; } #gfrwsufewz .gt_super { font-size: 65%; } #gfrwsufewz .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #gfrwsufewz .gt_asterisk { font-size: 100%; vertical-align: 0; } #gfrwsufewz .gt_indent_1 { text-indent: 5px; } #gfrwsufewz .gt_indent_2 { text-indent: 10px; } #gfrwsufewz .gt_indent_3 { text-indent: 15px; } #gfrwsufewz .gt_indent_4 { text-indent: 20px; } #gfrwsufewz .gt_indent_5 { text-indent: 25px; } 量的 × 量的変数の交互作用 product clerk Estimate Est.Error Q2.5 Q97.5 0 0 88.22 12.28 63.23 112.05 10 0 65.63 8.83 47.53 82.50 0 10 153.01 12.85 128.51 178.89 10 10 235.59 9.22 217.78 254.15 tab: https://gedevan-aleksizde.github.io/rmarkdown-cookbook/html-tabs.html 10.3.2 量的変数 × 質的変数 データの読み込み dat &lt;- read.csv(&quot;../stat_class_2025/sample_data/3-10-2-interaction-2.csv&quot;) コーディング（トリートメント） 他のコーディングでも分析可能である dat$publicity &lt;- factor(dat$publicity) contrasts(dat$publicity) &lt;- contr.treatment(2) contrasts(dat$publicity) ## 2 ## not 0 ## to_implement 1 model2 &lt;- brm(sales ~ publicity * temperature, gaussian(link = &quot;identity&quot;), data = dat, seed = 123, refresh = 0, iter = 5000, chains = 2) ## Compiling Stan program... ## Start sampling 宣伝アリの方が、切片（線の開始点）も傾きも大きいことが分かる plot(eff2, plot = F)[[1]]   sales Predictors Estimates CI (95%) Intercept 42.80 31.39 – 54.62 publicity2 17.49 1.15 – 33.52 temperature 2.59 1.94 – 3.23 publicity2:temperature 4.19 3.26 – 5.13 Observations 100 R2 Bayes 0.904 質的 × 量的変数の交互作用の予測値 df &lt;- data.frame( 宣伝 = c(&quot;なし&quot;, &quot;あり&quot;), `売り上げの予測値` = c( &quot;42.80 + temperature × 2.59&quot;, &quot;42.80 + 17.49 + temperature × (2.59 + 4.19)&quot;) ) df %&gt;% gt() %&gt;% tab_header(title = &quot;質的 × 量的変数の交互作用&quot;) %&gt;% cols_align(align = &quot;center&quot;) %&gt;% tab_options(table.width = pct(100)) #bwxikrsapf table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #bwxikrsapf thead, #bwxikrsapf tbody, #bwxikrsapf tfoot, #bwxikrsapf tr, #bwxikrsapf td, #bwxikrsapf th { border-style: none; } #bwxikrsapf p { margin: 0; padding: 0; } #bwxikrsapf .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: 100%; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #bwxikrsapf .gt_caption { padding-top: 4px; padding-bottom: 4px; } #bwxikrsapf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #bwxikrsapf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #bwxikrsapf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bwxikrsapf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bwxikrsapf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bwxikrsapf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #bwxikrsapf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #bwxikrsapf .gt_column_spanner_outer:first-child { padding-left: 0; } #bwxikrsapf .gt_column_spanner_outer:last-child { padding-right: 0; } #bwxikrsapf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #bwxikrsapf .gt_spanner_row { border-bottom-style: hidden; } #bwxikrsapf .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #bwxikrsapf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #bwxikrsapf .gt_from_md > :first-child { margin-top: 0; } #bwxikrsapf .gt_from_md > :last-child { margin-bottom: 0; } #bwxikrsapf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #bwxikrsapf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #bwxikrsapf .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #bwxikrsapf .gt_row_group_first td { border-top-width: 2px; } #bwxikrsapf .gt_row_group_first th { border-top-width: 2px; } #bwxikrsapf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bwxikrsapf .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #bwxikrsapf .gt_first_summary_row.thick { border-top-width: 2px; } #bwxikrsapf .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bwxikrsapf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bwxikrsapf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #bwxikrsapf .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #bwxikrsapf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #bwxikrsapf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bwxikrsapf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bwxikrsapf .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #bwxikrsapf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bwxikrsapf .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #bwxikrsapf .gt_left { text-align: left; } #bwxikrsapf .gt_center { text-align: center; } #bwxikrsapf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #bwxikrsapf .gt_font_normal { font-weight: normal; } #bwxikrsapf .gt_font_bold { font-weight: bold; } #bwxikrsapf .gt_font_italic { font-style: italic; } #bwxikrsapf .gt_super { font-size: 65%; } #bwxikrsapf .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #bwxikrsapf .gt_asterisk { font-size: 100%; vertical-align: 0; } #bwxikrsapf .gt_indent_1 { text-indent: 5px; } #bwxikrsapf .gt_indent_2 { text-indent: 10px; } #bwxikrsapf .gt_indent_3 { text-indent: 15px; } #bwxikrsapf .gt_indent_4 { text-indent: 20px; } #bwxikrsapf .gt_indent_5 { text-indent: 25px; } 質的 × 量的変数の交互作用 宣伝 売り上げの予測値 なし 42.80 + temperature × 2.59 あり 42.80 + 17.49 + temperature × (2.59 + 4.19) 気温の主効果は、宣伝がなかった時における気温の効果であることに注意。そのため、気温の主効果の数値だけではなく、交互作用を確認して結果を解釈する必要がある。 #iwvcukfvxe table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #iwvcukfvxe thead, #iwvcukfvxe tbody, #iwvcukfvxe tfoot, #iwvcukfvxe tr, #iwvcukfvxe td, #iwvcukfvxe th { border-style: none; } #iwvcukfvxe p { margin: 0; padding: 0; } #iwvcukfvxe .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: 100%; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #iwvcukfvxe .gt_caption { padding-top: 4px; padding-bottom: 4px; } #iwvcukfvxe .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #iwvcukfvxe .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #iwvcukfvxe .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #iwvcukfvxe .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iwvcukfvxe .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #iwvcukfvxe .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #iwvcukfvxe .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #iwvcukfvxe .gt_column_spanner_outer:first-child { padding-left: 0; } #iwvcukfvxe .gt_column_spanner_outer:last-child { padding-right: 0; } #iwvcukfvxe .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #iwvcukfvxe .gt_spanner_row { border-bottom-style: hidden; } #iwvcukfvxe .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #iwvcukfvxe .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #iwvcukfvxe .gt_from_md > :first-child { margin-top: 0; } #iwvcukfvxe .gt_from_md > :last-child { margin-bottom: 0; } #iwvcukfvxe .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #iwvcukfvxe .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #iwvcukfvxe .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #iwvcukfvxe .gt_row_group_first td { border-top-width: 2px; } #iwvcukfvxe .gt_row_group_first th { border-top-width: 2px; } #iwvcukfvxe .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #iwvcukfvxe .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #iwvcukfvxe .gt_first_summary_row.thick { border-top-width: 2px; } #iwvcukfvxe .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iwvcukfvxe .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #iwvcukfvxe .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #iwvcukfvxe .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #iwvcukfvxe .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #iwvcukfvxe .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iwvcukfvxe .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #iwvcukfvxe .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #iwvcukfvxe .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #iwvcukfvxe .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #iwvcukfvxe .gt_left { text-align: left; } #iwvcukfvxe .gt_center { text-align: center; } #iwvcukfvxe .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #iwvcukfvxe .gt_font_normal { font-weight: normal; } #iwvcukfvxe .gt_font_bold { font-weight: bold; } #iwvcukfvxe .gt_font_italic { font-style: italic; } #iwvcukfvxe .gt_super { font-size: 65%; } #iwvcukfvxe .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #iwvcukfvxe .gt_asterisk { font-size: 100%; vertical-align: 0; } #iwvcukfvxe .gt_indent_1 { text-indent: 5px; } #iwvcukfvxe .gt_indent_2 { text-indent: 10px; } #iwvcukfvxe .gt_indent_3 { text-indent: 15px; } #iwvcukfvxe .gt_indent_4 { text-indent: 20px; } #iwvcukfvxe .gt_indent_5 { text-indent: 25px; } 質的 × 量的変数の交互作用 publicity temperature Estimate Est.Error Q2.5 Q97.5 not 0 42.89 5.91 31.39 54.62 not 10 68.80 3.29 62.26 75.37 to_implement 0 60.31 5.67 49.33 71.52 to_implement 10 128.06 3.13 121.93 134.27 10.3.3 質的変数 × 質的変数 dat &lt;- read.csv(&quot;../stat_class_2025/sample_data/3-10-1-interaction-1.csv&quot;) コーディング（トリートメント） dat$publicity &lt;- factor(dat$publicity) contrasts(dat$publicity) &lt;- contr.treatment(2) contrasts(dat$publicity) ## 2 ## not 0 ## to_implement 1 dat$bargen &lt;- factor(dat$bargen) contrasts(dat$bargen) &lt;- contr.treatment(2) contrasts(dat$bargen) ## 2 ## not 0 ## to_implement 1 model3 &lt;- brm(sales ~ publicity * bargen, gaussian(link = &quot;identity&quot;), data = dat, seed = 123, refresh = 0, iter = 5000, chains = 2) ## Compiling Stan program... ## Start sampling 宣伝も安売りもありの方が売り上げが最も大きいことが分かる plot(eff3, plot = F)[[1]]   sales Predictors Estimates CI (95%) Intercept 103.32 96.18 – 110.51 publicity2 10.05 -0.22 – 20.17 bargen2 27.35 17.33 – 37.46 publicity2:bargen2 20.72 6.04 – 35.36 Observations 100 R2 Bayes 0.601 質的 × 質的変数の交互作用の予測値 宣伝も安売りもあった場合、二つの主効果に加え、交互作用の影響が加算される df &lt;- data.frame( 宣伝 = c(&quot;なし&quot;, &quot;あり&quot;, &quot;なし&quot;, &quot;あり&quot;), 安売り = c(&quot;なし&quot;, &quot;なし&quot;, &quot;あり&quot;, &quot;あり&quot;), `売り上げの予測値` = c(&quot;103.32&quot;, &quot;103.32 + 10.05&quot;, &quot;103.32 + 27.35&quot;, &quot;103.32 + 10.05 + 27.35 + 20.72&quot;) ) df %&gt;% gt() %&gt;% tab_header(title = &quot;質的 × 質的の交互作用&quot;) %&gt;% cols_align(align = &quot;center&quot;) %&gt;% tab_options(table.width = pct(100)) #axcnalqeqf table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #axcnalqeqf thead, #axcnalqeqf tbody, #axcnalqeqf tfoot, #axcnalqeqf tr, #axcnalqeqf td, #axcnalqeqf th { border-style: none; } #axcnalqeqf p { margin: 0; padding: 0; } #axcnalqeqf .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: 100%; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #axcnalqeqf .gt_caption { padding-top: 4px; padding-bottom: 4px; } #axcnalqeqf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #axcnalqeqf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #axcnalqeqf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #axcnalqeqf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #axcnalqeqf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #axcnalqeqf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #axcnalqeqf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #axcnalqeqf .gt_column_spanner_outer:first-child { padding-left: 0; } #axcnalqeqf .gt_column_spanner_outer:last-child { padding-right: 0; } #axcnalqeqf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #axcnalqeqf .gt_spanner_row { border-bottom-style: hidden; } #axcnalqeqf .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #axcnalqeqf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #axcnalqeqf .gt_from_md > :first-child { margin-top: 0; } #axcnalqeqf .gt_from_md > :last-child { margin-bottom: 0; } #axcnalqeqf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #axcnalqeqf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #axcnalqeqf .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #axcnalqeqf .gt_row_group_first td { border-top-width: 2px; } #axcnalqeqf .gt_row_group_first th { border-top-width: 2px; } #axcnalqeqf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #axcnalqeqf .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #axcnalqeqf .gt_first_summary_row.thick { border-top-width: 2px; } #axcnalqeqf .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #axcnalqeqf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #axcnalqeqf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #axcnalqeqf .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #axcnalqeqf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #axcnalqeqf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #axcnalqeqf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #axcnalqeqf .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #axcnalqeqf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #axcnalqeqf .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #axcnalqeqf .gt_left { text-align: left; } #axcnalqeqf .gt_center { text-align: center; } #axcnalqeqf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #axcnalqeqf .gt_font_normal { font-weight: normal; } #axcnalqeqf .gt_font_bold { font-weight: bold; } #axcnalqeqf .gt_font_italic { font-style: italic; } #axcnalqeqf .gt_super { font-size: 65%; } #axcnalqeqf .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #axcnalqeqf .gt_asterisk { font-size: 100%; vertical-align: 0; } #axcnalqeqf .gt_indent_1 { text-indent: 5px; } #axcnalqeqf .gt_indent_2 { text-indent: 10px; } #axcnalqeqf .gt_indent_3 { text-indent: 15px; } #axcnalqeqf .gt_indent_4 { text-indent: 20px; } #axcnalqeqf .gt_indent_5 { text-indent: 25px; } 質的 × 質的の交互作用 宣伝 安売り 売り上げの予測値 なし なし 103.32 あり なし 103.32 + 10.05 なし あり 103.32 + 27.35 あり あり 103.32 + 10.05 + 27.35 + 20.72 得られた係数の結果と比較するとさらに分かりやすい #lziwypofzf table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #lziwypofzf thead, #lziwypofzf tbody, #lziwypofzf tfoot, #lziwypofzf tr, #lziwypofzf td, #lziwypofzf th { border-style: none; } #lziwypofzf p { margin: 0; padding: 0; } #lziwypofzf .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: 100%; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lziwypofzf .gt_caption { padding-top: 4px; padding-bottom: 4px; } #lziwypofzf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lziwypofzf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #lziwypofzf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lziwypofzf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lziwypofzf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lziwypofzf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lziwypofzf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lziwypofzf .gt_column_spanner_outer:first-child { padding-left: 0; } #lziwypofzf .gt_column_spanner_outer:last-child { padding-right: 0; } #lziwypofzf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #lziwypofzf .gt_spanner_row { border-bottom-style: hidden; } #lziwypofzf .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #lziwypofzf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lziwypofzf .gt_from_md > :first-child { margin-top: 0; } #lziwypofzf .gt_from_md > :last-child { margin-bottom: 0; } #lziwypofzf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lziwypofzf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #lziwypofzf .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #lziwypofzf .gt_row_group_first td { border-top-width: 2px; } #lziwypofzf .gt_row_group_first th { border-top-width: 2px; } #lziwypofzf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lziwypofzf .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #lziwypofzf .gt_first_summary_row.thick { border-top-width: 2px; } #lziwypofzf .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lziwypofzf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lziwypofzf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lziwypofzf .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #lziwypofzf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lziwypofzf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lziwypofzf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lziwypofzf .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #lziwypofzf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lziwypofzf .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #lziwypofzf .gt_left { text-align: left; } #lziwypofzf .gt_center { text-align: center; } #lziwypofzf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lziwypofzf .gt_font_normal { font-weight: normal; } #lziwypofzf .gt_font_bold { font-weight: bold; } #lziwypofzf .gt_font_italic { font-style: italic; } #lziwypofzf .gt_super { font-size: 65%; } #lziwypofzf .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #lziwypofzf .gt_asterisk { font-size: 100%; vertical-align: 0; } #lziwypofzf .gt_indent_1 { text-indent: 5px; } #lziwypofzf .gt_indent_2 { text-indent: 10px; } #lziwypofzf .gt_indent_3 { text-indent: 15px; } #lziwypofzf .gt_indent_4 { text-indent: 20px; } #lziwypofzf .gt_indent_5 { text-indent: 25px; } 質的 × 質的変数の交互作用 publicity bargen Estimate Est.Error Q2.5 Q97.5 not not 103.34 3.68 96.18 110.51 to_implement not 113.35 3.64 106.09 120.52 not to_implement 130.65 3.70 123.49 137.85 to_implement to_implement 161.30 3.70 154.02 168.31 10.3.3.1 下位検定 交互作用が有意だった場合に、単純主効果を調べるために行う 単純主効果 ある要因の各水準における、別の要因の効果のこと e.g., Publicity条件における、Bargen実施の有無（to_impement/not）の平均値差 多重比較 水準が3以上などの場合、検定を繰り返すため、多重比較の問題が発生する。影響を軽減するため、補正を行う 交互作用が有意   sales Predictors Estimates CI p (Intercept) 103.38 96.15 – 110.60 &lt;0.001 publicity [2] 9.94 -0.28 – 20.16 0.057 bargen [2] 27.27 17.05 – 37.49 &lt;0.001 publicity [2] × bargen[2] 20.80 6.34 – 35.25 0.005 Observations 100 R2 / R2 adjusted 0.604 / 0.592 - emmeans()関数を使って、下位検定を行う #install.packages(&quot;emmeans&quot;) library(emmeans) bargenの単純主効果（publicityの各水準ごとにbargenの効果を調べる） bargen by publicity contrast( emmeans(model4, pairwise ~ bargen | publicity), adjust = &quot;bonferroni&quot; ) ## publicity = not: ## contrast estimate SE df t.ratio p.value ## not effect -13.6 2.57 96 -5.297 &lt;.0001 ## to_implement effect 13.6 2.57 96 5.297 &lt;.0001 ## ## publicity = to_implement: ## contrast estimate SE df t.ratio p.value ## not effect -24.0 2.57 96 -9.335 &lt;.0001 ## to_implement effect 24.0 2.57 96 9.335 &lt;.0001 ## ## P value adjustment: bonferroni method for 2 tests publicityの単純主効果（bargenの各水準ごとにpublicityの効果を調べる） publicity by bargen contrast( emmeans(model4, pairwise ~ publicity | bargen), adjust = &quot;bonferroni&quot; ) ## bargen = not: ## contrast estimate SE df t.ratio p.value ## not effect -4.97 2.57 96 -1.930 0.1132 ## to_implement effect 4.97 2.57 96 1.930 0.1132 ## ## bargen = to_implement: ## contrast estimate SE df t.ratio p.value ## not effect -15.37 2.57 96 -5.968 &lt;.0001 ## to_implement effect 15.37 2.57 96 5.968 &lt;.0001 ## ## P value adjustment: bonferroni method for 2 tests 10.4 ハンズオンセッション 10.4.1 質的 × 質的（サムコントラスト） dat &lt;- read.csv(&quot;../stat_class_2025/sample_data/Example4.csv&quot;) head(dat, 5) ## Grade Learning id Post ## 1 First List 1 73 ## 2 First List 2 59 ## 3 First List 3 63 ## 4 First List 4 59 ## 5 First List 5 46 table(dat$Grade) ## ## First Second ## 15 15 table(dat$Learning) ## ## Context KeyWord List ## 10 10 10 dat$Grade &lt;- factor(dat$Grade) dat$Learning &lt;- factor(dat$Learning, levels = c(&quot;List&quot;, &quot;Context&quot;, &quot;KeyWord&quot;)) 各群ごとの平均 aggregate(Post ~ Grade, data = dat, FUN = mean) ## Grade Post ## 1 First 39.93333 ## 2 Second 55.06667 aggregate(Post ~ Learning, data = dat, FUN = mean) ## Learning Post ## 1 List 65.1 ## 2 Context 32.5 ## 3 KeyWord 44.9 res &lt;- aggregate(Post ~ Grade*Learning , data = dat, FUN = mean) res ## Grade Learning Post ## 1 First List 60.0 ## 2 Second List 70.2 ## 3 First Context 19.8 ## 4 Second Context 45.2 ## 5 First KeyWord 40.0 ## 6 Second KeyWord 49.8 Ground Mean mean(res$Post) ## [1] 47.5 contrasts(dat$Grade) &lt;- contr.sum(2) contrasts(dat$Grade) ## [,1] ## First 1 ## Second -1 contrasts(dat$Learning) &lt;- contr.sum(3) contrasts(dat$Learning) ## [,1] [,2] ## List 1 0 ## Context 0 1 ## KeyWord -1 -1 model_sum &lt;- lm(Post ~ Grade * Learning, data = dat) summary(model_sum) ## ## Call: ## lm(formula = Post ~ Grade * Learning, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.2 -6.7 -1.0 8.1 15.2 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.500 1.807 26.285 &lt; 0.0000000000000002 *** ## Grade1 -7.567 1.807 -4.187 0.000328 *** ## Learning1 17.600 2.556 6.887 0.000000402 *** ## Learning2 -15.000 2.556 -5.869 0.000004701 *** ## Grade1:Learning1 2.467 2.556 0.965 0.344071 ## Grade1:Learning2 -5.133 2.556 -2.009 0.055952 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.898 on 24 degrees of freedom ## Multiple R-squared: 0.762, Adjusted R-squared: 0.7124 ## F-statistic: 15.37 on 5 and 24 DF, p-value: 0.0000008253 以下のような作図を行う場合、コーディングによって図中のパターンが変わることはない #install.packages(&quot;sjPlot&quot;) library(sjPlot) plot_model( model_sum, type = &quot;pred&quot;, terms = c(&quot;Grade&quot;, &quot;Learning&quot;) ) 10.4.2 係数の解釈 記述統計の値を参照した考えると分かりやすい Intercept: grand mean (47.5) GradeSecond: First - grand mean (39.93333 - 47.5) Learning1: List - grand mean (65.1 - 47.5) Learning2: Context - grand mean (32.5 - 47.5) GradeSecond:Learning1: {2 * (60 - 70.2) + (45.2 - 19.8) + (49.8 - 40)} ÷ 6 \\[ \\frac{2(M_{\\text{リスト1}} - M_{\\text{リスト2}}) + (M_{\\text{文脈2}} - M_{\\text{文脈1}}) + (M_{\\text{キー2}} - M_{\\text{キー1}})}{6} \\] GradeSecond:Learning2: {(70.2-60) + 2 * (19.8-45.2) + (49.8 - 40)} ÷ 6 \\[ \\frac{(M_{\\text{リスト2}} - M_{\\text{リスト1}}) + 2(M_{\\text{文脈1}} - M_{\\text{文脈2}}) + (M_{\\text{キー2}} - M_{\\text{キー1}})}{6} \\] 10.4.3 質的 × 質的（反復コントラスト） library(MASS) contrasts(dat$Grade) &lt;- fractions(contr.sdif(2)) contrasts(dat$Grade) ## 2-1 ## First -1/2 ## Second 1/2 contrasts(dat$Learning) &lt;- fractions(contr.sdif(3)) contrasts(dat$Learning) ## 2-1 3-2 ## List -2/3 -1/3 ## Context 1/3 -1/3 ## KeyWord 1/3 2/3 model_rep &lt;- lm(Post ~ Grade * Learning, data = dat) summary(model_rep) ## ## Call: ## lm(formula = Post ~ Grade * Learning, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.2 -6.7 -1.0 8.1 15.2 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.500 1.807 26.285 &lt; 0.0000000000000002 *** ## Grade2-1 15.133 3.614 4.187 0.000328 *** ## Learning2-1 -32.600 4.426 -7.365 0.000000132 *** ## Learning3-2 12.400 4.426 2.801 0.009898 ** ## Grade2-1:Learning2-1 15.200 8.853 1.717 0.098867 . ## Grade2-1:Learning3-2 -15.600 8.853 -1.762 0.090780 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.898 on 24 degrees of freedom ## Multiple R-squared: 0.762, Adjusted R-squared: 0.7124 ## F-statistic: 15.37 on 5 and 24 DF, p-value: 0.0000008253 10.4.4 係数の解釈 記述統計の値を参照した考えると分かりやすい Intercept: grand mean Grade2-1: Second - First Learning2-1: Context - List Learning3-2: Keyword - Context Grade2-1:Learning2-1: (ContextにおけるSecond-First) - (ListにおけるSecond-First) = (45.2 - 19.8) - (70.2 - 60) Grade2-1:Learning3-2: (KeywordにおけるSecond-First) - (ContextにおけるSecond-First) = (49.8 - 40) - (45.2 - 19.8) emmeans()関数で下位検定を行う場合も、どのコーディングをあてはめても結果は同じになります。 ここまで見てきたように、どのようなコーディングを適用したかで係数の値は異なります。また、何と何を比較しているのかによって係数の正負も変わります。必ず、どの変数にどのようなコーディングを適用したのか、どの水準とどの水準を比較したのかを第三者から見て分かるように記載しましょう。 2水準 × 3水準の交互作用でも係数の解釈は結構複雑になります。デザインはシンプルな方が解釈する側も分析をしやすいです。 10.5 最後に 清水先生の「心理学における重回帰分析の使い所を考える」に関してのコラムをいれる」 10.6 次週までの課題 10.6.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 （宿題を考える）- 外れ値を考えてやる Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 10.6.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 10.7 参考文献 南風原 馬場 RとStanではじめるベイズ統計モデリングによるデータ分析 小島ますみ（2022）. 外国語教育研究における（一般化）線形混合モデル：仮説に適したコーディング・モデリングを中心に The 2021 Annual Conference on Vocabulary Acquisition https://debruine.github.io/faux/articles/contrasts.html#x3-design .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["week10-一般化線形モデルロジスティック回帰分析.html", "Chapter 11 Week10: 一般化線形モデル：ロジスティック回帰分析 11.1 事前の確認 11.2 今日の目標 11.3 一般化線形モデル 11.4 二項分布 11.5 ロジット関数 11.6 ロジスティック関数 11.7 ハンズオンセッション 11.8 質的変数の場合 11.9 分類にも使えます 11.10 次週までの課題 11.11 参考文献", " Chapter 11 Week10: 一般化線形モデル：ロジスティック回帰分析 11.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 11.2 今日の目標 11.3 一般化線形モデル 確率分布に正規分布以外を仮定する（一般線形モデル = 正規分布を仮定） 世の中には、正規分布で表現するのが難しい事象がある テストへの合格/不合格 所得の分布 信頼できる友達の数 glm()関数で使用できる分布 外国語研究、言語研究では、正規分布、二項分布、対数正規分布などが用いられる binomial(link = &quot;logit&quot;) gaussian(link = &quot;identity&quot;) Gamma(link = &quot;inverse&quot;) inverse.gaussian(link = &quot;1/mu^2&quot;) poisson(link = &quot;log&quot;) quasi(link = &quot;identity&quot;, variance = &quot;constant&quot;) quasibinomial(link = &quot;logit&quot;) quasipoisson(link = &quot;log&quot;) 使用するRの関数によって、使用できる確率分布が異なります。glm関数には対数正規分布は含まれていません。 11.4 二項分布 ある試行を N 回行った際の成功回数 k が発生する確率 q \\[ p(k \\mid N, q) = \\binom{N}{k} q^k (1 - q)^{N - k} \\] \\[ \\binom{N}{k} = \\frac{N!}{k!(N-k)!} \\] 11.4.1 身近な例 寺井と雅人がじゃんけんを10回する。寺井が雅人に K 回勝つ確率を求める（勝つ可能性は50 %） 寺井が2回勝つ場合 (\\(k = 2\\)) \\[ P(X = 2) = \\binom{10}{2} (0.5)^2 (0.5)^{10-2} = \\binom{10}{2} (0.5)^{10} \\] ここで、二項係数は次のように計算（8!をまとめて消している）： \\[ \\binom{10}{2} = \\frac{10 \\times 9}{2 \\times 1} = 45 \\] したがって、確率は： \\[ P(X = 2) = 45 \\times (0.5)^{10} = 45 \\times \\frac{1}{1024} \\approx 0.043945 \\] 2回勝つ確率は約 0.0439 寺井が4回勝つ場合 (\\(k = 4\\)) \\[ P(X = 4) = \\binom{10}{4} (0.5)^4 (0.5)^{10-4} = \\binom{10}{4} (0.5)^{10} \\] \\[ \\binom{10}{4} = \\frac{10 \\times 9 \\times 8 \\times 7}{4 \\times 3 \\times 2 \\times 1} = 210 \\] したがって、確率は： \\[ P(X = 4) = 210 \\times (0.5)^{10} = 210 \\times \\frac{1}{1024} \\approx 0.205078 \\] 4回勝つ確率は約 0.2051 # パラメータ N &lt;- 10 # 試行回数 k &lt;- 4 # 成功回数 p &lt;- 0.5 # 成功確率（例えば、50%の確率） # 2項分布における確率を計算 prob &lt;- dbinom(k, size = N, prob = p) print(prob) ## [1] 0.2050781 線形回帰を2値のデータに当てはめたモデルは、予測値（直線）が1以上であったり0以下であったりしている（本来は1 = 合格、0 = 不合格） 予測値を0から1に収まるようにする必要がある。これを行うための関数がロジスティック関数 切片の値はマイナスとなっており、0-1という確率の範囲を超えている。 res &lt;- lm(Pass ~ Years_of_Study, data = dat) sjPlot::tab_model(res)   Pass Predictors Estimates CI p (Intercept) -0.19 -0.32 – -0.07 0.003 Years of Study 0.14 0.11 – 0.16 &lt;0.001 Observations 100 R2 / R2 adjusted 0.604 / 0.599 11.4.2 2項分布からロジスティック回帰モデルへ 二項分布は成功回数の確率分布を表す。この成功回数を予測するモデルがロジスティック回帰モデル 11.5 ロジット関数 0か1しかとらない従属変数が1になる確率（確率は0と1ではなく、0から1の間をとる）を P とすると、0になる確率は 1 - P。この二つの比をオッズ比という。 \\[ \\text{odds ratio} = \\frac{P}{1 - P} \\] 確率（ P ）を対数オッズに変換（ロジット変換という） 対数オッズのことをロジットという 0から1しかとらない値を、-∞ ~ ∞を取る連続値のデータに変換する関数がロジット関数 \\[ \\text{logit}(P) = \\log \\left( \\frac{P}{1 - P} \\right) \\] ロジット関数により、 この変換で、従属変数の値が0か1かという制約がなくなり、線形モデルとして偏回帰係数を推定できる 線形モデルで当てはめる方が計算などの都合がいいから 線形モデルとは異なり、曲線であるため、1単位の変化量が異なる logit(0.5) = 0、logit(0.6) = 0.4 =&gt; ロジットスケールでの0.4の変換は変換前の単位での50%から60%の変更に対応 logit(0.9) = 2.2、logit(0.93) = 2.6 =&gt; ロジットスケールでの0.4の変換は変換前の単位での90%から93%の変更に対応 11.6 ロジスティック関数 この関数を使うことで、説明変数の集まり（線形予測子：線形結合した説明変数）がどの範囲に合っても、0 ~ 1の範囲に収まる（確率を表すのに最適！）。 ロジスティック回帰ではリンク関数にロジット関数をおき、確率を線形予測子に変換 ロジスティック関数は逆リンク関数として使われ、線形予測子から確率を復元する リンク関数：従属変数を変換し、独立変数関数につなげる変換関数、独立変数を変換する場合は「逆」リンク関数 \\[ \\text{logistic}(x) = \\frac{1}{1 + e^{-x}} \\] 11.6.1 つまり データを分析しやすいようにロジット変換をして線形回帰を行う。 値をもとに戻さないと理解しずらいため、ロジスティック関数を使って0 ~ 1の範囲に戻している 一般「化」線形モデルでは、どの確率分布を使うかだけでなく、どのような変換関数で変換をするかも把握する必要がある。そのため、何でもかんでも正規分布で分析したり、データを無理やり変換し正規分布に近づけるような方法ではなく、得られたデータをそのままに、モデルの工夫でフィッティングを調整するという考え方が身につく。 11.6.2 一般化線形モデルの使用上の注意 一般線形モデルのように、回帰係数をそのまま解釈できない 変換係数を経由して、説明変数の変化が影響を受けている 回帰分析：ある独立変数Aが1単位変化すると、従属変数はBだけ変化 ロジスティック回帰：ある独立変数Aが1単位変化すると、従属変数はexp(B)だけ変化 ロジスティック関数はロジット関数の逆関数のこと 逆関数：戻してあげる関数のこと e.g., log(3) -&gt; exp(log(3)) = 3 リンク関数としてロジット関数を使っているため、ロジット関数の逆関数であるロジスティック関数で戻してあげている。 11.7 ハンズオンセッション 11.7.1 疑似データの用意 Pass： テストの合否。1なら合格、0なら不合格 Method：指導法A、指導法B Starting_age：英語を勉強し始めた年齢 set.seed(123) # 再現性のため dat &lt;- data.frame( Pass = sample(0:1, 40, replace = TRUE), # 1 または 0 Method = sample(c(&quot;A&quot;, &quot;B&quot;), 40, replace = TRUE), # A または B Starting_age = sample(0:10, 40, replace = TRUE) # 0 ~ 10 の数値 ) head(dat, head = 3) ## Pass Method Starting_age ## 1 0 A 5 ## 2 0 B 10 ## 3 0 B 7 ## 4 1 A 5 ## 5 0 A 5 ## 6 1 A 6 summary(dat) ## Pass Method Starting_age ## Min. :0.000 Length:40 Min. : 0.000 ## 1st Qu.:0.000 Class :character 1st Qu.: 2.000 ## Median :0.000 Mode :character Median : 5.000 ## Mean :0.425 Mean : 4.875 ## 3rd Qu.:1.000 3rd Qu.: 7.000 ## Max. :1.000 Max. :10.000 11.7.2 モデルの推定 glm()関数を使用する familyで確率分布を指定する library(stats) res &lt;- glm( Pass ~ Starting_age, family = binomial(link = &quot;logit&quot;), data = dat ) Estimate: 偏回帰係数 Std. Error (Standard Error): 標準誤差 かなり重要。どれくらい推定に誤差があるかを示す指標。「同じ調査法で同じ数のデータをとりなおしてみると、推定値も結構変わるので、そのバラツキ度合い」 z value：z値と呼ばれる統計量（Wald統計量とも言われる）。Estimate ÷ SE で算出。この値で、Wald信頼区間を算出し、その値がゼロから十分に離れているかの目安になる。 Pr(&gt;|z|): 平均が z値の絶対値で、標準偏差が1の正規分布において、マイナス無限大からゼロまでの値をとる確率。この確率が大きいほどZ値がゼロに近くなり、Estimateがゼロに近い。 p 値（アスタリスク）：95%CIに0を含む場合有意とされる summary(res) ## ## Call: ## glm(formula = Pass ~ Starting_age, family = binomial(link = &quot;logit&quot;), ## data = dat) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.6788 0.6650 1.021 0.3073 ## Starting_age -0.2061 0.1238 -1.665 0.0959 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 54.548 on 39 degrees of freedom ## Residual deviance: 51.559 on 38 degrees of freedom ## AIC: 55.559 ## ## Number of Fisher Scoring iterations: 4 95%信頼区間の算出 stats::confint(res) ## 2.5 % 97.5 % ## (Intercept) -0.6010333 2.05617252 ## Starting_age -0.4667027 0.02681936 11.7.3 作図 # 年齢（Years_of_Study）の範囲を設定 years_range &lt;- seq(0, 10, length.out = 100) # 各年数に対する予測確率を計算 pred_probs &lt;- predict(res, newdata = data.frame(Starting_age = years_range), type = &quot;response&quot;) # 予測確率を描画 plot( years_range, pred_probs, type = &quot;l&quot;, # 線で描画 col = &quot;blue&quot;, lwd = 2, xlab = &quot;Starting Age&quot;, ylab = &quot;Pr (Pass)&quot;, main = &quot;Logistic Regression: Probability of Passing&quot;, ylim = c(0, 1), xaxt = &quot;n&quot;, yaxs = &quot;i&quot; ) # x軸のカスタムラベルを追加 axis(1, at = seq(0, 10, by = 1), labels = seq(0, 10, by = 1)) 11.7.4 オッズ比の算出 オッズ比：オッズの変化量。ロジスティック回帰モデルの回帰係数に指数関数を適用すると算出できる。 指数関数をとると、その値は必ず正の値になる Estimate オッズ比 解釈 正（&gt; 0） &gt; 1 オッズが 増加 0 = 1 オッズは 変化なし 負（&lt; 0） &lt; 1 オッズが 減少 係数がマイナスだったので、 オッズ比 &lt; 1となっている点に注意 exp(res$coefficients) ## (Intercept) Starting_age ## 1.9715609 0.8137445 exp(stats::confint(res)) ## 2.5 % 97.5 % ## (Intercept) 0.5482448 7.815997 ## Starting_age 0.6270665 1.027182 11.7.5 結果報告の例と解釈 英語の学習年数の主効果の係数は有意ではなかった（Estimate = -0.21 [-0.47, 0.03], SE = 0.12, z = -1.67, p = .10, OR = 0.81 [0.63, 1.03]）。傾向として、英語学習開始歴が1年増えると、テストに合格するオッズが0.81倍になる（ = 合格するオッズが [1 - 0.81 = 19] 19%低い）と予測される。 もし係数が0.21だった場合、オッズ比はexp(0.21) = 1.23。この場合、 英語学習歴が1年増えると、テストに合格する**オッズが1.23倍になる。つまり、テストに合格するオッズは（不合格となる場合に比べ）（1.23 - 1 = 0.23）23%増加すると予測される。 しかし、オッズやオッズ比で結果を言われても解釈が少し難しい。predict関数で具体的な合格する確率を算出する方が分かりやすい。 # 年齢（Years_of_Study）の範囲を設定 years_range &lt;- seq(0, 10) # 各年数に対する予測確率を計算 pred_probs &lt;- predict(res, newdata = data.frame(Starting_age = years_range), type = &quot;response&quot;) 100を書けて%単位に変換 pred_probs * 100 ## 1 2 3 4 5 6 7 8 ## 66.34765 61.60266 56.62600 51.51202 46.36618 41.29658 36.40504 31.77923 ## 9 10 11 ## 27.48716 23.57445 20.06459 作図 plot(pred_probs * 100) 11.7.6 新たなデータで予測してみる 25歳で初めて場合を調べてみる type = \"link\"にすると、係数が得られる new &lt;- data.frame(Starting_age = 25) pred_probs &lt;- predict(res, newdata = new, type = &quot;link&quot;) オッズ比を計算 exp(pred_probs) ## 1 ## 0.01140283 type = \"response\"にすると、予測確率が返される pred_probs &lt;- predict(res, newdata = new, type = &quot;response&quot;) 25歳ではじめると、1.13 %の合格確率となる pred_probs * 100 ## 1 ## 1.127427 11.8 質的変数の場合 means &lt;- aggregate(Pass ~ Method, data = dat, FUN = mean) means ## Method Pass ## 1 A 0.4800000 ## 2 B 0.3333333 table(dat$Method) ## ## A B ## 25 15 # Methodごとの正答率を計算 table_data &lt;- table(dat$Method, dat$Pass) # 棒グラフで可視化 barplot(prop.table(table_data, margin = 1), beside = TRUE, legend = rownames(table_data), xlab = &quot;Pass (0 = Incorrect, 1 = Correct)&quot;, ylab = &quot;Proportion&quot;, main = &quot;Proportion of Passing by Method&quot;) 11.8.1 トリートメントコントラスト dat$Method &lt;- factor(dat$Method) contrasts(dat$Method) ## B ## A 0 ## B 1 res.2 &lt;- glm( Pass ~ Method, family = binomial(link = &quot;logit&quot;), data = dat ) Method Bの係数：Method B - Method A summary(res.2) ## ## Call: ## glm(formula = Pass ~ Method, family = binomial(link = &quot;logit&quot;), ## data = dat) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.08004 0.40032 -0.200 0.842 ## MethodB -0.61310 0.67842 -0.904 0.366 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 54.548 on 39 degrees of freedom ## Residual deviance: 53.713 on 38 degrees of freedom ## AIC: 57.713 ## ## Number of Fisher Scoring iterations: 4 95%信頼区間の算出 stats::confint(res.2) ## Waiting for profiling to be done... ## 2.5 % 97.5 % ## (Intercept) -0.8789758 0.710550 ## MethodB -2.0030397 0.692511 11.8.2 オッズ比 Methodのオッズ比は0.54だった。よってMethod BはAに比べ、合格の成功オッズが(1 - 0.54 = 0.46) 46%低い exp(res.2$coefficients) ## (Intercept) MethodB ## 0.9230769 0.5416667 exp(stats::confint(res.2)) ## Waiting for profiling to be done... ## 2.5 % 97.5 % ## (Intercept) 0.4152080 2.035110 ## MethodB 0.1349245 1.998728 11.8.3 確率を計算 # glmモデルの結果を使って予測確率を計算 pred_probs_A &lt;- predict(res.2, newdata = data.frame(Method = &quot;A&quot;), type = &quot;response&quot;) pred_probs_B &lt;- predict(res.2, newdata = data.frame(Method = &quot;B&quot;), type = &quot;response&quot;) pred_probs_A ## 1 ## 0.48 pred_probs_B ## 1 ## 0.3333333 11.8.4 作図 #install.packages(&quot;arm&quot;) library(arm) # Method A と Method B の予測確率を描画 plot( c(1, 2), c(pred_probs_A, pred_probs_B), pch = 16, col = &quot;black&quot;, cex = 2, xlim = c(0, 3), ylim = c(0, 1), xaxt = &quot;n&quot;, xlab = &quot;Method&quot;, ylab = &quot;Pr (Pass)&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot; ) # 信頼区間のエラーバーを追加 arrows(1, pred_probs_A - 0.1, 1, pred_probs_A + 0.1, angle = 90, code = 3, length = 0.1, col = &quot;black&quot;) arrows(2, pred_probs_B - 0.1, 2, pred_probs_B + 0.1, angle = 90, code = 3, length = 0.1, col = &quot;black&quot;) # x軸のカスタムラベルを追加 (Method A と Method B) axis(1, at = c(1, 2), labels = c(&quot;Method A&quot;, &quot;Method B&quot;)) 11.9 分類にも使えます 機械学習などでは分類モデル（2つのカテゴリのデータ）として用いられたりします。 以下では、合格の予測確率が0.6未満の場合やばい（0）、0.6以上の場合安心（1）と分類しています pred_probs &lt;- predict(res, type = &quot;response&quot;, newdata = data.frame(Starting_age = dat$Starting_age)) # 予測クラスを作成 pred_class &lt;- ifelse(pred_probs &gt; 0.6, 1, 0) # 元のデータに予測確率と予測クラスを追加 new_data &lt;- dat %&gt;% mutate(pred_probs = pred_probs, pred_class = pred_class) # ggplotで視覚化 ggplot(new_data, aes(x = Starting_age, y = 1, fill = factor(pred_class))) + geom_tile(height = 1, width = 1) + # 矩形のサイズ調整 scale_fill_manual(values = c(&quot;darkblue&quot;, &quot;skyblue&quot;)) + labs(x = &quot;Starting Age&quot;, y = &quot;&quot;, fill = &quot;Predicted Class&quot;) + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) 11.10 次週までの課題 11.10.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 （宿題を考える） ハンズオンセッションで使用したデータを基にサムコントラストで分析をしてみましょう Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 11.10.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 11.11 参考文献 草薙（2017） 確率分布から見る外国語教育研究データ Gelman Regression and Other stories 馬場 RとStanではじめるベイズ統計モデリングによるデータ分析 Rを用いた一般化線形混合モデル（GLMM）の分析手法を身につける:言語研究分野の事例をもとに 小杉 「言葉と数式で理解する多変量解析入門」 https://bellcurve.jp/statistics/course/26934.html?srsltid=AfmBOorwQsuSpgEx3zQ8gVhrS2zSP50-PUvuzRlNqNP-rxWB2J_XBwyf https://hkawabata.github.io/technical-note/note/ML/logistic-regression.html Terai, M., Fukuta, J., &amp; Tamura, Y. (2024). Learnability of L2 collocations and L1 influence on L2 collocational representations of Japanese learners of English. International Review of Applied Linguistics in Language Teaching, 62(4), 1959-1983. .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["week11-階層モデル.html", "Chapter 12 Week11: 階層モデル 12.1 事前の確認 12.2 今日の目標 12.3 次週までの課題 12.4 参考文献", " Chapter 12 Week11: 階層モデル 12.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 12.2 今日の目標 12.3 次週までの課題 12.3.1 課題内容 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。 （宿題を考える） ハンズオンセッションで使用したデータを基にサムコントラストで分析をしてみましょう Rで数値を出力するだけでなく、それぞれの質問への回答を高校生にもわかりやすく文字で記載してください。 12.3.2 提出方法 メールにファイルを添付して送信。 締め切りは今週の木曜日まで 12.4 参考文献 .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} "],["week-15言語研究とオープンサイエンス.html", "Chapter 13 Week 15：言語研究とオープンサイエンス 13.1 事前の確認 13.2 今日の目標 13.3 はじめに 13.4 1. R Markdownを使って分析結果をまとめることができる 13.5 プロジェクト 13.6 実際に作ってみましょう 13.7 ドキュメントチャンク：Markdown記法 13.8 Let’s 実践 13.9 答え合わせ 13.10 実は、Wordのように編集できます！ 13.11 コードチャンクの挿入 13.12 Let’s 実践 13.13 食費の合計 13.14 答え合わせ 13.15 2. R Markdownでまとめた結果を共有することができる 13.16 HTML形式だと、簡単にウェブサイトにできます 13.17 3. 様々なパソコンで同じ分析環境を再現することができる 13.18 R自体のバージョン管理も可能です 13.19 おまけ 13.20 関数の呼び出し方 13.21 まとめ 13.22 参考文献 &amp; 資料", " Chapter 13 Week 15：言語研究とオープンサイエンス 13.1 事前の確認 この講義のRプロジェクトを開いていますか？ 英数字で名前を付けた本日の講義のファイルを作成しましたか？ .Rでも.Rmdでもどちらでも大丈夫です。 13.2 今日の目標 /* Whole document */ body { font-family: Helvetica; font-size: 16pt; } /* Headers */ h1, h2, h3, h4, h5, h6 { font-size: 24pt; } .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #f5f5f5 5px center/3em no-repeat; } .beg { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png\");} .caution { background-image: url(\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png\");} 2024年8月に名古屋学院大で行われた外国語メディア学会全国大会でのワークショップ（外国語教育研究者のためのオープンサイエンス入門― R Markdownを用いた実践編の内容を改変したものです。 13.3 はじめに 13.3.1 研究成果や研究資料の公開・共有の必要性 13.3.1.1 再現可能な研究のために、研究に使用したマテリアルの提出を推奨 e.g., 実験で使用した刺激文、分析に使用した生データ、分析コード Language LearningのHPより Shared Research Materials and Data Policy for Accepted Articles. Language Learning encourages accepted authors to upload their data collection materials and/or data to the IRIS database (http://www.iris-database.org). IRIS is an online repository for data collection materials used for second language research. This includes data elicitation instruments such as interview and observation schedules, language tests, pictures, questionnaires, software scripts, URL links, word lists, pedagogical interventions, and so on. (…) The sharing of research instrumentation benefits the research community and helps authors and journals increase the visibility of their published research. 13.4 1. R Markdownを使って分析結果をまとめることができる 13.4.1 R Studioを開いて作成する 13.4.1.1 R Markdownの解体新書 【パーツ１】YAML（YAML Ain’t Markup Language）ヘッダー：文章全体の体裁や情報を操作する タイトル、サブタイトル 作成者 作成した日時、更新日時も設定可能 どのような形式で作成するか 注意 ・ YAMLヘッダーは、RでもMarkdownでもないプログラム言語で記述します。 【パーツ２】コードチャンク：Rのコードを記述するところ 【パーツ３】ドキュメントチャンク：Markdownと呼ばれるプログラム言語で記述するところ 見出し、表、箇条書き、強調、斜体など、Wordのリボン部分にある機能をMarkdownで書く 13.4.2 Knitを押して出力！ 初期設定はHTMLファイル出力です 13.5 プロジェクト プロジェクト = ディレクトリ ファイルや操作履歴を保存できる プロジェクトを作成する利点 研究ごとに分析に必要なファイルをまとめることができる 13.6 実際に作ってみましょう デスクトップに新しいフォルダーを作成してください 名前は、英数字のみがいいです（Rが関係しそうな場合、ファイル名、フォルダ名に日本語を使わない方が安心です） 作り方を解説しているサイト（私たちのR） デスクトップのフォルダーを指定してプロジェクトを作成しましょう 13.7 ドキュメントチャンク：Markdown記法 13.7.1 覚えるのはマストではない。その都度調べてよく使うものを覚えていく Markdownなら生成AIはほぼ完ぺきに正解を教えてくれる 必要最低限で覚えておくとよい記法 見出し → これはマスト！ #の数で指定。文字との間を半角あけるのを忘れない。 箇条書き *, +, -のいずれかを入れる。文字との間を半角あけるのを忘れない。 半角スペースを2つ前（もしくはtab）に入れると、レベル２を作れる。さらに2ついれると、、、 強調 *で挟むと斜体 **で挟むとBold体 ***で挟むとどうなるでしょう 13.8 Let’s 実践 以下の文章をMarkdownを使って再現してください。 ’# 名古屋飯といえば ’## ひつまぶし：Hitsumabushi おすすめは以下のお店です。 ひつまぶし花岡 場所：栄 13.9 答え合わせ # 名古屋飯といえば ## ひつまぶし：*Hitsumabushi* おすすめは以下のお店です。 - **ひつまぶし花岡** - 場所：栄 13.10 実は、Wordのように編集できます！ Markdownで書かなくとも、VisualモードであればWordと似たようにできます。 以下で設定ができる [Tools] → [Global Options…] → [R Markdown] → [Visual] “Use visual editor by default for new documents”の項目に☑ “Soft-wrap R Markdown files”にも☑を入れると、右側にアウトラインが出ます 欠点として、少し動作が遅い。簡単なものはMarkdownで書く方が速い 表などはVisualモードがおすすめ 13.11 コードチャンクの挿入 13.11.1 ショートカットキーが便利：[Ctrl] + [Alt] + [I]（Windows）、[Command] + [Option] + [I]（Mac） このコードの中はRです。Rで使う関数などを自由に指定できます。 以下のチャンク内でないと、動きません。 ```{r} ``` dat &lt;- c(1, 4, 6) mean(dat) ## [1] 3.666667 plot(dat) {r}の中にもいろいろな指定ができます。 コードを非表示にして結果だけを表示させたい（オープンサイエンスではないですが） ## [1] 3.666667 チャンクのオプションは沢山あるので、その都度チートシートを参照するとよいです。 チートシート 13.12 Let’s 実践 以下をドキュメントチャンクとコードチャンクを使って再現してください。 13.13 食費の合計 以下は、名古屋旅行で使った食費の合計である。 注! hitsuはひつまぶし、misoは味噌カツを表す。 hitsu &lt;- 1300 * 2 miso &lt;- 1000 * 2 total &lt;- sum(hitsu, miso) 13.14 答え合わせ ## 食費の合計 - 以下は、名古屋旅行で使った食費の合計である。 - **注!** *hitsu*はひつまぶし、*miso*は味噌カツを表す \\```{r} hitsu &lt;- 1300 * 2 miso &lt;- 1000 * 2 total &lt;- sum(hitsu, miso) \\``` 13.15 2. R Markdownでまとめた結果を共有することができる YAMLヘッダーのoutputを変更するだけ！ 13.15.1 Wordに出力 13.15.2 Before title: &quot;Untitled&quot; output: html_document date: &quot;2024-04-15&quot; 13.15.3 After title: &quot;Untitled&quot; output: word_document date: &quot;2024-04-15&quot; テンプレートを追加することも可能。テンプレートはきちんとレベル分けの設定などを行っておく必要あり（設定の仕方）。 13.15.4 Power Pointに出力 図や表は必ず新しいページに表示されるなど、knitした後の修正が面倒。 title: &quot;Untitled&quot; output: powerpoint_presentation date: &quot;2024-04-15&quot; 13.15.5 HTML slideに変更 title: &quot;Untitled&quot; output: ioslides_presentation date: &quot;2024-04-15&quot; #で定義するレベル分けでスライドの区切りが代わる #でスライドのセクション見出し ##で新しいページ ###ページ内の太文字 枠にとらわれない！ 以下のチャンクを先頭に入れると、スクロール可能なスライドになる（チャンク内はrではなく、=htmlにする）。 注意点として、タッチパッドや、マウスホイールでスクロールできますが、スクロールバーを掴んでスクロールはできません。 &lt;style&gt; slides &gt; slide { overflow-x: auto !important; overflow-y: auto !important; } &lt;/style&gt; 13.16 HTML形式だと、簡単にウェブサイトにできます リンクで他者に共有できます。 以下の二つは無料で利用できるが、無料版の場合、リンクを知る人だれもが閲覧できるので注意 13.16.1 RPubsを使う コメント機能もあるので、「発表へのコメントは匿名でこちらへ」みたいにできそう。 使い方の解説 13.16.2 Githubを使う Githubとは、コードのバージョン管理をするツール。共同編集可能。 今回は一番簡単な方法で実行します。しかし、Git(hub)をフルで使いこなせば、ファイルのバージョン管理、共同編集などが可能でより再現可能な資料作成に一歩近づくと思います。R Studioとの連携も可能。 使い方の解説 13.17 3. 様々なパソコンで同じ分析環境を再現することができる 13.17.1 パッケージのバージョン管理：renvパッケージ reproducible environments（再現性のある分析環境）の略 RのプロジェクトごとにRの環境を作る。同じパソコンで、同じ名前でバージョンが異なるパッケージを使うことができる。 旧バージョンを試しに使ってみたい場合が、今のバージョンも記録しておきたいときに！ プロジェクトディレクトリを相手に共有できる！別のパソコンで分析したいときにも！ Let’s インストール install.packages(&quot;renv&quot;) 使用する3つの関数 init関数：パッケージ管理の開始を宣言 snapshot関数：パッケージ情報の保存 restore関数：パッケージ情報の復元 13.17.2 バージョン管理の開始 以下のコマンドを走らせると、プロジェクト内で使用しているパッケージを、RやRmdファイルなどから検出します。そして、そのバージョンの情報をrenv.lockファイルに保存します。 renv::init() 最初に実行すると、以下のメッセージが表示されます。 renv: Project Environments for R Welcome to renv! It looks like this is your first time using renv. This is a one-time message, briefly describing some of renv&#39;s functionality. renv will write to files within the active project folder, including: - A folder &#39;renv&#39; in the project directory, and - A lockfile called &#39;renv.lock&#39; in the project directory. In particular, projects using renv will normally use a private, per-project R library, in which new packages will be installed. This project library is isolated from other R libraries on your system. In addition, renv will update files within your project directory, including: - .gitignore - .Rbuildignore - .Rprofile Finally, renv maintains a local cache of data on the filesystem, located at: - &quot;C:/Users/terai-masato/AppData/Local/R/cache/R/renv&quot; This path can be customized: please see the documentation in `?renv::paths`. Please read the introduction vignette with `vignette(&quot;renv&quot;)` for more information. You can browse the package documentation online at https://rstudio.github.io/renv/. Do you want to proceed? [y/N]: yを押して進むと、開いているプロジェクトのあるディレクトリにrenvというフォルダーが作成されます。その中に、3つのファイルと、1つのディレクトリが作成されています。また、renv.lockというファイルも同じディレクトリに作成されます。新しく作成されたものは、すべてrenvパッケージの利用に必要なので、削除しないでください。 - &quot;C:/Users/terai-masato/AppData/Local/R/cache/R/renv&quot; has been created. - Linking packages into the project library ... [33/33] Done! - Resolving missing dependencies ... # Installing packages -------------------------------------------------------- The following package(s) will be updated in the lockfile: # CRAN ----------------------------------------------------------------------- - base64enc [* -&gt; 0.1-3] - bslib [* -&gt; 0.5.1] - cachem [* -&gt; 1.0.8] - cli [* -&gt; 3.6.1] - digest [* -&gt; 0.6.33] - ellipsis [* -&gt; 0.3.2] - evaluate [* -&gt; 0.23] - fastmap [* -&gt; 1.1.1] - fontawesome [* -&gt; 0.5.2] - fs [* -&gt; 1.6.3] - glue [* -&gt; 1.6.2] - highr [* -&gt; 0.10] - htmltools [* -&gt; 0.5.7] - jquerylib [* -&gt; 0.1.4] - jsonlite [* -&gt; 1.8.7] - knitr [* -&gt; 1.45] - lifecycle [* -&gt; 1.0.4] - magrittr [* -&gt; 2.0.3] - memoise [* -&gt; 2.0.1] - mime [* -&gt; 0.12] - prettydoc [* -&gt; 0.4.1] - R6 [* -&gt; 2.5.1] - rappdirs [* -&gt; 0.3.3] - renv [* -&gt; 1.0.7] - rlang [* -&gt; 1.1.2] - rmarkdown [* -&gt; 2.25] - sass [* -&gt; 0.4.7] - stringi [* -&gt; 1.7.12] - stringr [* -&gt; 1.5.0] - tictoc [* -&gt; 1.2] - tinytex [* -&gt; 0.48] - vctrs [* -&gt; 0.6.4] - xfun [* -&gt; 0.41] - yaml [* -&gt; 2.3.7] The version of R recorded in the lockfile will be updated: - R [* -&gt; 4.3.2] - Lockfile written to &quot;~/LET/LET_Workshop_2024/materials_LETworkshop_2024/renv.lock&quot;. Restarting R session... - Project &#39;~/LET/LET_Workshop_2024/materials_LETworkshop_2024&#39; loaded. [renv 1.0.7] 13.17.3 パッケージ情報の保存 パッケージの追加・更新・削除を行ったら、snapshot関数を使ってrenv.lockファイルを更新します。これを忘れると、バージョン情報が変更されないので、注意。 試しに、新しいパッケージをインストールしましょう。今回は、Rに関する様々な名言を含んでいるfortunesパッケージをインストールしましょう。興味のある方はこちらにリストがあります(R Fortunes: Collected Wisdom)。 install.packages(&quot;fortunes&quot;) packageVersion(&quot;fortunes&quot;) ## [1] &#39;1.5.4&#39; fortunes::fortune(which = 78) ## ## R is the lingua franca of statistical research. Work in all other languages ## should be discouraged. ## -- Jan de Leeuw (as quoted by Matt Pocernich on R-help) ## JSM 2003, San Francisco (August 2003) fortunes::fortune(which = 386) ## ## If we put in a function into rstan that dropped chains, people would use it. ## -- Ben Goodrich (about (not) discarding selected chains from a stanfit ## object) ## Stan-users (December 2016) 今回の追加をrenv.lockファイルに追加しましょう。 renv::snapshot() The following package(s) will be updated in the lockfile: # CRAN ----------------------------------------------------------------------- - fortunes [* -&gt; 1.5-4] Do you want to proceed? [Y/n]: ファイルが更新される。 - Lockfile written to &quot;~/LET/LET_Workshop_2024/materials_LETworkshop_2024/renv.lock&quot;. renvフォルダーの中の、library &gt; R-あなたのバージョン &gt; あなたのパソコンPlatformを開くと、パッケージの名前と同じフォルダ（fortunes）が追加されています（五十音順になっているので見つけやすいです）。 13.17.4 パッケージ情報の復元 記録しておくことで、１）パッケージを前のバージョンに戻したり、２）他のパソコンにプロジェクトの分析環境を整えたりすることができる。 パッケージの更新では、お馴染みのinstall.packages関数や、update.packages関数、remove.packages関数を使うが、renv関数で管理しているプロジェクト内では、これらの関数はrenv関数内のパッケージを呼び出している。特に、バージョンを指定したパッケージのインストールがしやすくなっている。 以下のように、パッケージ名@バージョン名で指定 今回は、fortunesパッケージの古いバージョンをインストールする。 最初に、remove.packagesでfortunesパッケージを削除。 注！ここでrenv::snapshot()はやらない。やってしまうと、renv.lockからも削除され、戻らなくなってしまう。 install.packages(&quot;fortunes@1.4-0&quot;) # Installing packages -------------------------------------------------------- - Installing fortunes ... OK [linked from cache] Successfully installed 1 package in 22 milliseconds. The following loaded package(s) have been updated: - fortunes Restart your R session to use the new versions. restart（quit session）をして再度開く。 renv.lockファイルは確認すると、1.5-4のまま！ しかし、パッケージのバージョンは1.4.0! packageVersion(&quot;fortunes&quot;) バージョン1.4.0は2010年9月9日にリリースされている 2016年に追加された386番目の名言はこのバージョンでは追加されていないので表示されない。 fortunes::fortune(which = 78) fortunes::fortune(which = 386) 元に戻す場合は、renv::restore() renv::restore() The following package(s) will be updated: # CRAN ----------------------------------------------------------------------- - fortunes [1.4-0 -&gt; 1.5-4] Do you want to proceed? [Y/n]: 注意 ・ パッケージによっては、手動でのダウンロードが必要なものがあります。その場合、エラーメッセージでどのパッケージのインストールができないのか表示されます。エラーメッセージに表示されているパッケージを見て、手動でそれをインストールします。 13.18 R自体のバージョン管理も可能です 13.18.1 Windows [Tools] → [Global Options] → [R version]をクリックすると、過去にそのPCで使用していたRのバージョンが記録されている。 13.18.2 Mac Windowsのようなセレクトボタンがない！ RSwitchをダウンロードする必要あり 13.19 おまけ 13.19.1 R Markdownに含めておきたい情報 13.19.2 日付、日時 いつ作成されたファイルで、更新はされたことあるのかを明記することが重要 デフォルトでは、ファイルの作成日を手動で切り替えないといけない。 r Sys.Date：2022-01-20 title: &quot;Untitled&quot; author: &quot;Masato Terai&quot; date: &quot;`r Sys.Date()` in JST&quot; # ``と&quot;&quot;で囲うのを忘れない。 output: html_document r Sys.time：2022-01-20 21:36:36 title: &quot;Untitled&quot; author: &quot;Masato Terai&quot; date: &quot;`r format(Sys.time(), &#39;%Y-%m-%d %X&#39;)`&quot; # ``と&quot;&quot;で囲うのを忘れない。 output: html_document 寺井おすすめ title: &quot;Untitled&quot; author: &quot;Masato Terai&quot; date: &quot;作成日:2024-05-20, 最終更新(JST): `r format(Sys.time(), &#39;%Y-%m-%d %X&#39;)`&quot; output: html_document 13.19.3 Rのバージョン &amp; 使用したRのパッケージのバージョン Rのバージョンやパッケージのバージョン情報など sessionInfo() ## R version 4.3.2 (2023-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 11 x64 (build 22621) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## time zone: Asia/Tokyo ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] arm_1.14-4 lme4_1.1-35.1 Matrix_1.6-5 ## [4] kableExtra_1.3.4.9000 sjPlot_2.8.15 emmeans_1.8.9 ## [7] gt_0.10.0 rstan_2.32.5 StanHeaders_2.32.5 ## [10] brms_2.20.4 hdm_0.3.2 MASS_7.3-60 ## [13] olsrr_0.6.1 beeswarm_0.4.0 rstanarm_2.26.1 ## [16] Rcpp_1.0.11 magick_2.8.5 gmodels_2.19.1 ## [19] gganimate_1.0.9 gridExtra_2.3 lubridate_1.9.3 ## [22] forcats_1.0.0 stringr_1.5.0 purrr_1.0.2 ## [25] readr_2.1.4 tidyr_1.3.0 tibble_3.2.1 ## [28] tidyverse_2.0.0 vioplot_0.5.0 zoo_1.8-12 ## [31] sm_2.2-6.0 psych_2.3.9 moments_0.14.1 ## [34] patchwork_1.3.0 dplyr_1.1.3 ggplot2_3.5.1 ## ## loaded via a namespace (and not attached): ## [1] shinythemes_1.2.0 splines_4.3.2 later_1.3.1 ## [4] datawizard_1.0.0 xts_0.13.1 lifecycle_1.0.4 ## [7] processx_3.8.4 lattice_0.21-9 vroom_1.6.5 ## [10] insight_1.0.1 crosstalk_1.2.0 backports_1.4.1 ## [13] magrittr_2.0.3 sass_0.4.9 rmarkdown_2.29 ## [16] jquerylib_0.1.4 yaml_2.3.10 httpuv_1.6.12 ## [19] fortunes_1.5-4 gifski_1.32.0-1 pkgbuild_1.4.5 ## [22] RColorBrewer_1.1-3 chromote_0.4.0 minqa_1.2.6 ## [25] abind_1.4-5 rvest_1.0.4 tensorA_0.36.2 ## [28] tweenr_2.0.3 inline_0.3.19 gdata_3.0.0 ## [31] nortest_1.0-4 goftest_1.2-3 performance_0.13.0 ## [34] bridgesampling_1.1-2 svglite_2.1.3 codetools_0.2-19 ## [37] DT_0.30 xml2_1.3.6 tidyselect_1.2.1 ## [40] bayesplot_1.10.0 ggeffects_1.3.2 farver_2.1.1 ## [43] effectsize_1.0.0 matrixStats_1.1.0 stats4_4.3.2 ## [46] base64enc_0.1-3 webshot_0.5.5 jsonlite_1.8.9 ## [49] Formula_1.2-5 ellipsis_0.3.2 survival_3.5-7 ## [52] systemfonts_1.2.1 tools_4.3.2 progress_1.2.3 ## [55] glue_1.6.2 mnormt_2.1.1 xfun_0.49 ## [58] mgcv_1.9-0 distributional_0.3.2 websocket_1.4.2 ## [61] loo_2.6.0 withr_3.0.2 fastmap_1.2.0 ## [64] boot_1.3-28.1 shinyjs_2.1.0 digest_0.6.33 ## [67] estimability_1.4.1 timechange_0.2.0 R6_2.6.1 ## [70] mime_0.12 colorspace_2.1-0 gtools_3.9.4 ## [73] markdown_1.13 threejs_0.3.3 utf8_1.2.4 ## [76] generics_0.1.3 prettyunits_1.2.0 httr_1.4.7 ## [79] htmlwidgets_1.6.4 parameters_0.24.1 pkgconfig_2.0.3 ## [82] dygraphs_1.1.1.6 gtable_0.3.6 htmltools_0.5.8.1 ## [85] carData_3.0-5 bookdown_0.42 scales_1.3.0 ## [88] png_0.1-8 posterior_1.5.0 knitr_1.49 ## [91] rstudioapi_0.17.1 tzdb_0.4.0 reshape2_1.4.4 ## [94] coda_0.19-4.1 checkmate_2.3.0 nlme_3.1-163 ## [97] curl_5.1.0 nloptr_2.0.3 cachem_1.1.0 ## [100] sjlabelled_1.2.0 parallel_4.3.2 miniUI_0.1.1.1 ## [103] pillar_1.10.1 grid_4.3.2 vctrs_0.6.4 ## [106] shinystan_2.6.0 promises_1.2.1 car_3.1-2 ## [109] xtable_1.8-4 evaluate_1.0.3 mvtnorm_1.2-3 ## [112] cli_3.6.1 compiler_4.3.2 rlang_1.1.2 ## [115] crayon_1.5.3 rstantools_2.3.1.1 modelr_0.1.11 ## [118] labeling_0.4.3 ps_1.8.1 plyr_1.8.9 ## [121] sjmisc_2.8.9 stringi_1.7.12 viridisLite_0.4.2 ## [124] QuickJSR_1.0.7 munsell_0.5.1 colourpicker_1.3.0 ## [127] Brobdingnag_1.2-9 bayestestR_0.15.1 V8_4.4.1 ## [130] sjstats_0.18.2 hms_1.1.3 bit64_4.6.0-1 ## [133] shiny_1.8.0 haven_2.5.3 igraph_1.5.1 ## [136] broom_1.0.7 RcppParallel_5.1.7 bslib_0.9.0 ## [139] bit_4.5.0.1 13.19.4 パソコンのスペック CPUとコア数とRAM CPU コア数（論理コア） 「論理コア」は「スレッド」「論理プロセッサ」、「仮想コア」とも呼ばれる CPUとコアについて RAM (Random Access Memory) ストレージ（SSDやHDD）ではなく、データを一時保存する場所 #install.packages(&quot;benchmarkme&quot;) # 入れていないかたは先にインストールしてください benchmarkme::get_cpu() ## $vendor_id ## [1] &quot;GenuineIntel&quot; ## ## $model_name ## [1] &quot;13th Gen Intel(R) Core(TM) i9-13900K&quot; ## ## $no_of_cores ## [1] 32 benchmarkme::get_ram() ## 137 GB 13.19.5 処理にかかった時間 時間のかかる分析を行う人は明記する方が親切！ いつ終わるのか分からない見通しのつかない分析を実行するのは怖いです。コア数に加え処理にかかった時間が記載されていればおおよその見通しがつきます。 #install.packages(&quot;tictoc&quot;) # 入れていないかたは先にインストールしてください library(tictoc) tic() #測定開始 I &lt;-NULL for(i in 1:100000){ I &lt;- c(I, i)} toc() #測定終了 ## 6.14 sec elapsed 13.20 関数の呼び出し方 library(関数名)：一番メジャー パッケージ名::関数名：あまりメジャーじゃない require(関数名)：library()とほとんど変わらないが、関数を読み込めたかどうかを論理値で返すことができる。関数が読み込めない（＝パッケージを入れていない）場合に、まずそのパッケージを読み込んで、処理に進ませるみたいな用途で使える。 if (require(パッケージ名) == FALSE) { install.packages(パッケージ名) } else { #パッケージを利用してやろうとしていたことをここに書く } 13.20.1 関数名が被ることがある（xxxはマスクされています） グラフの透明度を設定するalpha関数（ggplot2パッケージ）と、信頼性係数を出すalpha関数（psychパッケージ） エラーの原因になる場合あり。::で定義すると回避できる。 13.20.2 関数とパッケージの対応は覚えにくい R Markdownのファイルの冒頭にこのようにまとめてある。確かに、その分析で使うパッケージが一目瞭然だが、個別の処理においてどのパッケージが読み込まれたのか分かりにくく、そのコードを参考に書き換えにくくなる。 どのパッケージに属する関数なのか一目瞭然。ただしその都度パッケージ名を書くので、コードが長くなるという欠点も 13.21 まとめ R Markdownでは、YAMLヘッダー、コードチャンク、ドキュメントチャンクを使って分析結果をまとめることができる。 研究ごとにプロジェクトを作成しておくとよい 作成したR Markdownファイルは、Word、HTMLファイル、Power Pointなど様々な形式に出力できる。 RPubsやGithubを使えば、ウェブページとして共有できる RのパッケージやR自体のバージョンは切り替えて使うことができる。 再現しようとする分析ファイルに記載されたバージョンに合わせて分析することでより再現性が高まる 13.22 参考文献 &amp; 資料 13.22.1 ：書籍、：ウェブサイトの記事 「物理コア」と「論理コア」の違い MacでのRstudio上でのR versionの切り替え方法 Rが生産性を高める データ分析ワークフロー効率化の実践 Rで関数の前に::をつけるのなんで？ R言語でパッケージから関数を呼び出す Switching R versions in Windows 再現可能性のすすめ：RStudioによるデータ解析とレポート作成 私たちのR YAMLについての基本知識 R Markdownでスライドを作成（ioslides） R Markdown クックブック R Markdown Cheat Sheet "],["sharing-your-book.html", "Chapter 14 Sharing your book", " Chapter 14 Sharing your book 以下の説明はダメ 標本サイズ30以上ならば大丈夫 正規性検定で正規性の帰無仮説が棄却されなかったら、正規分布モデルを使って良い ＊母集団分布の形状について何も情報がないならば、必要な標本サイズの上限は決まらなくなります。 ＊身長なら正規分布モデルに従うことが和kる ＊母平均があなたの目的にとって適切な代表値なのかどうかをよく考えよ。 ＊検定達は、確かに正規分布モデルを使って導出される検定法ですが、中心極限定理のお陰で、正規分布モデル自体が誤りになるような未知の母集団分布の場合であっても許容できる誤差の範囲内で使用可能な場合が結構沢山あります。(もちろんダメな場合もある。) ＊正規分布でないからノンパラ使おう（無条件では）はだめ ＊Mann-WhitneyのU検定のP値は 2つの母集団分布はぴったり等しい という仮定を使って計算されるので、2群の優劣のために使用するのは危険な場合があります。 無条件では使えない使い方が難しい検定法なので注意が必要。Mann-WhitneyのU検定を使っている報告は粗探しをする必要があります。 T検定はウェルチをデフォルトで使う ＊例えば、ある特定目的のための2つの集団の比較で母平均の差の推定値を使うことが適切であるか、という問題は、その目的と2つの集団とデータの取得法に関する専門知識がないと手も足も出ない問題になります。統計学の使用では Science before Statistics! という合言葉が必要。 *Use of nomality tests before t test https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787#use-of-normality-tests-before-t-tests-13 フローチャートに従って決めるなどは推奨されない。 →研究したいこと、見たいことは何かを考える →研究分野に対する知識が重要。〇→XならAIにもできるし、言語研究の専門家でなくても分析ができてしまう。→自分の研究したいことは自分が一番よく理解しようという心構えが自分の分野の将来も守る 過去の研究や理論的背景から、母集団分布の形を考える 引用：https://biostatistics.ucdavis.edu/sites/g/files/dgvnsk4966/files/media/documents/Greenland.Advancing%20statistics%20reform%2C%20part%204.Slides%201-110%2C%2001%20June%202022.pdf "]]
